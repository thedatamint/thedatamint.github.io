var tipuesearch = {"pages":[{"url":"/pages/meraki-hues.html","text":"","tags":"yeah","loc":"/pages/meraki-hues.html","title":"Meraki Hues"},{"url":"/multilabel text classification.html","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ Multilabel Text Classification Using Custom Embeddings in Keras. Traditionally, classification problems are either formulated as - Binary Classification problems - where each training example belongs to either a positive or a negative class. Multiclass Classification problem - where each training example belongs to one of the 'k' classes. In this article, we shall explore a new problem statement - Multilabel Classification Problem - In many real world data applications, often we encounter scenarios where each data point belongs to multiple classes. Suppose you are working for Recruiting Firm which receives thousands of Resumes each day. You are tasked with the problem of tagging each resume with relevant set of skills which hiring committee cares about. In such a scenario, it is possible to have a candidate who possesses 'leadership' skills as well as 'coding' skills. Such a setup requires you to solve a multilabel classification problem. The following sections will cover - Data Description, Data Cleaning. Encoding Labels. Defining a custom Embedding Layer with keras. Defining Loss Function and Evaluation Metric for Multilabel Classification Model Building Training a model Inference. Final Comments and References. Let's start by importing a whole bunch of python libraries that we will need for successful implementation of our algorithm. In [2]: import os import json import re import string import codecs from operator import itemgetter import numpy as np import pandas as pd import keras.backend as K from keras.layers import ( Dense , Conv1D , Activation , BatchNormalization , MaxPooling1D , Dropout , Flatten , GlobalMaxPool1D , Bidirectional , LSTM , GRU , Lambda , Concatenate , Dot , Reshape , TimeDistributed ) from keras.models import Model , Input from keras.preprocessing.text import Tokenizer , one_hot , text_to_word_sequence from keras.preprocessing import sequence from keras.preprocessing.sequence import pad_sequences import keras from keras.layers.embeddings import Embedding from keras import optimizers , regularizers from keras.optimizers import SGD from keras.utils import to_categorical from keras.regularizers import l1 , l2 from nltk.corpus import stopwords from nltk.stem import WordNetLemmatizer import nltk from nltk import word_tokenize , sent_tokenize import sklearn from sklearn.utils import shuffle from sklearn.preprocessing import MultiLabelBinarizer from IPython.core.interactiveshell import InteractiveShell InteractiveShell . ast_node_interactivity = \"all\" import matplotlib.pyplot as plt % matplotlib inline from IPython.display import HTML display ( HTML ( '<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>' )) display ( HTML ( \"<style>.container { width:100% !important; }</style>\" )) Using TensorFlow backend. .prompt{width: 0px; min-width: 0px; visibility: collapse} .container { width:100% !important; } In [3]: batch_size = 12 MAX_NB_WORDS = 300000 weight_decay = 1e-4 latent_dim = 300 Data Description - For implementing a multilabel classifier, we shall be using the \"DBPedia Hierarchical Classes dataset\" dataset from Kaggle. Context - DBpedia (from \"DB\" for \"database\") is a project aiming to extract structured content from the information created in Wikipedia. This is an extract of the data that provides taxonomic, hierarchical categories (\"classes\") for 342,782 wikipedia articles. There are 3 levels, with 9, 70 and 219 classes respectively. A version of this dataset is a popular baseline for NLP/text classification tasks. This version of the dataset is much tougher, especially if the L2/L3 levels are used as the targets. The Dataset consists of the following columns - text - a free text column which describes the entity. l1 - Base label in the hierarchy. l2 - Intermediate label in the hierarchy. l3 - Top level label in the hierarchy. There can be multiple tags associated with each entity making it a multilabel classificatiopn problem. In [6]: ### load training data data = pd . read_csv ( './data/dbpedia/DBPEDIA_train.csv' , encoding = \"utf-8\" , names = [ 'raw_text' , 'l1' , 'l2' , 'l3' ], header = 0 ) display ( data . head ()) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } raw_text l1 l2 l3 0 William Alexander Massey (October 7, 1856 – Ma... Agent Politician Senator 1 Lions is the sixth studio album by American ro... Work MusicalWork Album 2 Pirqa (Aymara and Quechua for wall, hispaniciz... Place NaturalPlace Mountain 3 Cancer Prevention Research is a biweekly peer-... Work PeriodicalLiterature AcademicJournal 4 The Princeton University Chapel is located on ... Place Building HistoricBuilding Data Cleaning - In this section, we shall perform some basic preprocessing on our raw text data using following techniques - merge title and synopsis data columns for better handling. We shall refer this column as raw_text Split comma separated tags for each movie. Remove punctuation and stopwords from raw_text. Lemmatize raw_text - Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma . For more information on lemmatization refer to the stanford notes . In [6]: en_stopwords = set ( stopwords . words ( 'english' )) punctuations_filter = string . punctuation . replace ( \".\" , \"\" ) print ( punctuations_filter ) regex = re . compile ( '[ %s ]' % re . escape ( punctuations_filter )) puncts_trans = string . maketrans ( \"\" , \"\" ) lemmatizer = WordNetLemmatizer () def get_cleaned_string ( raw_string ): cleaned_text = regex . sub ( '' , raw_string ) . lower () tokens = [ lemmatizer . lemmatize ( word ) for word in nltk . word_tokenize ( cleaned_text ) if word not in en_stopwords ] sentence = \" \" . join ( tokens ) return sentence data [ 'cleaned_text' ] = data [ 'raw_text' ] . apply ( get_cleaned_string ) !\"#$%&'()*+,-/:;<=>?@[\\]&#94;_`{|}~ Train Test Split - In this section, we shall split our data into 3 subsets - a. Training data - This data will be used for training our classifier my minimizing the overall loss. b. Validation data - The Validation data will help in selecting hyper-parameters. Since this data is not explicitly used for training the model, validation data also helps in reducing overfitting. c. Test Data - We shall use test data to estimate model's performance on OOB (out-of-bag) data points. Since there is no off the shelf function in sklearn or keras that splits dataset into 3 different subsets, We shall leverage the train_test_split function by making a call to it twice. In [7]: raw_train_data , test_data = sklearn . model_selection . train_test_split ( data , test_size = 0.03 ) train_data , validation_data = sklearn . model_selection . train_test_split ( raw_train_data , test_size = 0.03 ) In [8]: train_data = train_data . reset_index ( drop = True ) validation_data = validation_data . reset_index ( drop = True ) test_data = test_data . reset_index ( drop = True ) In [9]: print ( \"Training data has %d datapoints\" % len (train_data)) print ( \"Validation data has %d datapoints\" % len (validation_data)) print ( \"Test data has %d datapoints\" % len (test_data)) Training data has 226701 datapoints Validation data has 7012 datapoints Test data has 7229 datapoints In [56]: display ( train_data [[ 'cleaned_text' , 'l1' , 'l2' , 'l3' ]] . head ()) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } cleaned_text l1 l2 l3 0 national competition previously called nationa... Agent SportsLeague RugbyLeague 1 crbc established 1932 government r.b . bennett... Agent Broadcaster BroadcastNetwork 2 burger king v. rudzewicz 471 u.s. 462 1985 not... UnitOfWork LegalCase SupremeCourtOfTheUnitedStatesCase 3 lynda oconnell born 1981 cork camogie player a... Agent Athlete GaelicGamesPlayer 4 soreltracy éperviers soreltracy hawk hockey te... Agent SportsTeam HockeyTeam Label Encoding - In order to train a classifier, we need to convert the string tags into a vector of 1s and 0s. There are about 71 tags in the dataset. Therefore, for each datapoint, we need to construct a 1 x 71 dimensional vector with each bit in the vector representing a tag. Since datapoint can have multiple tags, the target label will consist of 1s at all indices corresponding to the target tag attached to the datapoint. To accomplish this, we shall train a MultiLabelBinarizer . In [12]: labelEncoder_model = MultiLabelBinarizer () labelEncoder_model . fit ( data [[ 'l1' , 'l2' , 'l3' ]] . values ) Out[12]: MultiLabelBinarizer(classes=None, sparse_output=False) In [13]: unique_classes = labelEncoder_model . classes_ print ( \"sample classes are %s \" % list (unique_classes)[:10]) sample classes are [u'AcademicJournal', u'Actor', u'AdultActor', u'Agent', u'Airline', u'Airport', u'Album', u'AmateurBoxer', u'Ambassador', u'AmericanFootballPlayer'] Custom Embedding Layer - Embedding layer in keras is responsible of representing the input sequence of text with a vector of a size defined in the model. one of the most adopted techniques while working with text is to train a tfidf vectorizer followed by a Dimensionality Reduction technique (PCA, Random Projections, etc) . The embedding layer in keras facilitates the execution of sequence mentioned above while training a classifier. It is also possible to derive weights from a pretrained model like word2vec or gloVe. However, in this article we shall focus on training a custom Embedding layer. The Embedding layer expect a fixed input size of dimensions (batch_size $\\times$ max_sequence_length) where max_sequence_length determines the maximum length of input text sequence. The Output of Embedding Layer is a matrix of shape batch_size X max_sequence_length X embedding_size. In order to match the input contract, we shall train a keras Tokenizer using fit_on_texts function. Note that, one can use different techniques to identify the max sequence length. For the sake of this project, we will consider the 90th percentile of the input sequence length distribution. In [14]: print ( \"tokenizing input data...\" ) tokenizer1 = Tokenizer ( num_words = MAX_NB_WORDS , lower = True , char_level = False ) tokenizer1 . fit_on_texts ( train_data [ 'cleaned_text' ]) train_data [ 'doc_len' ] = train_data [ 'cleaned_text' ] . apply ( lambda sentence : len ( sentence . split ( ' ' ))) tokenizing input data... Attention Mechanism - Before we proceed further, I would like to take a pause and delve into the philosophical and mathematical details of Attention Mechanism. Why Attention Mechanism ? Consider a simple spam vs not-spam binary text classification problem where input is a free flowing email text and you would like to predict if it is a spam or not-spam. Typically, if you were to decide manually, you invariably look for trigger words (Nigerian Prince, Lottery Winner, No credit check, <suspicious link> , etc) which would hint towards an email being spam. These trigger words influence your decision no matter where they appear in text. In other words, subconsciously you end up assigning a higher weight to these trigger keywords which ultimately helps you reach a decision. Attention Mechanism tries to replicate a similar behaviour where it attempts to assign a higher weightage to trigger keywords that ultimately helps our model in reaching a decision. Aren't the likes of GRUs and LSTMs suppose to do something similar? Well, a typical RNN network suffers from the problem of vanishing gradients. As a result, earlier parts of a temporal data is unable to contribute towards the final decision being made. GRUs and LSTMs are able to ameliorate this problem by introducing memory cells and forget gates. However, they can remember sequences of 100s but not definitely not 1000s. Sure, one can take a Global Max of returned activations and use them to predict classes but a \"hard-max\" takes the maximum value and forgets everything else. ENTER ATTENTION MECHANISM !! A softmax (Attention weights) gives the probability distribution over each activation at different time steps. Definitely, a distribution is more helpful than a point estimate (Stats 101, right?) Estimating Attention Weights while training - Hopefully, the need for an Attention Mechanism is justified in the previous section. In this section, let's go over some of the mathematical details to better understand the concept. This will help us while building the network as well. Let's get to it - It is evident that these weights are dynamic and hence cannot be pre-computed. The following image by WildML summarises the attention mechanism in a block diagram format. As seen in the above image, the output at time 't' is a weighted average of weights $\\alpha&#94;{<t,t'>}$ where t' = ${1, 2, 3....T_x}$ $\\alpha&#94;{<t,t'>}$ indicates the amount of attention that $y&#94;{<t>}$ should pay to $a&#94;{<t'>}$ \\begin{align} c&#94;{ } = \\sum_{t'=1}&#94;{Tx} \\alpha&#94;{ } * a&#94;{ } \\end{align} How to compute $\\alpha&#94;{<t,t'>}$ ? Since $\\alpha&#94;{<t,t'>}$ are weights at time t representing the probability distribution of attentions, a good way to model them would be to use Softmax (If you guessed it, be proud of yourselves !!) Let's define - \\begin{align} \\alpha&#94;{ } = \\frac{\\exp{e&#94;{ }}}{\\sum_{t=1}&#94;{T_x} \\exp{e&#94;{ }}} \\end{align} It is easy to conclude that where model should pay attention is dictated by the values of $<e&#94;{t,t'}>$ Where to pay attention depends not only on hidden states ($a&#94;{<t'>}$) but also on where we are in the output ($s&#94;{<t-1>}$) sequence of length $T_y$. However, we don't know the function that maps hidden states and current output to $e&#94;{<t,t'>}$. Hence we shall determine the function using a small neural network. In text classification, the output steps are limited to 1. This simplifies our problem statement. The magnified block diagram for attention mechanism is as follows - Hierarchical Attention Network - With the basics around attention network chalked out, let's take this a notch higher. Hierarchical Attention Networks were introduced by Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He, Alex Smola, & Eduard Hovy at Carnegie Melon in association with Microsoft. The proposed model exploits the herarchical structure in documents. Each document can be viewed as a group sentences with each sentence as collection of words. The block diagram of the architecture is as follows - The model represents a document representation by building a representation of sentences which are then aggregated. Further, the model also represents each sentence by building a representation of words. This takes into account the fact that words as well as sentences are differentially important based on context. The original paper can be found here . Do take some time to read it. Data Wrangling - It is now time to implement the ideas studied in earlier sections. We start by pre-processing our input data. The raw input data consists of paragraphs of textual information of dimensions m $\\times$ 1. In the next section, we simply convert of 1D data into 2D. The new dimensions will be $m \\times n_{sent} \\times n_{words}$ where m is the number of training examples, $n_{sent}$ is the maximum number of sentences in each training example and $n_{words}$ is the maximum number of words in a sentence. In [16]: tot_sents = [] num_sents = [] len_sent = [] In [17]: for text_val in train_data [ 'cleaned_text' ]: ind_sentences = sent_tokenize ( text_val ) tot_sents . append ( ind_sentences ) num_sents . append ( len ( ind_sentences )) for sent in ind_sentences : len_sent . append ( len ( word_tokenize ( sent ))) In [18]: max_sent_len = int ( np . percentile ( len_sent , 98 )) max_num_sent = int ( np . percentile ( num_sents , 95 )) In [19]: print ( \"Max sentences capped to %f \" % max_num_sent ) print ( \"Max sentence length capped at %f \" % max_sent_len ) Max sentences capped to 12.000000 Max sentence length capped at 38.000000 In [20]: train_data_np = np . zeros (( len ( train_data [ 'cleaned_text' ]), max_num_sent , max_sent_len ), dtype = 'int32' ) for i , sentences in enumerate ( tot_sents ): for j , sent in enumerate ( sentences ): if j < max_num_sent : wordTokens = text_to_word_sequence ( sent ) k = 0 for _ , word in enumerate ( wordTokens ): try : if k < max_sent_len and tokenizer1 . word_index [ word ] < MAX_NB_WORDS : train_data_np [ i , j , k ] = tokenizer1 . word_index [ word ] k = k + 1 except : pass In [21]: val_sents = [] for text_val in validation_data [ 'cleaned_text' ]: ind_sentences = sent_tokenize ( text_val ) val_sents . append ( ind_sentences ) In [22]: val_data_np = np . zeros (( len ( validation_data [ 'cleaned_text' ]), max_num_sent , max_sent_len ), dtype = 'int32' ) for i , sentences in enumerate ( val_sents ): for j , sent in enumerate ( sentences ): if j < max_num_sent : wordTokens = text_to_word_sequence ( sent ) k = 0 for _ , word in enumerate ( wordTokens ): try : if k < max_sent_len and tokenizer1 . word_index [ word ] < MAX_NB_WORDS : val_data_np [ i , j , k ] = tokenizer1 . word_index [ word ] k = k + 1 except : pass In [23]: word_index = tokenizer1 . word_index vocab_size = len ( tokenizer1 . word_index ) + 1 print ( \"Vocab size - %d \" % vocab_size ) Vocab size - 566172 Transfer Learning - To expedite the training process, we shall piggy back on pre-trained gloVe models. The process of building Embedding matrix is pretty standard. In [24]: #load embeddings print ( 'loading word embeddings...' ) embeddings_index = {} f = codecs . open ( os . path . join ( '.' , 'data' , 'glove_pretrained' , 'glove.42B.300d.txt' ), encoding = 'utf-8' ) for line in f : values = line . rstrip () . rsplit ( ' ' ) word = values [ 0 ] coefs = np . asarray ( values [ 1 :], dtype = 'float32' ) embeddings_index [ word ] = coefs f . close () print ( 'found %s word vectors' % len ( embeddings_index )) loading word embeddings... found 1917494 word vectors In [25]: #embedding matrix print ( 'preparing embedding matrix...' ) words_not_found = [] nb_words = min ( MAX_NB_WORDS , vocab_size ) embedding_matrix = np . zeros (( nb_words , latent_dim )) for word , i in word_index . items (): if i >= nb_words : continue embedding_vector = embeddings_index . get ( word ) if ( embedding_vector is not None ) and len ( embedding_vector ) > 0 : # words not found in embedding index will be all-zeros. embedding_matrix [ i ] = embedding_vector else : words_not_found . append ( word ) print ( 'number of null word embeddings: %d ' % np . sum ( np . sum ( embedding_matrix , axis = 1 ) == 0 )) preparing embedding matrix... number of null word embeddings: 120322 In [26]: def prepare_training_generators ( train_x , train_y , chunk_size = 5 , channel_orientation = \"channels_first\" ): ''' This function generates mini batches of training data in the form of an iterator. inputs: train_df: pandas dataframe of training data. len_unique_classes - integer value highlighting the number of unique target labels in training data. chunk_size - integer value highlighting the mini batch siz. The default value is set to 16 channel_orientation - A string values used to represenattion the channel orientation of images to be read. output: iterator of text_data, image_data and output label ''' indices = range ( len ( train_x )) index_tracker = 0 while True : batch_indices = indices [ index_tracker : index_tracker + chunk_size ] text_x = train_x [ batch_indices ] y_le = labelEncoder_model . transform ( train_y . loc [ batch_indices , [ 'l1' , 'l2' , 'l3' ]] . values ) index_tracker += chunk_size if index_tracker >= len ( train_x ): index_tracker = 0 np . random . shuffle ( indices ) yield text_x , y_le Loss Function and Evaluation metric - Loss Function - A cross entropy loss for C classes and m training examples is defined as - \\begin{align} CE = - \\sum_{i = 1}&#94;{m} \\sum_{j= 1}&#94;{C} y_ilog(\\hat{y_i})\\end{align} Typically a Binary classification problem uses a sigmoid activation in the final layer of the neural network. The sigmoid function for pre-activations $z$ is defined as - \\begin{align} \\hat{y} = \\frac{1}{1 + e&#94;{-z}} \\end{align} Where, \\begin{align} z = WX + b \\end{align}\\begin{align} X = m \\times n \\end{align}\\begin{align} W = n \\times 1 \\end{align} The cross entropy loss function for binary classification can hence be written as - \\begin{align} BCE & = - \\sum_{i = 1}&#94;{m} \\sum_{j= 1}&#94;{2} y_ilog(\\hat{y_i}) \\\\ & = - \\sum_{i = 1}&#94;{m} y_i log(\\hat{y_i}) + (1- y_i)log(1 - \\hat{y_i}) \\end{align} For multilabel classification we shall assume that each label as an independent Binomial Random Variable. As a result of this assumption, a loss of Binary loss function makes much more sense than a categorical cross entropy function. Lastly, by the assumption of independence, since the probability that a data point belongs to class i is independent of whether of class j, the activation in the final layer of the network has to be \"sigmoid\" and not \"softmax\". For a multilabel classification problem, various different loss function can also be used. Check them out at the following links for more information. Multilabel Classification - Label Dependence, Loss Minimization and Reduction Algorithms by Krzysztof Dembczy´nski Distance for Binary Variables Approaches for the Improvement of the Multilabel Multiclass Classification with a huge Number of Classes by Martha Tatusch Evaluation Metric - Typically, a standard metric for classification like accuracy can suffice. However, it can often be misleading when target labels have only a small subset which is positive. In such cases, accuracy is often over-estimated. To overcome this problem, we shall be using a custom loss function defined by Matthew R. Boutell in Learning multi-label scene classification Please find below a snippet from the paper which describes the $\\alpha evaluation$ metric - In [27]: def softmax_over_time ( x ): assert ( K . ndim ( x ) > 2 ) e = K . exp ( x - K . max ( x , axis = 1 , keepdims = True )) s = K . sum ( e , axis = 1 , keepdims = True ) return e / s def check_nonzero ( y_true , y_pred ): \"\"\" Custom metric Returns sum of all embeddings \"\"\" return ( K . sum ( K . cast ( y_pred > 0.4 , 'int32' ))) def custom_score ( y_true , y_pred ): \"\"\" score reference - https://www.rose-hulman.edu/~boutell/publications/boutell04PRmultilabel.pdf more resources - 1. Distance between binary variables - https://people.revoledu.com/kardi/tutorial/Similarity/BinaryVariables.html 2. jaccard co-efficient (intersection over union) - https://people.revoledu.com/kardi/tutorial/Similarity/Jaccard.html \"\"\" y_true = K . cast ( y_true , 'int32' ) y_pred = K . cast ( K . round ( y_pred ), 'int32' ) neg_y_true = 1 - y_true neg_y_pred = 1 - y_pred alpha = K . constant ( 1 , 'float32' ) beta = K . constant ( 0.75 , 'float32' ) gamma = K . constant ( 1 , 'float32' ) tp = K . cast ( K . sum ( y_true * y_pred ), 'float32' ) fp = K . cast ( K . sum ( neg_y_true * y_pred ), 'float32' ) fn = K . cast ( K . sum ( y_true * neg_y_pred ), 'float32' ) score = 1 - (( beta * fn + gamma * fp ) / ( fn + fp + tp + K . epsilon ())) return score Building HAN Model - In order to build a Hierarchical Attention network, we will split it into two models for better visibility, debugging and code management. First, we define a \"word attention model\" which takes a sentence as input and return activations based an attention mechanism. Next we design a \"sentence attention model\" which is responsible for representing attention mechanism for each sentence at the input. Note that, we shall be using TimeDistributed layer provided by keras to extract word attention representation for each sentence at the input. The TimeDistributed layer ensures that same weights are applied to each input in the sequence. In [28]: def word_encoder ( text_input_shape ): inp = Input ( shape = text_input_shape ) x = Embedding ( embedding_matrix . shape [ 0 ], embedding_matrix . shape [ 1 ], weights = [ embedding_matrix ], trainable = False )( inp ) # x = Embedding(vocab_size, latent_dim)(inp) x = BatchNormalization ()( x ) h = Bidirectional ( GRU ( 128 , return_sequences = True , recurrent_dropout = 0.2 , dropout = 0.2 ))( x ) ## FCNN for estimating attention weights. u = Dense ( 256 )( h ) u = BatchNormalization ()( u ) u = Activation ( 'tanh' )( u ) u = Dense ( 1 )( u ) u = BatchNormalization ()( u ) u = Activation ( softmax_over_time )( u ) ## weighted average of attention weights and GRU output sequence for words. s = Dot ( axes = 1 )([ u , h ]) s = Flatten ()( s ) model = Model ( inputs = inp , outputs = s ) word_attention_weights_model = Model ( inputs = inp , outputs = u ) model . summary () return model , word_attention_weights_model In [29]: def sent_encoder ( word_encoder , text_input_shape = ( 11 , 33 ), classes = 6 ): inp = Input ( shape = text_input_shape ) x = TimeDistributed ( word_encoder )( inp ) x = BatchNormalization ()( x ) h = Bidirectional ( GRU ( 32 , return_sequences = True , recurrent_dropout = 0.2 , dropout = 0.2 ))( x ) ## FCNN for estimating attention weights. u = Dense ( 128 )( h ) u = BatchNormalization ()( u ) u = Activation ( 'tanh' )( u ) u = Dense ( 1 )( u ) u = BatchNormalization ()( u ) u = Activation ( softmax_over_time )( u ) ## Weighted average of attention and sentence representation sequencs. s = Dot ( axes = 1 )([ u , h ]) s = Flatten ()( s ) ## Note that the activation for final layer is sigmoid and softmax. x = Dense ( classes , activation = \"sigmoid\" )( s ) model = Model ( inputs = inp , outputs = x ) attention_weights_model = Model ( inputs = inp , outputs = u ) opt = keras . optimizers . Adam ( lr = 0.01 , beta_1 = 0.9 , beta_2 = 0.999 , epsilon = None , decay = 0.0 , amsgrad = False ) ## Note that the loss function is 'binary_crossentropy' model . compile ( loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = [ custom_score , check_nonzero ]) model . summary () return model , attention_weights_model In [48]: word_encoder_model , word_attention_model = word_encoder ( text_input_shape = ( max_sent_len , )) __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_5 (InputLayer) (None, 38) 0 __________________________________________________________________________________________________ embedding_3 (Embedding) (None, 38, 300) 90000000 input_5[0][0] __________________________________________________________________________________________________ batch_normalization_13 (BatchNo (None, 38, 300) 1200 embedding_3[0][0] __________________________________________________________________________________________________ bidirectional_5 (Bidirectional) (None, 38, 256) 329472 batch_normalization_13[0][0] __________________________________________________________________________________________________ dense_11 (Dense) (None, 38, 256) 65792 bidirectional_5[0][0] __________________________________________________________________________________________________ batch_normalization_14 (BatchNo (None, 38, 256) 1024 dense_11[0][0] __________________________________________________________________________________________________ activation_9 (Activation) (None, 38, 256) 0 batch_normalization_14[0][0] __________________________________________________________________________________________________ dense_12 (Dense) (None, 38, 1) 257 activation_9[0][0] __________________________________________________________________________________________________ batch_normalization_15 (BatchNo (None, 38, 1) 4 dense_12[0][0] __________________________________________________________________________________________________ activation_10 (Activation) (None, 38, 1) 0 batch_normalization_15[0][0] __________________________________________________________________________________________________ dot_5 (Dot) (None, 1, 256) 0 activation_10[0][0] bidirectional_5[0][0] __________________________________________________________________________________________________ flatten_5 (Flatten) (None, 256) 0 dot_5[0][0] ================================================================================================== Total params: 90,397,749 Trainable params: 396,635 Non-trainable params: 90,001,114 __________________________________________________________________________________________________ In [49]: text_only_model , sent_attention_weights_model = sent_encoder ( word_encoder_model , text_input_shape = ( max_num_sent , max_sent_len ) , classes = len ( labelEncoder_model . classes_ )) __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_6 (InputLayer) (None, 12, 38) 0 __________________________________________________________________________________________________ time_distributed_3 (TimeDistrib (None, 12, 256) 90397749 input_6[0][0] __________________________________________________________________________________________________ batch_normalization_16 (BatchNo (None, 12, 256) 1024 time_distributed_3[0][0] __________________________________________________________________________________________________ bidirectional_6 (Bidirectional) (None, 12, 64) 55488 batch_normalization_16[0][0] __________________________________________________________________________________________________ dense_13 (Dense) (None, 12, 128) 8320 bidirectional_6[0][0] __________________________________________________________________________________________________ batch_normalization_17 (BatchNo (None, 12, 128) 512 dense_13[0][0] __________________________________________________________________________________________________ activation_11 (Activation) (None, 12, 128) 0 batch_normalization_17[0][0] __________________________________________________________________________________________________ dense_14 (Dense) (None, 12, 1) 129 activation_11[0][0] __________________________________________________________________________________________________ batch_normalization_18 (BatchNo (None, 12, 1) 4 dense_14[0][0] __________________________________________________________________________________________________ activation_12 (Activation) (None, 12, 1) 0 batch_normalization_18[0][0] __________________________________________________________________________________________________ dot_6 (Dot) (None, 1, 64) 0 activation_12[0][0] bidirectional_6[0][0] __________________________________________________________________________________________________ flatten_6 (Flatten) (None, 64) 0 dot_6[0][0] __________________________________________________________________________________________________ dense_15 (Dense) (None, 298) 19370 flatten_6[0][0] ================================================================================================== Total params: 90,482,596 Trainable params: 480,712 Non-trainable params: 90,001,884 __________________________________________________________________________________________________ In [50]: tboard = keras . callbacks . TensorBoard ( log_dir = './logs' , histogram_freq = 0 , batch_size = batch_size , write_graph = True , write_grads = False , write_images = False , embeddings_freq = 0 , embeddings_layer_names = None , embeddings_metadata = None , embeddings_data = None ) validation_data_gen = prepare_training_generators ( val_data_np , validation_data , chunk_size = batch_size ) train_data_gen = prepare_training_generators ( train_data_np , train_data , chunk_size = batch_size ) In [51]: history3 = text_only_model . fit_generator ( train_data_gen , steps_per_epoch = np . ceil ( len ( train_data ) / batch_size ), epochs = 5 , validation_data = validation_data_gen , validation_steps = np . ceil ( len ( validation_data ) / batch_size ), verbose = 1 , callbacks = [ tboard ]) Epoch 1/5 18891/18891 [==============================] - 13359s 707ms/step - loss: 0.0221 - custom_score: 0.6035 - check_nonzero: 26.4339 - val_loss: 0.0066 - val_custom_score: 0.8510 - val_check_nonzero: 34.5274 Epoch 2/5 18891/18891 [==============================] - 6789s 359ms/step - loss: 0.0065 - custom_score: 0.8494 - check_nonzero: 34.3188 - val_loss: 0.0045 - val_custom_score: 0.8968 - val_check_nonzero: 35.6263 Epoch 3/5 18891/18891 [==============================] - 6793s 360ms/step - loss: 0.0052 - custom_score: 0.8778 - check_nonzero: 35.0802 - val_loss: 0.0039 - val_custom_score: 0.9105 - val_check_nonzero: 35.9709 Epoch 4/5 18891/18891 [==============================] - 6924s 367ms/step - loss: 0.0046 - custom_score: 0.8906 - check_nonzero: 35.3497 - val_loss: 0.0036 - val_custom_score: 0.9171 - val_check_nonzero: 36.2400 Epoch 5/5 18891/18891 [==============================] - 6511s 345ms/step - loss: 0.0043 - custom_score: 0.8974 - check_nonzero: 35.4717 - val_loss: 0.0034 - val_custom_score: 0.9207 - val_check_nonzero: 36.1354 Training Analysis - It can be seen that the loss is decreasing consistently across epochs. The custom_score keeps getting better. The custom_score and loss on validation dataset is comparable with training phase which indicates that the model is not overfitting. Investigating Attention Mechanism - In order to gain more insights on how our model is training, let us perform a quick analysis of how model is estimated weights and which words are actually being paid attention to while predicting multilabel classes. To facilitate this analysis, we have tapped our original models to spit out attention weighted activations. Based on these activations, we can back trace the word in the input which are influencing the final decision. Without much further a do, lets jump into the implementation !! In [52]: sugg_num = 190 tokenized_sentences = sent_tokenize ( validation_data [ 'cleaned_text' ] . iloc [ sugg_num ]) true_labels = validation_data [[ 'l1' , 'l2' , 'l3' ]] . iloc [ sugg_num ] . values print ( \"True labels are %s \" % true_labels ) for sent_num in range ( len ( tokenized_sentences )): word_attention_vector = word_attention_model . predict ( val_data_np [ sugg_num : sugg_num + 1 , sent_num , :])[ 0 ][:, 0 ] sorted_indices = np . argsort ( word_attention_vector )[:: - 1 ] sorted_weights = np . sort ( word_attention_vector )[:: - 1 ] tokenized_words = word_tokenize ( tokenized_sentences [ sent_num ]) padded_tokenized_words = tokenized_words + [ '<dummy>' ] * ( max_sent_len - len ( tokenized_words )) top_words = itemgetter ( * sorted_indices )( padded_tokenized_words ) short_listed_words = [( word , attention_weight ) for word , attention_weight in zip ( top_words , sorted_weights ) if attention_weight > 0.15 ] print ( \"Sentence is \\n %s \" % tokenized_sentences [sent_num]) print ( \"Focused words are \\n %s \" % short_listed_words ) print ( \"*************************************************\" ) True labels are [u'Event' u'SportsEvent' u'WrestlingEvent'] Sentence is professional wrestling hardcore heaven event held philadelphia pennsylvania united statesbased professional wrestling promotion eastern championship wrestlingextreme championship wrestling annually 1994 1995 1996 1997 1999 2000. Focused words are [(u'wrestling', 0.22687979), (u'event', 0.22041698), (u'wrestling', 0.178191)] ************************************************* Sentence is 1997 1999 2000 iteration hardcore heaven aired payperview . Focused words are [(u'iteration', 0.27779353), (u'aired', 0.27136996)] ************************************************* Sentence is footage six hardcore heaven event owned wwe . Focused words are [(u'footage', 0.3976578), (u'event', 0.36673942)] ************************************************* Results and Final Comments - VOILA !!! We can now trace the path of how the model is reaching its decision. As seen from the output printed on the console, the input text is describing a wrestling event. The model is iterating over different sentences and words with more \"Attention\" are being printed. The model is able to correctly assign weights in each word which is indicative of wrestling despite having other words like philadelphia, pennsylvania, and unites states which hints towards \"Place\" as a potential label. By assigning a lower weights to words that are not so important in the overall context of the document, the model is more robust and accurate. Final Comments - To scope down the problem statement, the output sequence in our problem definition has a size 1. Hence it suffices to ignore the previous decoder states while estimating attentions at time t. In other words, $T_y$ in our case is 1 which largely simplifies the implementation. The code will change if we are tasked with a use case that involves a temporal output. In such a situation, we will have to account for previous decoder states while estimating attentions. Finally, this article covers a lot of new concepts viz. - a. Formulation of Multilabel classification b. Attention Mechanism c. Hierarchical Attention Network d. Loss function and Activations for multilabel classification problem e. custom loss function. Some of these may not be easy to digest. Feel free to reach out to me if you have any queries or would like to brainstorm ideas. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Deep Learning","loc":"/multilabel text classification.html","title":"Hierarchical Attention Network For Multilabel Classification (Detailed Case study)"},{"url":"/Proving Convexity of Mean Squared Error Loss in a Regression Setting..html","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ Proving Convexity of Mean Squared Error Loss - Case Study In this blog post, we shall quickly cover the convexity proof for Mean Squared Error Loss function used in a traditional Regression setting. In case you haven't checked out my previous blog - The Curious Case of Convex Functions , I would highly recommend you to check it out. The blog focuses on all the basic building blocks for proving convexity. With that in mind, let us start by reviewing - The MSE loss for a Regression Algorithm. Conditions for checking Convexity. 1. MSE Loss Function - The MSE loss function in a Regression setting is defined as - $$ \\begin{align} J(W) = \\frac{1}{2m}\\sum_{i=1}&#94;{m} [y&#94;{(i)} - \\hat{y}&#94;{(i)}]&#94;2 \\tag{1} \\end{align} $$ Where, m = number of training examples. $J(w)$ = Loss as a function of Regression Coeffients. $y&#94;{(i)}$ = true value for the $ith$ training example. $\\hat{y}&#94;{(i)}$ = predicted value for the $ith$ training example. For $ith$ training example, $\\hat{y}&#94;{(i)}$ is defined as - $$ \\begin{align} \\hat{y}&#94;{(i)} = \\sum_{j = 1}&#94;{n}(w_jx_{j}&#94;{(i)} ) \\tag{2} \\end{align} $$ Where, n = number of features. For the sake of convenience/readability, let's assume n = 3 . The eq.(2) can thus be written as - $$ \\begin{align} \\hat{y}&#94;{(i)} &= \\sum_{j = 1}&#94;{n}(w_jx_{j}&#94;{(i)} ) \\\\ & = w_1x_{1}&#94;{(i)} + w_2x_{2}&#94;{(i)} + w_3x_{3}&#94;{(i)} \\tag{3} \\end{align} $$ Since we have considered only one training example, we can let go of the training index. $$ \\begin{align} \\therefore J(W) = \\frac{1}{2} [y - (w_1x_{1} + w_2x_{2} + w_3x_{3})]&#94;2 \\tag{4} \\end{align} $$ 2. Checking for Convexity of J(W)- For checking the convexity of Mean-Squared-Error function, we shall perform the following checks - Step 1 - Computing the Hessian of J(W) Step 2- Computing the Principal Minors of the Hessian. Step 3 - Based on the values of principal minors, determine the definiteness of Hessian. Step 4 - Comment on Convexity based on convexity tests. Let us get down to it right away- Step 1 - Hessian of $J(w)$ - $$ \\begin{align} J&#94;H = \\begin{bmatrix} \\frac{\\partial &#94;2 J}{\\partial w_1&#94;2} & \\frac{\\partial&#94;2 J}{\\partial w_1 \\partial w_2} & \\frac{\\partial&#94;2 J}{\\partial w_1 \\partial w_3} & \\\\ \\frac{\\partial &#94;2 J}{\\partial w_2 \\partial w_1} & \\frac{\\partial&#94;2 J}{\\partial {w_2}&#94;2 } & \\frac{\\partial&#94;2 J}{\\partial w_2 \\partial w_3} \\\\ \\frac{\\partial &#94;2 J}{\\partial w_3 \\partial w_1} & \\frac{\\partial&#94;2 J}{\\partial w_3 \\partial w_2 } & \\frac{\\partial&#94;2 J}{\\partial {w_3}&#94;2 } \\\\ \\end{bmatrix} \\end{align} $$ Lets compute each component of the matrix. $$ \\begin{align} \\frac{\\partial &#94;2 J}{\\partial w_1&#94;2} &= \\frac{\\partial}{\\partial w_1} \\big[ \\frac{\\partial}{\\partial w_1}\\big[\\frac{1}{2} [y - (w_1x_{1} + w_2x_{2} + w_3x_{3})]&#94;2\\big] \\big] \\\\ &= \\frac{\\partial}{\\partial w_1} [y - (w_1x_{1} + w_2x_{2} + w_3x_{3})](-x_1) \\\\ &= (-x_1)(-x_1) \\\\ &= (x_1)&#94;2 \\end{align} $$$$ \\begin{align} \\frac{\\partial &#94;2 J}{\\partial w_1w_2} &= \\frac{\\partial}{\\partial w_1} \\big[ \\frac{\\partial}{\\partial w_2}\\big[\\frac{1}{2} [y - (w_1x_{1} + w_2x_{2} + w_3x_{3})]&#94;2\\big] \\big] \\\\ &= \\frac{\\partial}{\\partial w_1}[y - (w_1x_{1} + w_2x_{2} + w_3x_{3})](-x_2) \\\\ & = (-x_2)(-x_1) \\\\ & = x_1x_2 \\\\ &= \\frac{\\partial &#94;2 J}{w_2w_1} \\end{align} $$ Similarly, it can be proven that - $$ \\begin{align} \\frac{\\partial &#94;2 J}{\\partial w_1w_3} = \\frac{\\partial &#94;2 J}{\\partial w_3w_1} = x_1x_3 \\\\ \\frac{\\partial &#94;2 J}{\\partial w_2w_3} = \\frac{\\partial &#94;2 J}{\\partial w_3w_2} = x_2x_3 \\\\ \\end{align} $$$$ \\begin{align} \\frac{\\partial &#94;2 J}{\\partial w_2&#94;2} = x_2&#94;2 \\\\ \\frac{\\partial &#94;2 J}{\\partial w_3&#94;2} = x_3&#94;2 \\end{align} $$$$ \\begin{align} \\therefore J&#94;H = \\begin{bmatrix} x_1&#94;2 & x_1x_2 & x_1x_3 & \\\\ x_2x_1 & x_2&#94;2 & x_2x_3 \\\\ x_3x_1 & x_3x_2 & x_3&#94;2 \\\\ \\end{bmatrix} \\end{align} $$ Step 2 - Computing the Principal Minors - From previous blog post , a function is convex if all the principal minors are greater than or equal to zero i.e. $\\bigtriangleup_k$ $\\geq 0 \\;\\; \\forall$ k . compute $\\bigtriangleup_1$ - Principal Minors of order 1 ($\\bigtriangleup_1$) can be obtained by deleting any 3-1 = 2 rows and corresponding columns. a. By deleting row 2 and 3 along with corresponding columns $ \\bigtriangleup_1 $ = x_1&#94;2 b. By deleting row 1 and 3 along with corresponding columns $ \\bigtriangleup_1 $ = x_2&#94;2 c. By deleting row 1 and 2 along with corresponding columns $ \\bigtriangleup_1 $ = x_3&#94;2 compute $\\bigtriangleup_2$ - Principal Minors of order 2 can be obtained by deleting any 3-2 = 1 row and corresponding column. a. By deleting row 1 and corresponding column 1 - $$ \\begin{align} \\bigtriangleup_2 & = \\begin{vmatrix} x_2&#94;2 & x_2x_3 \\\\ x_3x_2 & x_3&#94;2 \\end{vmatrix} \\\\ & = x_2&#94;2x_3&#94;2 - (x_2x_3)(x_3x_2) \\\\ & = x_2&#94;2x_3&#94;2 - x_2&#94;2x_3&#94;2 \\\\ & = 0 \\end{align} $$ b. By deleting row 2 and corresponding column 2 $$ \\begin{align} \\bigtriangleup_2 & = \\begin{vmatrix} x_1&#94;2 & x_1x_3 \\\\ x_3x_1 & x_3&#94;2 \\end{vmatrix} \\\\ & = x_1&#94;2x_3&#94;2 - (x_1x_3)(x_3x_1) \\\\ & = x_1&#94;2x_3&#94;2 - x_1&#94;2x_3&#94;2 \\\\ & = 0 \\end{align} $$ c. By deleting row 3 and corresponding column 3 $$ \\begin{align} \\bigtriangleup_2 & = \\begin{vmatrix} x_1&#94;2 & x_1x_2 \\\\ x_2x_1 & x_2&#94;2 \\end{vmatrix} \\\\ & = x_1&#94;2x_2&#94;2 - (x_1x_2)(x_2x_1) \\\\ & = x_1&#94;2x_2&#94;2 - x_1&#94;2x_2&#94;2 \\\\ & = 0 \\end{align} $$ compute $\\bigtriangleup_3$ - Principal Minors of order 3 can be obtained by computing determinant of J(W). $$ \\begin{align} \\bigtriangleup_3 & = \\begin{vmatrix}J&#94;H \\end{vmatrix} \\\\ &= \\begin{vmatrix} x_1&#94;2 & x_1x_2 & x_1x_3 & \\\\ x_2x_1 & x_2&#94;2 & x_2x_3 \\\\ x_3x_1 & x_3x_2 & x_3&#94;2 \\\\ \\end{vmatrix}\\\\ &= x_1&#94;2 * (x_2&#94;2x_3&#94;2 - x_2&#94;2x_3&#94;2) - x_1x_2 * (x_1x_2x_3&#94;2 - x_1x_2x_3&#94;2) + x_1x_3(x_1x_2&#94;2x_3 - x_1x_2&#94;2x_3) \\\\ &= 0 \\end{align} $$ Step 3 - Comment on Definiteness of Hessian of J(w) - The principal minors of order 1 have a squared form. We know that a squared function is always positive. The principal minors of order 2 and 3 are equal zero. It can be concluded that $\\bigtriangleup_k \\geq 0 \\;\\; \\forall k$ Hence the Hessian of J(w) is Positive Semidefinite. Step 4 Comment on convexity - Before we comment on the convexity of J(W), let's revise the conditions for convexity - If $X&#94;H$ is the Hessian Matrix of f(x) then - f(x) is strictly convex in $S$ if $X&#94;H$ is a Postive Definite Matrix. f(x) is convex in $S$ if $X&#94;H$ is a Postive Semi-Definite Matrix. f(x) is strictly concave in $S$ if $X&#94;H$ is a Negative Definite Matrix. f(x) is concave in $S$ if $X&#94;H$ is a Negative Semi-Definite Matrix. Since the Hessian of J(w) is Positive Semidefinite, it can be concluded that the function J(w) is convex. Final Comments - This blog post is aimed at proving the convexity of MSE loss function in a Regression setting by simplifying the problem. There are different ways of proving the convexity but I found this easier to comprehend. Feel free to try out the process for different loss functions that you may have encountered. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Linear Algebra","loc":"/Proving Convexity of Mean Squared Error Loss in a Regression Setting..html","title":"Proving Convexity of Mean Squared Error Loss in a Regression Setting."},{"url":"/The Curious Case of Convex Functions.html","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ The Curious Case of Convex Functions Most of the introductory courses for Machine Learning cover algorithms like Linear Regression and Logistic Regression with varying degrees of detail. The resources are plentiful for grasping the nitty gitties involved. However, I rarely found traditional courses diving into proving the convexity of MSE loss function. Most of the online resources often skim through the part where they define the cost function for Regression Algorithms using MSE where the cost function is claimed to be a convex function. The convexity property unlocks a crucial advantage where the local minima of a convex function is also a global minima. This ensures that a model can be trained where the loss function is minimized to its globally minimum value. Proving Convexity - In this blog post, we shall work through the concepts needed to prove the convexity of a function. So hang in tight and by the end of this article, you would have a better understanding of - a. Symmetric Matrices. b. Hessian Matrices. c. Postive and Negative Definite/Semidefinite Matrices. d. Proving convexity of functions. Without much further ado, let's jump into it. Basics of Matrices - We shall touch base on some of the basic concepts in Matrices that will help us in proving the convexity of a function. These basics are typically covered in Undergraduate Courses and should sound familiar to you. 1. Square Matrix - Given a matrix X of dimensions $m \\times n$, X is a square matrix iff (if and only if) m = n. In other words, A matrix 'X' is called a square matrix if the number of matrix rows is equal to the number of columns. $$ \\begin{align} X = \\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 8 & 9 & 10 \\end{bmatrix}_{3 \\times 3} \\end{align} $$ In the above example, since the number of rows (m) = number of columns (3), X can be termed as a square matrix. In [108]: ## basic python imports import numpy as np from IPython.core.display import display , HTML from sklearn.datasets import make_spd_matrix display ( HTML ( '<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>' )) display ( HTML ( \"<style>.container { width:100% !important; }</style>\" )) .prompt{width: 0px; min-width: 0px; visibility: collapse} .container { width:100% !important; } In [109]: ### python function for checking whether a matrix is a square matrix. def check_square_matrix ( X ): if X . shape [ 0 ] == X . shape [ 1 ]: return True else : return False A = np . random . randn ( 3 , 3 ) B = np . random . randn ( 4 , 5 ) print ( \"Is Matrix A a Square Matrix: - {0}\" . format ( check_square_matrix ( A ))) print ( \"Is Matrix B a Square Matrix - {0}\" . format ( check_square_matrix ( B ))) Is Matrix A a Square Matrix: - True Is Matrix B a Square Matrix - False 2. Symmetric Matrix - A square matrix 'X' is termed as symmetric if $x_{ij} = x_{ji}$ for all i and j where i, j denotes the ith row and jth column respectively. In other words, a matrix X is syemmetric if the transpose of X if equal to matrix X. i.e, $$ \\begin{align} X&#94;T = X \\end{align} $$ In [110]: ## function for checking if a matrix is symmetric def check_symmetry ( X ): if check_square_matrix ( X ): if ( X . transpose () == X ) . all (): return \"is a Symmetric Matrix\" else : return \"not a Symmetric Matrix\" else : return \"not a Symmetric Matrix since it is not Square Matrix\" In [111]: ## pseudo generate a symmetric matrix base_matrix = np . random . randint ( 20 , size = ( 3 , 3 )) SA = ( base_matrix + base_matrix . T ) print \"Matrix A - \\n {0}\" . format ( np . matrix ( SA )) ## generate a random matrix SB = np . random . randint ( 20 , size = ( 3 , 3 )) print \"Matrix B - \\n {0}\" . format ( SB ) SC = np . random . randint ( 20 , size = ( 2 , 10 )) print \"Matrix C - \\n {0}\" . format ( SC ) Matrix A - [[34 16 12] [16 10 21] [12 21 18]] Matrix B - [[19 2 18] [15 3 17] [ 8 15 17]] Matrix C - [[ 0 4 8 0 6 6 4 9 8 0] [ 0 1 9 17 6 0 6 8 9 8]] In [112]: print ( \"Is Matrix A {0}\" . format ( check_symmetry ( SA ))) print ( \"Is Matrix B {0}\" . format ( check_symmetry ( SB ))) print ( \"Is Matrix C {0}\" . format ( check_symmetry ( SC ))) Is Matrix A is a Symmetric Matrix Is Matrix B not a Symmetric Matrix Is Matrix C not a Symmetric Matrix since it is not Square Matrix 3. Hermitian Matrix - A square matrix X is self-adjoint or a Hermitian matrix if - $$ \\begin{align} \\overline{X&#94;{T}} = X = X&#94;{H} \\end{align} $$ Note that the terms self-adjoint and Hermitian can be used interchangeably . In [113]: def check_hermitian ( X ): if check_square_matrix ( X ): if ( np . conjugate ( X . transpose ()) == X ) . all (): return \"is a Hermitian Matrix\" else : return \"is not a Hermitian Matrix\" else : return \"is not a Hermitian Matrix since it is not a Square Matrix\" In [114]: ## pseudo generate a symmetric matrix ##generate a random complex matrix with entries between -20 and 10. base_matrix = np . random . randint ( - 10 , 10 , size = ( 3 , 3 )) + 1j * np . random . randint ( - 20 , 10 , size = ( 3 , 3 )) ## trick to force symmetric nature HA = ( base_matrix + np . conjugate ( base_matrix . T )) print \"Matrix A - \\n {0}\" . format ( np . matrix ( HA )) ## generate a random complex matrix that is not symmetric HB = np . random . randint ( - 10 , 10 , size = ( 3 , 3 )) + 1j * np . random . randint ( - 20 , 10 , size = ( 3 , 3 )) print \"Matrix B - \\n {0}\" . format ( HB ) HC = np . random . randint ( - 10 , 10 , size = ( 5 , 2 )) + 1j * np . random . randint ( - 20 , 10 , size = ( 5 , 2 )) print \"Matrix C - \\n {0}\" . format ( HC ) Matrix A - [[-16. +0.j -5. -8.j -4.+20.j] [ -5. +8.j 18. +0.j -4.-10.j] [ -4.-20.j -4.+10.j 18. +0.j]] Matrix B - [[-10. -7.j 2. +6.j -3.-10.j] [ 0.-20.j 2. -9.j 2. -9.j] [ 3. -4.j 4.-19.j 3. -1.j]] Matrix C - [[ -6. -4.j 2. +1.j] [ 1. +9.j 5.-19.j] [ 9.-16.j 7. -3.j] [ 3.-12.j -10. +3.j] [ 0. -1.j -4. +0.j]] In [115]: print ( \"Is Matrix A {0}\" . format ( check_hermitian ( HA ))) print ( \"Is Matrix B {0}\" . format ( check_hermitian ( HB ))) print ( \"Is Matrix C {0}\" . format ( check_hermitian ( HC ))) Is Matrix A is a Hermitian Matrix Is Matrix B is not a Hermitian Matrix Is Matrix C is not a Hermitian Matrix since it is not a Square Matrix 4. Hessian Matrix - The Hessian of a multivariate function $f(x_1, x_2, ...x_n)$ is a way for organizing second-order partial derivatives in the form of a matrix. Consider a multivariate fucntion $ f(x_1, x_2, ...x_n) $ then its Hessian can be defined as follows - $$ \\begin{align} H_f = \\begin{bmatrix} \\frac{\\partial &#94;2 f}{\\partial x_1&#94;2} & \\frac{\\partial&#94;2 f}{\\partial x_1 \\partial x_2} & \\cdots & \\frac{\\partial &#94;2 f}{\\partial x_1 \\partial x_n} \\\\ \\frac{\\partial &#94;2 f}{\\partial x_2 \\partial x_1} & \\frac{\\partial&#94;2 f}{\\partial {x_2}&#94;2 } & \\cdots & \\frac{\\partial&#94;2 f}{\\partial x_2 \\partial x_n} \\\\ \\vdots & \\ddots & \\cdots & \\vdots\\\\ \\frac{\\partial &#94;2 f}{\\partial x_n \\partial x_1} & \\frac{\\partial&#94;2 f}{\\partial x_n \\partial x_2 } & \\cdots & \\frac{\\partial&#94;2 f}{\\partial {x_n}&#94;2 } \\\\ \\end{bmatrix} \\end{align} $$ Note that a Hessian matrix by definition is a Square and Symmetric matrix. 5. Positive Definite and Semidefinte Matrices - You may have seen references about these matrices at multiple places but the definition and ways to prove definitiveness remains elusive to many. Let us start with the text definition - \\begin{align} A \\; n \\times n \\; square \\; matrix \\; X \\; is \\; Postive \\; Definite \\; if \\;\\;\\; a&#94;TXa \\; > \\; 0 \\; \\forall a \\; \\in \\; \\mathbb R&#94;n. \\end{align} Similarly, \\begin{align} A \\; n \\times n \\; square \\; matrix \\; X \\; is \\; Postive \\; Semidefinite \\; if \\;\\; a&#94;TXa \\geq 0 \\; \\forall \\; a \\in \\; \\mathbb R&#94;n. \\end{align} The same logic can be easily extended to Negative Definite and Negative Semidefinite matrices. \\begin{align} A \\; n \\times n \\; square \\; matrix \\; X \\; is \\; Negative \\; Definite \\; if \\;\\; a&#94;TXa \\; < \\; 0 \\; \\forall a \\; \\in \\; \\mathbb R&#94;n. \\end{align} And finally, \\begin{align} A \\; n \\times n \\; square \\; matrix \\; X \\; is \\; Negative \\; Semidefinite \\; if \\;\\; a&#94;TXa \\leq 0 \\; \\forall \\; a \\in \\; \\mathbb R&#94;n. \\end{align} However, while checking for Matrix Definiteness, manually validating the condition of every value of x is definitely not an option. So let us try and break this down even further. Eigen Values and Eigen Vector - We know that an eigenvector is a vector whose direction remains unchanged when a linear transformation is applied to it. Mathematically, $$ \\begin{align} Xa = \\lambda a \\tag{1} \\end{align} $$ Where, $\\lambda $ represents a scalar called the eigenvalue. This simply means that the linear transformation X on a can be completely defined by $\\lambda $. pre-multiplying eq.(1) by $a&#94;T$ gives - $$ \\begin{align} a&#94;TXa = a&#94;T \\lambda a \\tag{2} \\end{align} $$ since $\\lambda $ in eq.(2) is a scalar we can write eq.(2) as - $$ \\begin{align} a&#94;TXa = \\lambda a&#94;T a = \\lambda <a, a> \\tag{3} \\end{align} $$ where, $<x, y>$ represent the dot product, $x&#94;Ty$ Analysis It is easy to see that the dot product of a with $a&#94;T$ will always be positive. Referring back to the definition of positive definite matrix and eq(3), $a&#94;TXa$ can be greater than zero if and only if $\\lambda$ is greater than zero. Derived Definition for Matrix Definiteness - Based on pointers mentioned in above Analysis we can tweak the formal definitions of Matrix Definiteness as follows - A Symmetric Matrix 'X' is Positive Definite if $\\lambda_{i} > \\; 0 \\;\\; \\forall i$ A Symmetric Matrix 'X' is Positive Semi-Definite if $\\lambda_{i} \\geq \\; 0 \\;\\; \\forall i$ A Symmetric Matrix 'X' is Negative Definite if $\\lambda_{i} < \\; 0 \\;\\; \\forall i$ A Symmetric Matrix 'X' is Negative Semi-Definite if $\\lambda_{i} \\leq \\; 0 \\;\\; \\forall i$ In [116]: ### computing eigen values in python - def compute_eigen_values ( X ): eigen_values = np . linalg . eigvals ( X ) return eigen_values def check_definiteness ( eigen_values ): if ( eigen_values > 0 ) . all (): return \"Matrix is Postive Definite as well as Positive Semidefinite\" elif ( eigen_values >= 0 ) . all (): return \"Matrix is Postive Semi Definite only\" elif ( eigen_values < 0 ) . all (): return \"Matrix is Negative Definite as well as Negative Semidefinite\" elif ( eigen_values <= 0 ) . all (): return \"Matrix is Negative SemiDefinite\" else : return \"Matrix is neither positive definite nor negative definite\" base_eig_matrix = make_spd_matrix ( 3 ) EA = base_eig_matrix + base_eig_matrix . transpose () ea_eigen_values = compute_eigen_values ( EA ) print \"Eigen values are %s \" % ea_eigen_values print check_definiteness ( ea_eigen_values ) Eigen values are [6.54206241 0.08543726 0.82923445] Matrix is Postive Definite as well as Positive Semidefinite Alternate Definition for Dtermining Matrix Defniteness - Computing Eigen values for large matrices often involves solving linear equations. Large Matrices will will involve solving linear equations in large number of variables. Hence, It may not always to be feasible to solve for Eigen Values. An Alternate Theorem for Determing Defniteness of Matrices comes to the rescue - Theorem - A Symmetric Matrix 'X' is Positive Definite if $D_k > \\; 0 \\;\\; \\forall k$ Where, $D_k$ represents the kth Leading Principal Minor. A Symmetric Matrix 'X' is Positive Semi-Definite if $\\bigtriangleup_k \\geq \\; 0 \\;\\; \\forall k$ Where, $\\bigtriangleup_k$ represents the kth Principal Minor. A Symmetric Matrix 'X' is Negative Definite if $D_k < \\; 0 \\;\\; \\forall k$ Where, $D_k$ represents the kth Leading Principal Minor. A Symmetric Matrix 'X' is Negative Semi-Definite if $\\bigtriangleup_k \\leq \\; 0 \\;\\; \\forall k$ Where, $\\bigtriangleup_k$ represents the kth Principal Minor. Principal Minors of a Matrix - For a Square Matrix X, a Pricipal Submatrix of order k is obtained by deleting any (n-k) rows and corresponding (n-k) columns. The determinant of such a Pricipal Submatrix is called as the Principal Minor of matrix X. Leading Principal Minors of a Matrix - For a Square Matrix X, a Leading Pricipal Submatrix of order k is obtained by deleting last (n-k) rows and corresponding (n-k) columns. The determinant of such a Leading Pricipal Submatrix is called as the Leading Principal Minor of matrix X. Proving / Checking Convexity of a function - With all the relevant definitions and theorem covered in previous sections, we are now ready to define checks for determining the convexity of functions. A function f(x) defined over n variables on an open convex set $S$ can be tested for convexity using following criteria - If $X&#94;H$ is the Hessian Matrix of f(x) then - f(x) is strictly convex in $S$ if $X&#94;H$ is a Postive Definite Matrix. f(x) is convex in $S$ if $X&#94;H$ is a Postive Semi-Definite Matrix. f(x) is strictly concave in $S$ if $X&#94;H$ is a Negative Definite Matrix. f(x) is concave in $S$ if $X&#94;H$ is a Negative Semi-Definite Matrix. Example - Consider an equation of Quadratic form - $$ \\begin{align} f(x_1, x_2, x_3) = 5x_1&#94;2 - 2x_1x_2 + 2x_2&#94;2 + x_3x_2 + x_3&#94;2 \\end{align} $$ STEP 1 - Computing the Hessian The Hessian of $f(x_1, x_2, x_3)$ can be defined as follows - $$ \\begin{align} X&#94;H = \\begin{bmatrix} \\frac{\\partial{f&#94;2}}{\\partial{x_1&#94;2}} & \\frac{\\partial{f&#94;2}}{\\partial{x_1x_2}} & \\frac{\\partial{f&#94;2}}{\\partial{x_1x_3}} \\\\ \\frac{\\partial{f&#94;2}}{\\partial{x_2x_1}} & \\frac{\\partial{f&#94;2}}{\\partial{x_2&#94;2}} & \\frac{\\partial{f&#94;2}}{\\partial{x_2x_3}} \\\\ \\frac{\\partial{f&#94;2}}{\\partial{x_3x_1}} & \\frac{\\partial{f&#94;2}}{\\partial{x_3x_2}} & \\frac{\\partial{f&#94;2}}{\\partial{x_3&#94;2}} \\\\ \\end{bmatrix} \\end{align} $$ \\begin{align} \\\\ \\frac{\\partial{f&#94;2}}{\\partial{x_1&#94;2}} & = \\frac{\\partial{}}{\\partial{x_1&#94;2}}(5x_1&#94;2 - 2x_1x_2 + 2x_2&#94;2 + x_3x_2 + x_3&#94;2) \\\\ & = \\frac{\\partial{}}{\\partial{x_1}}(10x_1 -2x_2) \\\\ & = 10 \\end{align} Similarly, \\begin{align} \\\\ \\frac{\\partial{f&#94;2}}{\\partial{x_1x_2}} & = \\frac{\\partial{}}{\\partial{x_1x_2}}(5x_1&#94;2 - 2x_1x_2 + 2x_2&#94;2 + x_3x_2 + x_3&#94;2) \\\\ & = \\frac{\\partial{}}{\\partial{x_1}}(-2x1 + 4x_2 + 1) \\\\ & = -2 \\\\ & = \\frac{\\partial{f&#94;2}}{\\partial{x_2x_1}} \\end{align}\\begin{align} \\\\ \\frac{\\partial{f&#94;2}}{\\partial{x_1x_3}} & = \\frac{\\partial{}}{\\partial{x_1x_3}}(5x_1&#94;2 - 2x_1x_2 + 2x_2&#94;2 + x_3x_2 + x_3&#94;2) \\\\ & = \\frac{\\partial{}}{\\partial{x_1}}(1x_2 + 2x_3) \\\\ & = 0 \\\\ & = \\frac{\\partial{f&#94;2}}{\\partial{x_3x_1}} \\end{align}\\begin{align} \\\\ \\frac{\\partial{f&#94;2}}{\\partial{x_2&#94;2}} & = \\frac{\\partial{}}{\\partial{x_2&#94;2}}(5x_1&#94;2 - 2x_1x_2 + 2x_2&#94;2 + x_3x_2 + x_3&#94;2) \\\\ & = \\frac{\\partial{}}{\\partial{x_2}}(-2x_1 + 4x_2 + x_3) \\\\ & = 4 \\end{align}\\begin{align} \\\\ \\frac{\\partial{f&#94;2}}{\\partial{x_2x_3}} & = \\frac{\\partial{}}{\\partial{x_2x_3}}(5x_1&#94;2 - 2x_1x_2 + 2x_2&#94;2 + x_3x_2 + x_3&#94;2) \\\\ & = \\frac{\\partial{}}{\\partial{x2}}(x_2 + 2x_3) \\\\ & = 1 \\\\ & = \\frac{\\partial{f&#94;2}}{\\partial{x_3x_2}} \\end{align}\\begin{align} \\\\ \\frac{\\partial{f&#94;2}}{\\partial{x_3&#94;2}} & = \\frac{\\partial{}}{\\partial{x_3&#94;2}}(5x_1&#94;2 - 2x_1x_2 + 2x_2&#94;2 + x_3x_2 + x_3&#94;2) \\\\ & = \\frac{\\partial{}}{\\partial{x_3}}(x_2 + 2x_3) \\\\ & = 2 \\end{align}$$ \\begin{align} X&#94;H = \\begin{bmatrix}10 & -2 & 0 \\\\ -2 & 4 & 1 \\\\ 0 & 1 & 2\\end{bmatrix} \\end{align} $$ Step 2 - Compute Leading Principal Minors - for k = 3, delete last (3-3) =0 rows and (3-3) = 0 columns $$ \\begin{align} \\\\ D_{k} & = D_{3} \\\\ &= \\begin{vmatrix}10 & -2 & 0 \\\\ -2 & 4 & 1 \\\\ 0 & 1 & 2 \\\\ \\end{vmatrix} \\\\ & = 62 \\end{align} $$ for k = 2, delete last (3-2) =1 rows and corresponding (3-2) = 1 columns $$ \\begin{align} \\\\ D_{k} & = D_{2} \\\\ &= \\begin{vmatrix}10 & -2 \\\\ -2 & 4 \\\\ \\end{vmatrix} \\\\ & = 36 \\end{align} $$ for k = 1, delete last (3-1) =2 rows and corresponding (3-1) = 2 columns $$ \\begin{align} \\\\ D_{k} & = D_{1} \\\\ & = D_1 \\\\ &= \\begin{vmatrix}10 \\\\ \\end{vmatrix} \\\\ & = 10 \\end{align} $$ Since $D_1 > 0 $, $D_2 >0 $ and $D_3 > 0$, Hessian of $f(x_1, x_2, x_3)$ is Positive Definite. Step 3 - Comment on Convexity - Since Hessian of $f(x_1, x_2, x_3)$ is Positive Definite, the function is strictly convex. Properties of Convex functions - Constant functions of the form $f(x) = c$ are both convex and concave. $f(x) = x$ is both convex and concave. Functions of the form $f(x) = x&#94;r$ with $r \\geq 1$ are convex on the Interval $0 < x < \\infty$ Functions of the form $f(x) = x&#94;r$ with $0 < r < 1$ are concave on the Interval $0 < x < \\infty$ The function $f(x) = \\log{(x)}$ is concave on the interval $0 < x < \\infty$ The function $f(x) = e&#94;{x}$ is convex everywhere. If $f(x)$ is convex, then $g(x) = cf(x)$ is also convex for any positive value of c. If $f(x)$ and $g(x)$ are convex then their sum $h(x) = f(x) + g(x)$ is also convex. Final Comments - We have investigated convex functions in depth while studying different ways of proving convexity. In the next part of the article, we shall prove convexity of MSE loss function used in linear regression. Convex functions are easy to minimise thus resulting in its usage across research domains. So, the next time you want to plug in a different loss function in place of MSE while training a linear regression model, you might as well check its convexity. References - [1] Eigen Values and Eigen Vectors [2] Formal Definitions for Matrix Definiteness [3] Principal Minors and Hessian Matrix by Dr. Eivind Eriksen [4] Computing Minors and Cofactors [5] Properties of convex functions if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Linear Algebra","loc":"/The Curious Case of Convex Functions.html","title":"The Curious Case of Convex Functions"},{"url":"/Training Classifier Using PyTorch - Detailed Example..html","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ Training a Classifier using Pytorch As a part of \"Getting Acquainted with Deep Learning Frameworks\" series, in the article, we shall explore Pytorch Library. Pytorch is a deep learning library developed by Facebook Researchers. Pytorch consists of 3 important modules namely - Autograd Module - This module takes care of gradient computations. Optim Module - The optim module implements optimizer algorithms for building neural networks. NN Module - The NN module in PyTorch implements different layers necessary for building complex neural networks. In the following sections, lets over steps involved in building a multiclass classifier using Pytorch. In [1]: import os import sys import pandas as pd import numpy as np import torch import torch.nn.functional as F from torchvision import datasets , transforms from torch import nn , optim from IPython.core.display import display , HTML display ( HTML ( '<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>' )) display ( HTML ( \"<style>.container { width:100% !important; }</style>\" )) .prompt{width: 0px; min-width: 0px; visibility: collapse} .container { width:100% !important; } As always, it helps to come up with a road map before digging into the implementation aspects. We shall complete our goal of building and training a model using the following steps - Load Dataset Visualize some data Define a model Define loss Define optimizer Train a model Validate the model Loading dataset in PyTorch In this article, we shall be using the Fashion MNIST dataset which consists of 10 categories, viz. T-shirt/top Trouser Pullover Dress Coat Sandal Shirt Sneaker Bag Ankle boot. Let's kick off the implementation by loading the Fashion MNIST Dataset In [60]: ### loading dataset from pytorch data repository ### when you use the dataset for the first time, it will download the actual files. BATCH_SIZE = 32 data_transforms = transforms . Compose ([ transforms . ToTensor ()]) trainset = datasets . FashionMNIST ( '~/.pytorch/F_MNIST_data/' , download = True , train = True , transform = data_transforms ) training_data_loader = torch . utils . data . DataLoader ( trainset , batch_size = BATCH_SIZE , shuffle = True ) testset = datasets . FashionMNIST ( '~/.pytorch/F_MNIST_data/' , download = True , train = False , transform = data_transforms ) test_data_loader = torch . utils . data . DataLoader ( testset , batch_size = BATCH_SIZE , shuffle = True ) Data loading explained - We shall be loading the data using Compose and DataLoader classes from PyTorch's transforms and utils.data module respectively. We can load the supported datasets by providing the path where data exists. If the data is not available, set the 'download' argument as True. The API for loading dataset is quite straightforward and can be further explored here . The important point to note here is the use of a transform argument while loading the data. The transform argument is used to define a function that accepts a PIL image and returns a transformed tensor. For the sake of simplicity, I will not be applying any transformations to the input dataset. However, the DataLoader expects tensors and not PIL images at its input hence, we shall be applying a single transformation that simply transforms the PIL images to tensors for them to be converted into iterable by DataLoader. Note - All the datasets supported by PyTorch are implemented as subclasses of torch.utils.data.Dataset i.e, they have getitem and len methods implemented. Hence, they can all be passed to a torch.utils.data.DataLoader which can load multiple samples parallelly using torch.multiprocessing workers. Code Explanation - Based on the explanation provided above, let's review the code line by line - The first line defines the transformation that needs to be applied to our data. In this case, it is simply type-casting the input into tensors. The second line loads the dataset. Note that the transform defined in step 1 has been passed as an argument while loading data. The third line of code is responsible for converting the data into an iterator object so that we can train a model in batches. We have set the 'train' flag to True to return the training bits. By analogy, a test loader can be defined by setting the 'train' flag to False. The 'shuffle' flag is responsible for shuffling data after each training epoch. For more information on DataLoader, refer official documentation . While we are at it, lets quickly check the output of Dataloader. We will have to convert the output of DataLoader (iterable) into an iterator object. Check out this stackoverflow thread if you are confused between an iterable and an iterator. In [30]: itr = iter ( training_data_loader ) In [52]: sample_image_batch , sample_image_labels = next ( itr_val ) print ( \"Shape of sample batch is %s and shape of sample batch labels is %s \" % ( sample_image_batch . shape , sample_image_labels . shape )) Shape of sample batch is torch.Size([32, 1, 28, 28]) and shape of sample batch labels is torch.Size([32]) Now that we have our data ready, let's dig into defining and training a classification model. Building a model in PyTorch - Similar to Keras, torch provides us with a Sequential API where we can add modules/Layers to the container. The order in which layers are added to the container is important. It is important to keep track of dimensions while adding layers. All the layers - Linear (fully connected), Convolution, LSTMs, etc are available in torch.nn. torch.nn also provides access to different activation functions. It is imperative to choose activation functions based on the type of problem you are trying to solve. For example, for regression, the output activation function can be Relu whereas for binary classification it can sigmoid. For more information regarding the Sequential API checkout PyTorch's master documentation Data Specific Model - As seen above, each batch of our train data has a shape [batch_size, 1, 28, 28] which implies that there is only one channel with height and width of 28 and 28 respectively. In this article, let's keep things simple by using only Dense/ Linear/ Fully-connected layers. To use Dense layers, we need to reshape our training example to a tensor of shape $[batch_size, n_channels \\times width \\times height]$. In this case, it will be $1 \\times 28 \\times 28 = 784$. Thus each batch of input data can be reshaped to a size of [batch_size, 784]. Keeping in mind the dimensions from point 3, it is evident that our first Dense/Linear layer should have dimensions of 784 x $(n\\_units)_1$ where $(n\\_units)_1$ denotes the number of units in the first layer of the network. We shall be adding 2 more hidden layers with sizes 128 and 64 respectively. The last layer is the output layers consisting of 10 neurons which is equivalent to the number of classes in our dataset. In [40]: \"\"\" define a model \"\"\" classifier_model = nn . Sequential ( nn . Linear ( 784 , 256 ), nn . ReLU (), nn . Linear ( 256 , 128 ), nn . ReLU (), nn . Linear ( 128 , 64 ), nn . ReLU (), nn . Linear ( 64 , 10 ), nn . LogSoftmax ( dim = 1 )) Model Explanation - As seen above, we have added 4 fully connected layers to our model using Relu activation. Notice the activation function in the last layer - LogSoftmax. As the names suggest LogSoftmax takes the log of softmax function. Mathematically, $$Softmax = \\large \\frac{e&#94;{z}}{\\sum_{j = 1}&#94;{n\\_classes} e&#94;{z_j}}$$$$ \\therefore Log(Softmax) = \\log \\big[ \\large \\frac{e&#94;{z}}{\\sum_{j = 1}&#94;{n\\_classes} e&#94;{z_j}} \\big]$$$$ = \\log \\big[ e&#94;{z} \\bigl] - \\bigr[ \\sum_{j = 1}&#94;{n\\_classes} e&#94;{z_j} \\big]$$ People tend to prefer log-likelihood over likelihood functions for the following reasons - Log Likelihoods are more numerically stable since by taking a log, divisions are converted to subtractions. Log-Likelihood is less computationally expensive since exponential from the equations are eliminated. Lastly, Log-likelihood tends to punish bigger mistakes in log-likelihood space. Let's consider a case were your true class is 1 and your model estimates the probability of the true class is .9. If your loss function is the L1 Loss function, the value of the loss function is 0.1. On the other hand, if you are using the log-likelihood then the value of the loss function is 0.105 (assuming natural log). On the other hand, if your estimated probability is 0.3 and you are using the likelihood function the value of your loss function is 0.7. If you are using the log-likelihood function the value of your loss function is 1.20. Now if we consider these two cases, using the standard likelihood function (akin to softmax), the error increases by a factor of 7 (.7/.1) between those two examples. Using the log-likelihood function (akin to log-softmax) the error increases by a factor of ~11 (1.20/.105). The point is, even though log softmax and softmax are monotonic, their effect on the relative values of the loss function changes. For further deep dive into why likelihood are used, refer to this Stackoverflow thread. Also, notice the dim = 1 in the Pytorch Activation. It signifies that log softmax is to be computed across columns. Step 4 and 5 - In this section, we shall define a loss function and optimizer. Since this is a classification problem we shall be using a Negative log-likelihood function. You can choose to use CrossEntropyLoss() which internally takes the Logsoftmax and NLL. If you choose to use CrossEntropyLoss, make sure to use a Softmax() function in the output layer instead of LogSoftmax(). Read the master documentation here for more information. While defining an optimizer, PyTorch requires us to pass model parameters that are to be optimized. In [53]: ## define loss criterion = nn . NLLLoss () ## define optimizer optimizer = optim . Adam ( classifier_model . parameters (), lr = 0.003 ) The Fun Part Now, we get to the business end of the article. In this section, we shall train a classifier by iterating over mini-batches. For the sake of convenience, I have added comments to the code below so that each code block can be discussed in later sections. In [65]: epochs = 10 for e in range ( epochs ): ## code block 1 starts## running_loss = 0 train_accuracy = 0 ## code block 1 ends ## for images , labels in training_data_loader : ## code block 2 starts ## images = images . view ( BATCH_SIZE , - 1 ) ## code block 2 ends ## ## code block 3 starts ## optimizer . zero_grad () ## code block 3 ends ## ## code block 4 starts ## log_ps = classifier_model . forward ( images ) ## code block 4 ends ## ## code block 5 starts ## loss = criterion ( log_ps , labels ) ## code block 5 ends ## ## code block 6 starts ## ps = torch . exp ( log_ps ) top_p , top_class = ps . topk ( 1 , dim = 1 ) equals = top_class == labels . view ( * top_class . shape ) train_accuracy += torch . mean ( equals . type ( torch . FloatTensor )) ## code block 6 ends ## ## code block 7 starts ## loss . backward () ## code block 7 ends ## ## code block 8 starts ## optimizer . step () ## code block 8 ends ## running_loss += loss . item () else : test_loss = 0 test_accuracy = 0 # Turn off gradients for validation, saves memory and computations ## code block 9 starts ## with torch . no_grad (): ## code block 9 ends ## ## code block 10 starts ## classifier_model . eval () ## code block 10 ends ## for images , labels in test_data_loader : images = images . view ( len ( images ), - 1 ) log_ps = classifier_model . forward ( images ) test_loss += criterion ( log_ps , labels ) ps = torch . exp ( log_ps ) top_p , top_class = ps . topk ( 1 , dim = 1 ) equals = top_class == labels . view ( * top_class . shape ) test_accuracy += torch . mean ( equals . type ( torch . FloatTensor )) ## code block 11 starts ## classifier_model . train () ## code block 11 ends ## print ( \"Training loss: {0} , Train_Accuracy: {1} , \\ Test loss: {2} , Test Accuarcy: {3} \" . format ( running_loss / len ( training_data_loader ), train_accuracy / len ( training_data_loader ), test_loss / len ( test_data_loader ), test_accuracy / len ( test_data_loader ))) Training loss: 0.22853158619801203, Test_Accuracy: 0.9164999723434448, Test loss: 0.4568166136741638, Test Accuarcy: 0.8700079917907715 Training loss: 0.2272799943834543, Test_Accuracy: 0.9163333177566528, Test loss: 0.41424477100372314, Test Accuarcy: 0.877595841884613 Training loss: 0.22670600768327712, Test_Accuracy: 0.9175333380699158, Test loss: 0.37628260254859924, Test Accuarcy: 0.8856828808784485 Training loss: 0.22063465672135352, Test_Accuracy: 0.918316662311554, Test loss: 0.44326987862586975, Test Accuarcy: 0.8767971396446228 Training loss: 0.22119727455774943, Test_Accuracy: 0.9186333417892456, Test loss: 0.4482117295265198, Test Accuarcy: 0.8738019466400146 Training loss: 0.21561113123893738, Test_Accuracy: 0.9218999743461609, Test loss: 0.4552798569202423, Test Accuarcy: 0.8777955174446106 Training loss: 0.21721694296598434, Test_Accuracy: 0.9197999835014343, Test loss: 0.4298233091831207, Test Accuarcy: 0.8843849897384644 Training loss: 0.21643914391646782, Test_Accuracy: 0.921750009059906, Test loss: 0.4264931380748749, Test Accuarcy: 0.8882787823677063 Training loss: 0.21255102254152297, Test_Accuracy: 0.9224666953086853, Test loss: 0.4677496552467346, Test Accuarcy: 0.883286714553833 Training loss: 0.21463266763687133, Test_Accuracy: 0.9224166870117188, Test loss: 0.46781498193740845, Test Accuarcy: 0.8779951930046082 Code Explanation - code block 1 - In code block 1, we have simple initialized training_loss and training_accuracy to 0. This is done so that we can track progress while iterating over data min-batches. code block 2 - In code block 2, we have reshaped our input batch so that it matches the dimensions expected by our neural network model. Tensors can be reshaped in PyTorch by using the .view method. Note that for a tensor 't1' of shape (a, b, c), t1.view(a, b*c) is equivalent to t1.view(a, -1). code block 3 - In code block 3, we have simply clearing out the gradient values that may have been accumulated from previous iterations. code block 4 - In code 4, we pass the batch if images through the network. This is equivalent to a forward pass and can be implemented using the 'forward' method. code block 5 - After the forward pass, we need to compute the loss to implement backward propagation. The loss is computed by passing logits and true labels through the loss defined earlier. Final Comments - Hopefully, this article will help you to get started with PyTorch. I will try to cover more usecases, in upcoming articles. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Deep Learning","loc":"/Training Classifier Using PyTorch - Detailed Example..html","title":"Training Classifier Using PyTorch - Detailed Example."},{"url":"/Deep Neural Network for Multiclass Classification Using Keras..html","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ CIFAR-10 Image Classification using Keras With the increasing adoption of Deep Neural Nets for various machine learning tasks, acquaintance with different frameworks and tools for modeling complex machine learning problems is a must. In this series, we shall focus on building various architectures of DNN using different frameworks (TensorFlow /Keras, PyTorch, etc). The idea behind these articles is to familiarize with the syntax and good practices for building DNN models. Let's kick off the series with a Convolutional Neural Network model for classifying images using Keras. About the Dataset - To limit the training times, we shall be working with the Cifar-10 dataset which consists of images across 10 categories. These categories are birds, airplanes, cars, cats, deer, dogs, frogs, horses, ships, and trucks. Each category consists of 6000 images. For more details about the dataset, check out the official website . Let's start by importing the libraries needed for training the model. In [63]: import IPython import os import glob from operator import itemgetter import scipy.io import pandas as pd import numpy as np import keras.backend as K from keras.layers import ( Dense , Conv2D , Activation , Dropout , Input , MaxPooling2D , Flatten , BatchNormalization , LeakyReLU ) from keras.models import Model from keras import optimizers from keras.utils import plot_model from keras.utils.vis_utils import model_to_dot from keras import callbacks from keras import regularizers from keras.datasets import mnist from sklearn.utils import shuffle from sklearn.preprocessing import LabelBinarizer from sklearn.model_selection import train_test_split import matplotlib.pyplot as plt % matplotlib inline from IPython.core.display import display , HTML display ( HTML ( '<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>' )) display ( HTML ( \"<style>.container { width:100% !important; }</style>\" )) .prompt{width: 0px; min-width: 0px; visibility: collapse} .container { width:100% !important; } Before we jump into the implementation bits, it would be helpful to chalk out the roadmap for successfully building and training a Deep Neural Network. 1. Loading the data- First we shall implement the code for successfully reading the cifar-10 dataset. 2. Visualizing data- Visualizing different aspects of our data often helps us to understand the problem statement and underlying dataset better. This visualization step can be as detailed as one would like it to be. This includes performing Exploratory analysis, Outlier Analysis, Image Visualization, Class distribution, etc. Data Visualization and pre-processing steps are often under-rated but the analysis directly influences the choice of certain hyperparameters in your ML model. For instance, consider a dataset with severe class imbalance, say a 99:1 ratio. That is, for every 99 positive data points, we have 1 negative data point. Choosing accuracy as our evaluation metric will result in incorrect results. In such cases, a quick visualization of class distribution will help us choose better evaluation metrics. Perhaps, something like recall, F1 score, beta F1-score. 3. Preparing Data for Training, Validation and Prediction - Often, loading entire data set in memory is not efficient. Different Deep Learning frameworks offer various wrappers for loading datasets using generators. To gain better insights into how data batches should be generated, we shall implement a custom data generator. 4. Defining / Building the Model - In this section, we shall build the actual model. The focus of this section would be to familiarize ourselves with Keras syntax for adding complex layers. In this section, we shall also highlight good practices that can help our model to learn faster. 5. Visual the Model - Before we train the model, it often helps to visualize the neural network that has been implemented. This step also helps in debugging the issues that may have been embedded in our model unknowingly resulting in code errors. 6. Training the model - Once a model has been defined and data ready to be flown through it, the next logical step is to train the model. We shall train a model using training and validation data. 7. Predicting - DNN are known to overfit easily. It is often helpful to test the model for out of bag data points. This will help us understand how well the model generalizes on unseen data. 8. Trouble Shooting / FAQs In this last section, we shall focus on a few issues that one may encounter while training DNNs. I will keep updating this list to ensure that all the possible pitfalls are documented. Lets kick off implementation by writing some basic functions for loading the dataset In [64]: ### reading Labels file def unpickle ( file_name ): ''' Unpickles a pickled file. Args: file_name : absolute path of the file that needs to be unpickled. Returns: dict_val: python dictionary containing data and labels. eg - {'data': np.array, labels: np.array} ''' import cPickle with open ( file_name , 'rb' ) as fo : dict_val = cPickle . load ( fo ) return dict_val In [65]: ## read data def read_cifar_data ( parent_directory_wildcard ): ''' The cifar-10 dataset is available in part files and hence this fucntion will unpickle and concatenate the content of all the files in a directory Args: parent_directory_wildcard: folder_path where all the training data is present Return: raw_X: dataframe containing all the data available for training. raw_labels: dataframe containing corresponding labels for the training data. ''' raw_X = [] raw_labels = [] for filename in glob . glob ( parent_directory_wildcard ): dict_val = unpickle ( filename ) raw_X . extend ( dict_val [ 'data' ]) raw_labels . extend ( dict_val [ 'labels' ]) return raw_X , raw_labels Now thet we have our helper functions ready, lets load the entire dataset in pandas dataframe In [66]: raw_X , raw_labels = read_cifar_data ( './data/cifar10/cifar-10-python/cifar-10-batches-py/data_batch*' ) cifar_raw_data = pd . DataFrame ( zip ( raw_X , raw_labels ), columns = [ 'np_images' , 'labels' ]) print ( cifar_raw_data . head ()) np_images labels 0 [255, 252, 253, 250, 238, 233, 245, 241, 232, ... 1 1 [127, 126, 127, 127, 128, 128, 128, 128, 129, ... 8 2 [116, 64, 19, 29, 36, 40, 57, 143, 173, 83, 39... 5 3 [205, 213, 235, 232, 112, 98, 95, 80, 98, 224,... 1 4 [189, 184, 181, 186, 191, 177, 186, 167, 147, ... 5 Label Binarizer - It can be seen that for each training image, the labels are an integer. Before we train our classifier, we need to transform these categorical labels into one-hot encoded vectors. We shall achieve this using Sklearn's Label Binarizer. For more details on building intuition behind LabelBinarizer, check out toy examples on sklearn documentation page . In [67]: label_binarizer = LabelBinarizer () label_binarizer . fit ( cifar_raw_data [ 'labels' ] . unique ()) Out[67]: LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False) Now that we have trained our LabelBinarizer, lets quickly check out the unique classes encoded by the Binarizer. This is just a sanity check and can be skipped. In [68]: print ( \"Successfully trained a Binarizer with %d unique classes\" % len (label_binarizer.classes_)) Successfully trained a Binarizer with 10 unique classes Awesome !! We are now ready to move on to the step 2 of our blueprint - Data Visualization In [69]: def get_shuffled_data ( grouped_data , n = 5 ): shuffled_data = shuffle ( grouped_data ) . head ( n ) return shuffled_data In [70]: sampled_data = cifar_raw_data . groupby ( 'labels' , as_index = False ) . apply ( get_shuffled_data , 3 ) . reset_index ( drop = True ) In [71]: def generate_visualizations ( vis_df ): ## fix the height and width of the image to be displayed height , width = 20 , 5 # decide the number of images to be displayed from each category columns = 3 # Find the number of unique categories in the training dataset rows = vis_df [ 'labels' ] . nunique () fig , axes = plt . subplots ( nrows = rows , ncols = columns , figsize = ( width , height ), sharex = True , sharey = True ); labels = vis_df [ 'labels' ] . unique () for index in range (( columns * rows )): ax = fig . add_subplot ( rows , columns , index + 1 ) ax . axis ( 'off' ) ax . imshow ( vis_df [ 'np_images' ] . iloc [ index ] . reshape ( 3 , 32 , 32 ) . transpose ( 1 , 2 , 0 ) / 255. , interpolation = 'nearest' ) for ax , row in zip ( axes [:, 0 ], labels ): ax . set_ylabel ( row ) ax . set_yticks ([]) for ax , row in zip ( axes [ 0 , :], labels ): ax . set_xticks ([]) In [72]: generate_visualizations ( sampled_data ) Some Observations - It can be seen from above visualizations that the image quality is below par. By design, the categories are mutually exclusive however, things can get tricky for datasets with poor quality images and categories that are visually similar. On that note, let's move on to Step 3 - Preparing data for Training and Validation Since there is no class imbalance, let's keep the logic for splitting that dataset into training, test and validation fairly simple. We shall piggyback on sklearn's train_test_split function for accomplishing the task. It is important to note this particular function doesn't split data 3 ways and hence we shall be making a function call twice to further split the training data for model validation. For more information on sklearn's train_test_split function checkout their official documentation . In [74]: #### split raw_data into train, test and validation sets complete_train_data , test_data = train_test_split ( cifar_raw_data , test_size = 0.05 ) train_data , validation_data = train_test_split ( complete_train_data , test_size = 0.08 ) train_data = train_data . reset_index ( drop = True ) validation_data = validation_data . reset_index ( drop = True ) test_data = test_data . reset_index ( drop = True ) print ( \"Training data is of size %d \" % len (train_data)) print ( \"Validation data is of size %d \" % len (validation_data)) print ( \"Test data is of size %d \" % len (test_data)) Training data is of size 43700 Validation data is of size 3800 Test data is of size 2500 Now that we have our training, validation and test data set cut out, we would like our training process to be memory efficient. To implement mini-batch training, we shall leverage the concept of generators in python. To learn more about the difference between a generator and iterator in python, check out this blog post . For generating mini-batches of our data, we shall implement a generator function involving the following steps - Args: Pass original_dataframe, trained Label Binarizer model and batch_size as input arguments. We can easily make the function more scalable by loading the Label Binarizer model from the pickle file. However, I would like to keep it as simple as possible for the sake of this article. Initialize a counter variable. While True: --> Batch indices based on batch_size --> Slice dataset. --> yield data In [99]: def prep_training_generators ( train_df , label_binarizer_model , batch_size ): indices = range ( len ( train_df )) indx_iterator = 0 while True : if ( indx_iterator + 1 ) * batch_size > len ( indices ): indx_iterator = 0 np . random . shuffle ( indices ) batch_indices = indices [ indx_iterator * batch_size : ( indx_iterator + 1 ) * batch_size ] batch_x = np . stack ( train_df . loc [ batch_indices , 'np_images' ] . values , axis = 0 ) reshaped_batch_x = ( batch_x . reshape ( batch_size , 3 , 32 , 32 ) . transpose ( 0 , 2 , 3 , 1 )) / 255. raw_y = train_df . loc [ batch_indices , 'labels' ] . values batch_y = label_binarizer_model . transform ( raw_y ) indx_iterator += 1 yield reshaped_batch_x , batch_y We shall combine steps 4 and 5 in the next section - In this article, we will be building a model using Keras's Functional API. I prefer the Functional API since it allows us to define and build more flexible models with Keras. For more information regarding the difference and advantages of Functional API over Sequential API, refer to this blog post . Each layer of our neural network shall consist of following elements - Convolution2D layer. BatchNormalization. Activation Layer. MaxPooling2D Dropout Layer. The output layer shall consist of neurons equivalent to the number of unique classes. Note that, since this is a multiclass classification, categorical cross-entropy will be our choice of loss function. For Binary classification, one can use binary_crossentropy. Also, note the activation function in the output layer. Since we would like a probability vector at the output layers, we shall be using softmax function. With this basic building blocks in mind, feel free to experiment with the network architecture. In [119]: def keras_image_functional_model ( image_shape , n_classes ): \"\"\" More info on losses - https://keras.io/losses/ \"\"\" weight_decay = 1e-4 img_input = Input ( shape = image_shape ) img_emd = Conv2D ( 32 , ( 3 , 3 ), padding = 'same' , strides = 1 , kernel_regularizer = regularizers . l2 ( weight_decay ))( img_input ) img_emd = BatchNormalization ()( img_emd ) img_emd = LeakyReLU ( alpha = 0.2 )( img_emd ) img_emd = Dropout ( 0.2 )( img_emd ) img_emd = Conv2D ( 32 , ( 3 , 3 ), padding = 'same' , kernel_regularizer = regularizers . l2 ( weight_decay ))( img_emd ) img_emd = BatchNormalization ()( img_emd ) img_emd = LeakyReLU ( alpha = 0.2 )( img_emd ) img_emd = MaxPooling2D ()( img_emd ) img_emd = Dropout ( 0.2 )( img_emd ) img_emd = Conv2D ( 64 , ( 3 , 3 ), padding = 'same' , kernel_regularizer = regularizers . l2 ( weight_decay ))( img_emd ) img_emd = BatchNormalization ()( img_emd ) img_emd = LeakyReLU ( alpha = 0.2 )( img_emd ) img_emd = MaxPooling2D ()( img_emd ) img_emd = Dropout ( 0.2 )( img_emd ) img_emd = Flatten ()( img_emd ) img_emd = Dense ( 512 , kernel_regularizer = regularizers . l2 ( weight_decay ))( img_emd ) img_emd = BatchNormalization ()( img_emd ) img_emd = Activation ( 'relu' )( img_emd ) img_emd = Dense ( 128 , kernel_regularizer = regularizers . l2 ( weight_decay ))( img_emd ) img_emd = BatchNormalization ()( img_emd ) img_emd = Activation ( 'relu' )( img_emd ) out_logits = Dense ( n_classes , activation = 'softmax' )( img_emd ) model = Model ( inputs = img_input , outputs = out_logits , name = \"image_model\" ) model . summary ( line_length = 200 ) model . compile ( optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) return model In [120]: def plot_keras_model ( model_name , show_shapes_bool = True ): return IPython . display . SVG ( model_to_dot ( model_name , show_shapes = show_shapes_bool ) . create ( prog = 'dot' , format = 'svg' )) In [121]: BATCH_SIZE = 32 tboard = callbacks . TensorBoard ( log_dir = './logs' , histogram_freq = 0 , batch_size = 32 , write_graph = True , write_grads = False , write_images = False , embeddings_freq = 0 ) train_data_gen = prep_training_generators ( train_data , label_binarizer , BATCH_SIZE ) validation_data_gen = prep_training_generators ( validation_data , label_binarizer , BATCH_SIZE ) image_only_model = keras_image_functional_model ( image_shape = ( 32 , 32 , 3 ) , n_classes = 10 ) ________________________________________________________________________________________________________________________________________________________________________________________________________ Layer (type) Output Shape Param # ======================================================================================================================================================================================================== input_19 (InputLayer) (None, 32, 32, 3) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ conv2d_74 (Conv2D) (None, 32, 32, 32) 896 ________________________________________________________________________________________________________________________________________________________________________________________________________ batch_normalization_88 (BatchNormalization) (None, 32, 32, 32) 128 ________________________________________________________________________________________________________________________________________________________________________________________________________ leaky_re_lu_51 (LeakyReLU) (None, 32, 32, 32) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ dropout_74 (Dropout) (None, 32, 32, 32) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ conv2d_75 (Conv2D) (None, 32, 32, 32) 9248 ________________________________________________________________________________________________________________________________________________________________________________________________________ batch_normalization_89 (BatchNormalization) (None, 32, 32, 32) 128 ________________________________________________________________________________________________________________________________________________________________________________________________________ leaky_re_lu_52 (LeakyReLU) (None, 32, 32, 32) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ max_pooling2d_38 (MaxPooling2D) (None, 16, 16, 32) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ dropout_75 (Dropout) (None, 16, 16, 32) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ conv2d_76 (Conv2D) (None, 16, 16, 64) 18496 ________________________________________________________________________________________________________________________________________________________________________________________________________ batch_normalization_90 (BatchNormalization) (None, 16, 16, 64) 256 ________________________________________________________________________________________________________________________________________________________________________________________________________ leaky_re_lu_53 (LeakyReLU) (None, 16, 16, 64) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ max_pooling2d_39 (MaxPooling2D) (None, 8, 8, 64) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ dropout_76 (Dropout) (None, 8, 8, 64) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ flatten_19 (Flatten) (None, 4096) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ dense_37 (Dense) (None, 512) 2097664 ________________________________________________________________________________________________________________________________________________________________________________________________________ batch_normalization_91 (BatchNormalization) (None, 512) 2048 ________________________________________________________________________________________________________________________________________________________________________________________________________ activation_38 (Activation) (None, 512) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ dense_38 (Dense) (None, 128) 65664 ________________________________________________________________________________________________________________________________________________________________________________________________________ batch_normalization_92 (BatchNormalization) (None, 128) 512 ________________________________________________________________________________________________________________________________________________________________________________________________________ activation_39 (Activation) (None, 128) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ dense_39 (Dense) (None, 10) 1290 ======================================================================================================================================================================================================== Total params: 2,196,330 Trainable params: 2,194,794 Non-trainable params: 1,536 ________________________________________________________________________________________________________________________________________________________________________________________________________ In [122]: # plot_keras_model(image_only_model, to_file='keras_cnn_cifar_model.png') plot_model ( image_only_model , to_file = 'keras_cnn_cifar_model.png' , show_shapes = True , show_layer_names = True ) Step 6 - Lets train the model without much a do !! a. Pay special attention to the parameters steps_per_epoch and validation_steps. b. steps_per_epoch signifies the number of batches that should be drawn from the generator before shuffling the data and starting a new iteration of training. c. There are two different parameters to control the steps per epoch to account for different data sizes of training and validation sets. In [123]: history = image_only_model . fit_generator ( train_data_gen , steps_per_epoch = np . ceil ( len ( train_data ) / BATCH_SIZE ), epochs = 15 , validation_data = validation_data_gen , validation_steps = np . ceil ( len ( validation_data ) / BATCH_SIZE ), verbose = 1 , callbacks = [ tboard ]) Epoch 1/15 1365/1365 [==============================] - 329s 241ms/step - loss: 1.4505 - acc: 0.5424 - val_loss: 1.3004 - val_acc: 0.6025 Epoch 2/15 1365/1365 [==============================] - 317s 232ms/step - loss: 1.1478 - acc: 0.6706 - val_loss: 1.1542 - val_acc: 0.6806 Epoch 3/15 1365/1365 [==============================] - 327s 240ms/step - loss: 1.0745 - acc: 0.7112 - val_loss: 1.0869 - val_acc: 0.7198 Epoch 4/15 1365/1365 [==============================] - 298s 218ms/step - loss: 1.0374 - acc: 0.7400 - val_loss: 1.0513 - val_acc: 0.7431 Epoch 5/15 1365/1365 [==============================] - 301s 220ms/step - loss: 1.0069 - acc: 0.7630 - val_loss: 1.1248 - val_acc: 0.7256 Epoch 6/15 1365/1365 [==============================] - 302s 221ms/step - loss: 0.9877 - acc: 0.7821 - val_loss: 1.2158 - val_acc: 0.7209 Epoch 7/15 1365/1365 [==============================] - 312s 228ms/step - loss: 0.9749 - acc: 0.7941 - val_loss: 1.3047 - val_acc: 0.6894 Epoch 8/15 1365/1365 [==============================] - 313s 229ms/step - loss: 0.9510 - acc: 0.8091 - val_loss: 1.0938 - val_acc: 0.7701 Epoch 9/15 1365/1365 [==============================] - 294s 216ms/step - loss: 0.9410 - acc: 0.8221 - val_loss: 1.2910 - val_acc: 0.7068 Epoch 10/15 1365/1365 [==============================] - 314s 230ms/step - loss: 0.9319 - acc: 0.8294 - val_loss: 1.1774 - val_acc: 0.7656 Epoch 11/15 1365/1365 [==============================] - 291s 213ms/step - loss: 0.9203 - acc: 0.8389 - val_loss: 1.1822 - val_acc: 0.7635 Epoch 12/15 1365/1365 [==============================] - 300s 220ms/step - loss: 0.9125 - acc: 0.8470 - val_loss: 1.2179 - val_acc: 0.7624 Epoch 13/15 1365/1365 [==============================] - 334s 245ms/step - loss: 0.8985 - acc: 0.8563 - val_loss: 1.1793 - val_acc: 0.7786 Epoch 14/15 1365/1365 [==============================] - 303s 222ms/step - loss: 0.8975 - acc: 0.8614 - val_loss: 1.2055 - val_acc: 0.7669 Epoch 15/15 1365/1365 [==============================] - 299s 219ms/step - loss: 0.8908 - acc: 0.8644 - val_loss: 1.3411 - val_acc: 0.7331 In [124]: ## Prediction def prep_test_generators ( train_df , batch_size ): indices = range ( len ( train_df )) indx_iterator = 0 while True : if ( indx_iterator + 1 ) * batch_size > len ( indices ): indx_iterator = 0 batch_indices = indices [ indx_iterator * batch_size : ( indx_iterator + 1 ) * batch_size ] batch_x = np . stack ( train_df . loc [ batch_indices , 'np_images' ] . values , axis = 0 ) reshaped_batch_x = batch_x . reshape ( batch_size , 3 , 32 , 32 ) . transpose ( 0 , 2 , 3 , 1 ) / 255. indx_iterator += 1 yield reshaped_batch_x In [125]: test_pred_gen = prep_test_generators ( test_data , batch_size = BATCH_SIZE ) In [126]: test_prediction_logits = image_only_model . predict_generator ( test_pred_gen , steps = np . ceil ( len ( test_data ) / BATCH_SIZE )) In [127]: predicted_values = np . argmax ( test_prediction_logits , axis = - 1 ) In [128]: test_accuracy = np . float ( np . sum ( np . equal ( predicted_values , test_data [ 'labels' ][: len ( predicted_values )] . values ))) / len ( test_data ) print ( \"Test Accuracy is %f \" % ( test_accuracy * 100 )) Test Accuracy is 74.520000 End Comments - Evidently, DNNs is doing much better than random predictions. A comparable accuracy on train and test data reveals that the model is capable of generalizing and is not overfitting. Finally, the purpose of this article is to highlight the process of building a DNN using Keras. Feel free to experiment with different architectures and check how accuracy improves. Note that, bigger the model, larger will be the training times. I will soon try and upload an article in which we shall leverage pre-trained models for faster train times and better accuracy. Trouble Shooting - Why is my loss is NaN/ Inf? Be very careful while choosing activation function, especially ReLu. It is important to note that, ReLu activations are often unbounded and may result in an exploding gradient problem. Use batch Normalization to minimize the probability of encountering the problem of exploding gradients. Gradient Clipping strategy to counter the issue of Exploding Gradient is also widely adopted. If you are using custom loss function, ensure that a 0/0 situation won't arise which may induce nan/inf in computations. Check out the strategies suggested for a similar issue on stackoverflow . If the problem persists, reach out to the community and seek help. Why is my accuracy not changing? Such a problem can be encountered due to multiple reasons. Start by checking the class distribution. If there is a severe class imbalance, a model may resort to predicting all zeros/ all ones resulting in stagnant accuracy. Ensure that the generator used for generating mini-batches is working as expected. Instead of building an ambitious and complex model, start by building a minimalistic version and add layers based on performance achieved. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Deep Learning","loc":"/Deep Neural Network for Multiclass Classification Using Keras..html","title":"Deep Neural Network for Multiclass Classification Using Keras."},{"url":"/TextRank Algorithm for Key-Phrase Extraction / Text Summarization..html","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ Problem Statement Suppose you are working for a Newspaper Publisher and you are assigned a task of tagging each of the articles using text mentioned in the articles . You donwload the corpus of data and realise that there are more than 1 Million articles to be tagged. You have two options to choose from - Manually tagging articles Designing an Automated System for phrase extraction. An attempt to manually accomplish this task has following disadvantages - Manual processes are subjective with hardly any quality control. The sunk cost (money plus time) associated with the manual excercise is huge. A manual extraction model is not scalable. With time constraints, the only option available will to add more resources which will diminish the returns on the project. The results will not be reproducible. Its evident that manual process has a number of disadvantages. This leaves us with option 2 of 'Designing an Automated System for phrase extraction'. How can we automate the process? To accomplish the task we need an Extractive NLP (Natural Language Processing) model which can do the task for us at scale. TextRank is inspired from Google's PageRank algorithm which leverages Markov chains for ranking web pages. The Pagerank algorithm is named after Google cofounder - Larry Page. The Pagerank Algorithm outputs the probability distribution used to represent the likelihood that a person clicking randomly on links will arrive on a particular page. In this article, we shall try to extend pagerank algorithm to textual data and implement it from scratch using python. Pre-requisites - Before we jump into the task at hand, please refer to the following articles to brush up the theory on basic building blocks of a pagerank algorithm. Eigen Values and Eigen Vectors. Markov Chains and Steady State probabilities. Relation between Eigen Vectors and Pagerank Algorithm. Data - We shall be using \"all-the-news\" data published on kaggle The Description of dataset is as follows - unnamed - index column id - Database ID title - Article title publication - Publication name author - Author name date - Date of publication year - Year of publication month - Month of publication url - URL for article (not available for all articles) content - Article content Lets Start by importing python libraries that we will be needing throughout the process. In [1]: ### Import python libraries import warnings warnings . filterwarnings ( 'ignore' ) import os import string from collections import defaultdict import itertools import operator import networkx import nltk from nltk import sent_tokenize , word_tokenize import numpy as np import pandas as pd from IPython.core.interactiveshell import InteractiveShell InteractiveShell . ast_node_interactivity = \"none\" from IPython.display import display from IPython.display import HTML display ( HTML ( '<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>' )) display ( HTML ( \"<style>.container { width:100% !important; }</style>\" )) .prompt{width: 0px; min-width: 0px; visibility: collapse} .container { width:100% !important; } In [2]: raw_data = pd . read_csv ( './data/news_articles/all-the-news/articles1.csv' , encoding = 'utf-8' , dtype = { 'content' : unicode }) display ( raw_data . head ()) Unnamed: 0 id title publication author date year month url content 0 0 17283 House Republicans Fret About Winning Their Hea... New York Times Carl Hulse 2016-12-31 2016 12 NaN WASHINGTON — Congressional Republicans have... 1 1 17284 Rift Between Officers and Residents as Killing... New York Times Benjamin Mueller and Al Baker 2017-06-19 2017 6 NaN After the bullet shells get counted, the blood... 2 2 17285 Tyrus Wong, ‘Bambi' Artist Thwarted by Racial ... New York Times Margalit Fox 2017-01-06 2017 1 NaN When Walt Disney's \"Bambi\" opened in 1942, cri... 3 3 17286 Among Deaths in 2016, a Heavy Toll in Pop Musi... New York Times William McDonald 2017-04-10 2017 4 NaN Death may be the great equalizer, but it isn't... 4 4 17287 Kim Jong-un Says North Korea Is Preparing to T... New York Times Choe Sang-Hun 2017-01-02 2017 1 NaN SEOUL, South Korea — North Korea's leader, ... For the sake of convenience, we shall randomly sample 10 articles from the corpus. Typically, using bigger data would help in estimating accurate rank scores. But this article is for demonstration purposes only. Since article categories are missing from the original data, one can sample articles and train a pagerank network in a better way using unsupervised clustering algorithm. A clustering would ensure that the articles in each cluster are coherent resulting in a more robust 'proof of concept'. In [3]: data = raw_data . loc [: 10 ] Before we dig into the implementation aspect, lets have a receipe / pseudo code documented which will help us track our progress - Step 0 - Load data (Duh !!!) Step 1 - Inspect and clean raw data. A free flowing textual data is always subject to noise which can affect the model training process. Hence it is imperative to perform pre-processing to ensure robust fetaure extraction. Please note that the cleaning techinques can be modified and made more elaborate depending on the quality of data. Step 2 - Candidate Key-phrase Extraction. For the sake of convenience, we shall use a simple regex chunking technique to extract potential candidate phrases which will then be ranked using textrank algorithm. Please refer to this for an overview of phrase extraction. The article provides and overview of unsupervised as well as supervised techniques that can be used to extract and rank phrases. Step 3 - Node Extraction . This is an important step in building a textrank model. Instead of including all the tokens of the cleaned data, we shall ensure that only valid and useful tokens are added as nodes. Step 4 - Extra Bigrams and build a networkx graph . Using the bigrams from cleaned text and tokens from step 3 build a graph using networkx. One can explore the other types of graphs supported by networkx using the official documentation . Step 5 - Train the textrank model. Training a textrank/pagerank model is an iterative process which estimates the steady state probabilities. These steady state probabilities for each node reflect the importance of that particular token in the context of the corpus. Step 6 - Aggregate scores for potential candidates from step 2. . In this article, we have taken a simple sum of all the token on candidates phrases which are ranked by the textrank algorithm. This technique has an obvious disadvantage that longer phrases will come out are winners which may not be ideal for certain applications. Step 7 - Scoop out the Creamy layer . This step is optional and subject to domain of application. Step 8 - Reverse map the shortlisted keyphrase to original article Step 9 - Inspect results. Lets start with Step 1 of basic text pre-processing. We shall clean the contents of new articles by - Removing punctuations except for fullstop. Convert sentences to lower case. In [77]: punctuations = set ( string . punctuation ) punctuations_map = dict (( ord ( char ), None ) for char in punctuations ) def clean_text ( raw_text ): sentences = sent_tokenize ( raw_text ) punctuations_free_sentences = [ \" \" . join ( raw_string . translate ( punctuations_map ) . split ()) for raw_string in sentences ] concatenated_sentences = \". \" . join ( punctuations_free_sentences ) case_sensitive_text = concatenated_sentences . lower () return case_sensitive_text In [79]: data . loc [:, 'cleaned_text' ] = data . loc [:, 'content' ] . apply ( clean_text ) Step 2 - Potential Candidate Extraction. Next, we shall extract candidate phrases using regex chunker. The regex chunker is designed to extract noun phrases from a corpus of text. For more details on how to design regex chunker, please refer following resources - Regex Cheatsheet NLTK chunking In [80]: def get_chunks ( text , chunker , lang = 'en' ): tagged_sents = nltk . pos_tag_sents ( word_tokenize ( sent ) for sent in sent_tokenize ( text )) all_chunks = list ( itertools . chain . from_iterable ( nltk . chunk . tree2conlltags ( chunker . parse ( tagged_sent )) for tagged_sent in tagged_sents )) return all_chunks def mine_potential_phrases ( text , grammar = r 'KT: {(<JJ>* <NN.*>+ <IN>)? <JJ>* <NN.*>+}' , lang = 'en' ): stop_words = set ( nltk . corpus . stopwords . words ( 'english' )) chunker = nltk . chunk . regexp . RegexpParser ( grammar ) all_chunks = get_chunks ( text , chunker , lang ) # join constituent chunk words into a single chunked phrase candidates = [ ' ' . join ( word for word , pos , chunk in group ) . lower () for key , group in itertools . groupby ( all_chunks , lambda word_pos_chunk : word_pos_chunk [ 2 ] != 'O' ) if key ] return [ cand for cand in candidates if cand not in stop_words and not all ( char in punctuations for char in cand )] def build_candidate_phrases ( df , col_name , lang = 'en' ): unique_candidate_chunks = defaultdict ( lambda : 0 ) potential_chunks = df [ col_name ] . apply ( mine_potential_phrases ) for candidate_list in potential_chunks : for single_candidate in candidate_list : unique_candidate_chunks [ single_candidate ] += 1 return unique_candidate_chunks . keys () In [7]: unique_candidate_phrases = build_candidate_phrases ( data , 'cleaned_text' ) Step 3 - Node Extraction - In order to build a textrank graph, we need to mine potential nodes and train to estimate the steady state probabilities. In [8]: def mine_node_candidates ( text , lang = 'en' , valid_pos_tags = set ( [ 'JJ' , 'JJR' , 'JJS' , 'NN' , 'NNP' , 'NNS' , 'NNPS' ])): puncts_trans = string . maketrans ( \"\" , \"\" ) stop_words = set ( nltk . corpus . stopwords . words ( 'english' )) tagged_words = itertools . chain . from_iterable ( nltk . pos_tag_sents ( word_tokenize ( sent ) for sent in nltk . sent_tokenize ( text ))) candidates = [ word . encode ( \"utf-8\" ) . translate ( puncts_trans , string . punctuation ) . lower () for word , tag in tagged_words if ( tag in valid_pos_tags and word . lower () not in stop_words ) and not all ( char in punctuations for char in word )] return candidates In [9]: def build_candidate_nodes ( df , col_name , lang = 'en' ): unique_candidate_nodes = defaultdict ( lambda : 0 ) potential_nodes = df [ col_name ] . apply ( mine_node_candidates ) for candidate_list in potential_nodes : for single_candidate in candidate_list : unique_candidate_nodes [ single_candidate ] += 1 return unique_candidate_nodes . keys () In [10]: node_candidates = build_candidate_nodes ( data , 'cleaned_text' ) Step 4 - Generate N-grams and build a networkx graph In [81]: def generate_n_grams ( data , col_name , lang = 'en' ): unique_ngrams = defaultdict ( lambda : 0 ) for cand_text in data [ col_name ]: potential_ngrams = nltk . bigrams ( word_tokenize ( cand_text )) for single_ngram in potential_ngrams : unique_ngrams [ single_ngram ] += 1 return unique_ngrams . keys () In [12]: n_grams = generate_n_grams ( data , 'cleaned_text' ) In [ ]: def construct_textrank_graph ( bigram_candidates , candidate_words ): textrank_graph = networkx . DiGraph () textrank_graph . add_nodes_from ( candidate_words ) # sequence graph for ind_bigram in bigram_candidates : w1 , w2 = ind_bigram if w1 in candidate_words and w2 in candidate_words : textrank_graph . add_edges_from ([( w1 , w2 )]) else : continue return textrank_graph In [82]: textrank_graph = construct_textrank_graph ( n_grams , node_candidates ) Step 5 - Train networkX model. In [15]: text_rank = networkx . pagerank ( textrank_graph , max_iter = 5000 ) Step 6 - Aggregate Scores for each potential candidate - In [20]: def get_smart_dict ( text_rank_model ): word_ranks = { word_rank [ 0 ]: word_rank [ 1 ] for word_rank in sorted ( text_rank_model . iteritems (), key = lambda x : x [ 1 ], reverse = True )} keywords = sorted ( word_ranks . items (), key = operator . itemgetter ( 1 ), reverse = True ) scored_nodes_df = pd . DataFrame ( keywords , columns = [ 'smart_token' , 'smart_token_score' ]) filtered_nodes_df = scored_nodes_df . loc [ scored_nodes_df [ 'smart_token_score' ] > np . percentile ( scored_nodes_df [ 'smart_token_score' ], 25 )] smart_dict = filtered_nodes_df . set_index ( 'smart_token' )[ 'smart_token_score' ] . to_dict () return smart_dict In [21]: smart_dict = get_smart_dict ( text_rank ) In [24]: def compute_aggregated_scores ( scored_smart_phrases , node_scores ): scored_smart_tag_candidates = {} unique_scored_smart_token_keys = set ( node_scores . keys ()) for smart_tag_candidate in scored_smart_phrases : smart_tokens = word_tokenize ( smart_tag_candidate ) intersected_tokens = set ( smart_tokens ) . intersection ( unique_scored_smart_token_keys ) if len ( intersected_tokens ) >= 2 : selected_scores = operator . itemgetter ( * intersected_tokens )( node_scores ) if len ( intersected_tokens ) == 1 : scores = selected_scores else : scores = np . sum ( list ( selected_scores )) else : scores = 0 scored_smart_tag_candidates [ smart_tag_candidate ] = scores return scored_smart_tag_candidates In [33]: scored_node_candidates = compute_aggregated_scores ( unique_candidate_phrases , smart_dict ) sorted_keywords = pd . DataFrame ( sorted ( scored_node_candidates . items (), key = operator . itemgetter ( 1 ), reverse = True ), columns = [ 'key_phrase' , 'score' ]) In [35]: def get_phrase_length ( keyphrase_string ): phrase_length = len ( word_tokenize ( keyphrase_string )) return phrase_length In [36]: sorted_keywords [ 'phrase_length' ] = sorted_keywords [ 'key_phrase' ] . apply ( get_phrase_length ) Step 7 - Scoop out the Creamy Layer. Please note that this step is subject to the domain of application. In [71]: creamy_layer_phrases = sorted_keywords . loc [( sorted_keywords [ 'phrase_length' ] > 1 ) & ( sorted_keywords [ 'phrase_length' ] <= 4 ) & ( sorted_keywords [ 'score' ] > 0 )] Step 8 - Reverse map key phrase to articles - In [73]: data . loc [:, 'key_phrases' ] = '' In [74]: base = r '{}' expr = '(?=.*{})' for individual_phrase , smart_score in creamy_layer_phrases [[ 'key_phrase' , 'score' ]] . values : smart_tokens = word_tokenize ( individual_phrase ) match_pattern = base . format ( '' . join ( expr . format ( w . encode ( 'utf-8' )) for w in smart_tokens )) filtered_indices = data [ data [ 'cleaned_text' ] . str . contains ( match_pattern )] . index if len ( filtered_indices ): data . loc [ filtered_indices , 'key_phrases' ] = data . loc [ filtered_indices , 'key_phrases' ] + \"||{0}\" . format ( individual_phrase ) else : continue Step 9 - Inspect sample Results Inspecting results is an important step while developing algorithms and often under explored by ML/DS developers. Every domain of application has its own set of nuances which makes it less probable for any off-the-shelf algorithm to fit all the use-cases. It is very important to perform a critical analysis of results in order to make the algorithm more robust, accurate and scalable. Due to the scope of this article, I have already performed the necessary analysis and adjust some of the thresholds (hyper parameters) in above implementation to extract acceptable results. Lets check out the first article in our dataset. WASHINGTON — Congressional Republicans have a new fear when it comes to their health care lawsuit against the Obama administration: They might win. The incoming Trump administration could choose to no longer defend the executive branch against the suit, which challenges the administration's authority to spend billions of dollars on health insurance subsidies for and Americans, handing House Republicans a big victory on issues. But a sudden loss of the disputed subsidies could conceivably cause the health care program to implode, leaving millions of people without access to health insurance before Republicans have prepared a replacement. That could lead to chaos in the insurance market and spur a political backlash just as Republicans gain full control of the government. To stave off that outcome, Republicans could find themselves in the awkward position of appropriating huge sums to temporarily prop up the Obama health care law, angering conservative voters who have been demanding an end to the law for years. In another twist, Donald J. Trump's administration, worried about preserving executive branch prerogatives, could choose to fight its Republican allies in the House on some central questions in the dispute. Eager to avoid an ugly political pileup, Republicans on Capitol Hill and the Trump transition team are gaming out how to handle the lawsuit, which, after the election, has been put in limbo until at least late February by the United States Court of Appeals for the District of Columbia Circuit. They are not yet ready to divulge their strategy. \"Given that this pending litigation involves the Obama administration and Congress, it would be inappropriate to comment,\" said Phillip J. Blando, a spokesman for the Trump transition effort. \"Upon taking office, the Trump administration will evaluate this case and all related aspects of the Affordable Care Act. \" In a potentially decision in 2015, Judge Rosemary M. Collyer ruled that House Republicans had the standing to sue the executive branch over a spending dispute and that the Obama administration had been distributing the health insurance subsidies, in violation of the Constitution, without approval from Congress. The Justice Department, confident that Judge Collyer's decision would be reversed, quickly appealed, and the subsidies have remained in place during the appeal. In successfully seeking a temporary halt in the proceedings after Mr. Trump won, House Republicans last month told the court that they \"and the 's transition team currently are discussing potential options for resolution of this matter, to take effect after the 's inauguration on Jan. 20, 2017. \" The suspension of the case, House lawyers said, will \"provide the and his future administration time to consider whether to continue prosecuting or to otherwise resolve this appeal. \" Republican leadership officials in the House acknowledge the possibility of \"cascading effects\" if the payments, which have totaled an estimated $13 billion, are suddenly stopped. Insurers that receive the subsidies in exchange for paying costs such as deductibles and for eligible consumers could race to drop coverage since they would be losing money. Over all, the loss of the subsidies could destabilize the entire program and cause a lack of confidence that leads other insurers to seek a quick exit as well. Anticipating that the Trump administration might not be inclined to mount a vigorous fight against the House Republicans given the 's dim view of the health care law, a team of lawyers this month sought to intervene in the case on behalf of two participants in the health care program. In their request, the lawyers predicted that a deal between House Republicans and the new administration to dismiss or settle the case \"will produce devastating consequences for the individuals who receive these reductions, as well as for the nation's health insurance and health care systems generally. \" No matter what happens, House Republicans say, they want to prevail on two overarching concepts: the congressional power of the purse, and the right of Congress to sue the executive branch if it violates the Constitution regarding that spending power. House Republicans contend that Congress never appropriated the money for the subsidies, as required by the Constitution. In the suit, which was initially championed by John A. Boehner, the House speaker at the time, and later in House committee reports, Republicans asserted that the administration, desperate for the funding, had required the Treasury Department to provide it despite widespread internal skepticism that the spending was proper. The White House said that the spending was a permanent part of the law passed in 2010, and that no annual appropriation was required — even though the administration initially sought one. Just as important to House Republicans, Judge Collyer found that Congress had the standing to sue the White House on this issue — a ruling that many legal experts said was flawed — and they want that precedent to be set to restore congressional leverage over the executive branch. But on spending power and standing, the Trump administration may come under pressure from advocates of presidential authority to fight the House no matter their shared views on health care, since those precedents could have broad repercussions. It is a complicated set of dynamics illustrating how a quick legal victory for the House in the Trump era might come with costs that Republicans never anticipated when they took on the Obama White House. Now lets inspect the key phrases extracted from the above article - mr trump proceedings after mr trump election of mr trump mr obama house republicans last month house committee reports republicans deal between house republicans new administration despite years house republicans obama white house health insurance before republicans administration desperate american donald j trump obama health care law many people case house lawyers effects of people health care program future administration time incoming trump administration trump administration last year last half trump era trump transition effort white house trump transition team obama administration health care law law for years new administration district of columbia circuit health care lawsuit health care systems judge rosemary m collyer house speaker affordable care act general public american president views on health care full control many legal experts health insurance subsidies donald j united states laws new congress deal cut american officials team of lawyers united states executive branch prerogatives new fear widespread internal skepticism quick legal victory health insurance annual appropriation treasury department insurance market republican allies east side executive branch Concluding Comments - As it can be seen from results, the extracted key phrases are actually quite accurate and does capture of the article. Sure, there a few misses with phrases like \"last year\", \"last half\". Again extraction of such phrases is subjective and can be supressed by tweaking thresholds and hyper-parameters. For eg - I have extracted all the phrases with score > 0. By going aggressive on this score, one can suppress false positive. This is by no means the only solution out there for extractive text modelling. Infact, there is so much to play around with. Each of the step in pseudo code has been truncated / simplified to bring out the hero - Pagerank. Finally, I hope this article helps in establishing the baseline and provides an inspiration for everyone who are trying solve the this problem in their respective domains. Further Readings - Improved Automatic Keyword Extraction Based on TextRank Using Domain Knowledge Embed Rank if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Data Science","loc":"/TextRank Algorithm for Key-Phrase Extraction / Text Summarization..html","title":"TextRank Algorithm for Key Phrase Extraction / Text Summarization."},{"url":"/fantasy_sports_auto_selection.html","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ Auto Dream11 Selector With all the buzz around Indian Premier League (IPL), FIFA World Cup, Cricket World Cup-2019, fantasy sports websites like Dream11 are gaining traction. Fanatsy Sports Portal allows sports fans like me to be a part of it. Having said that, it is very difficult to keep track of all the players and their performance across the sports. In this Tutorial, I will try to automate the fantasy selection process so that the probability of winning a fantasy league is maximized. Lets get right to it by loading and inspecting the player data for an upcoming match between Chennai Superkings vs Mumbai Indians. In [1]: ##import python libraries from IPython.core.interactiveshell import InteractiveShell InteractiveShell . ast_node_interactivity = \"none\" from IPython.display import display from IPython.display import HTML import os import sys import re import pandas as pd import numpy as np from ast import literal_eval import pulp from sklearn.preprocessing import LabelBinarizer from IPython.core.display import display , HTML display ( HTML ( '<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>' )) display ( HTML ( \"<style>.container { width:100% !important; }</style>\" )) .prompt{width: 0px; min-width: 0px; visibility: collapse} .container { width:100% !important; } Data Description - The input file for auto selecting players has following fields - a. Cost - Most of the fantasy websites (including Dream11) allocates a total budget which cannot be exceeded. b. last_5_matches_points - This field is a list of points accured by a player in his last 5 matches. c. player_category - This field highlights the category of the player. In case of cricket, the possible categories are wicket-keeper, batsman, all-rounder, bowler. For a sport like football, the possible catgeories are - Goal keeper, Defender, Midfielder, Striker. This field is important because every fantasy website imposes a restriction on the number of players one can select from each of these categories. d. player_name - This field highlights the player name on fantasy sports website. e. team_name - This column in the dataframe highlights the team name of the player. In [4]: raw_player_data = pd . read_csv ( 'data/dream11_performance_data.csv' , converters = { \"last_5_matches_points\" : literal_eval }) display ( HTML ( '<font size=2>' + raw_player_data . head () . to_html () + '</font>' )) cost last_5_matches_points player_category player_name team_name 0 9.0 [25, 20, 15, 30, 18] wicket_keeper M.S. dhoni CSK 1 10.0 [30, 10, 23, 22, 16] batsman Suresh Raina CSK 2 8.5 [17, 13, 14, 27, 35] wicket_keeper kishan MI 3 10.5 [15, 7, 9, 40, 3] batsman rohit_sharma MI 4 9.5 [20, 18, 15, 22, 20] batsman lewis MI Algorithm Pseudo Code / Workflow - We will be viewing the selection problem as a Integer Linear Programming (ILP) problem with constraints. The objective function for ILP (Integer Linear Programming) will be to maximize the expected points. The constraints will be defined as per the rules imposed by fantasy website (In this case, Dream11). Once a ILP problem is defined, it can be easily solved using the PuLP library in python. For more mathematical details, I will be adding references at the end of the tutorial As one can imagine, we cannot work directly with text data. Hence, we will be using the \"get_dummies\" function in pandas to convert categorical data into one hot encoded vectors. For Eg - A single column of player_category in pandas dataframe will be split into number of unique values of player category. In this case, each player can either be a wicketkeeper, batsman, alrounder or a bowler. As a result, the player category for each player will be represented by a 4 dimensional one-hot encoded vector. In [5]: def get_dummies ( data , col_names = [ \"player_category\" , \"team_name\" ]): dummies_data = pd . get_dummies ( raw_player_data , columns = [ \"player_category\" , \"team_name\" ]) return dummies_data processed_player_data = get_dummies ( raw_player_data ) display ( HTML ( '<font size=2>' + processed_player_data . drop ([ 'cost' , 'last_5_matches_points' ], axis = 1 ) . head () . head () . to_html () + '</font>' )) player_name player_category_all_rounder player_category_batsman player_category_bowler player_category_wicket_keeper team_name_CSK team_name_MI 0 M.S. dhoni 0 0 0 1 1 0 1 Suresh Raina 0 1 0 0 1 0 2 kishan 0 0 0 1 0 1 3 rohit_sharma 0 1 0 0 0 1 4 lewis 0 1 0 0 0 1 In this Section, we will start crunching numbers so that an optimal objective function can be designed. One of the most important features which dictates where a player should be included in a fantasy team in his recent performance. The column - \"last_5_matches_points\" is a list of points accrued by a player in his last 5 matches. Now, Instead of taking a simple average of this points, we will be using a weighted average where weights are time decayed. This will ensure that the very recent form of a player is captured and leveraged by the selection algorithm. To better illustrate the importance of weighted average, lets consider following scenario. Say, the poinsts for player 1 and player 2 in last 5 matches are as follows - player 1 - [10, 20 , 30 , 40 , 50] player 2 - [50, 40 , 30, 20 , 10] The approach of computing simple averages will yield averaged scores as follows - player 1 - 30 player 2 - 30 The above stats imply that, both player 1 and player 2 accrue 30 points on an average. However it can be clearly seen that player 1 is growing in confidence and has a uptrend trend to his performance whereas player 2 has a downward trend to his performance. By taking simple average, we are losing an important insight. Now, if we compute the averages using time decayed weights, the averaged points are as follows - player 1 - 33.93 player 2 - 26.06 As it can seen from above numbers, even though both the players have amassed the same number of points, the trend in performances is now being captured with player 2 getting a higher average as compared to player 1. Such subtle differences will help us build a robust model. So, lets compute the time decayed weighted averages for the eligible players in the dataframe. In [3]: def compute_weighted_points ( points_vector , alpha = 0.20 ): weights = np . exp ( list ( reversed ( np . array ( range ( 1 , len ( points_vector ) + 1 )) * alpha * - 1 ))) exponential_weighted_average = np . average ( np . array ( points_vector ), weights = weights ) return exponential_weighted_average In [39]: processed_player_data [ 'weighted_player_points' ] = processed_player_data [ 'last_5_matches_points' ] . apply ( compute_weighted_points ) processed_player_data . reset_index ( inplace = True ) display ( processed_player_data [[ 'player_name' , 'last_5_matches_points' , 'weighted_player_points' ]] . head ()) player_name last_5_matches_points weighted_player_points 0 M.S. dhoni [25, 20, 15, 30, 18] 21.457434 1 Suresh Raina [30, 10, 23, 22, 16] 19.613900 2 kishan [17, 13, 14, 27, 35] 23.303382 3 rohit_sharma [15, 7, 9, 40, 3] 15.016017 4 lewis [20, 18, 15, 22, 20] 19.193689 Now, lets define the constraints for selecting players as defined by Dream11. These constraints are to be honoured by the algorithm while trying to maximize points. For more information, check out dream11 FAQs . In [41]: max_players = 11 max_batsman = 5 max_allrounders = 3 max_bowlers = 5 max_keepers = 1 max_cost = 100 max_team1_players = 7 max_team2_players = 7 In [42]: prob = pulp . LpProblem ( 'Dreamteam' , pulp . LpMaximize ) In [43]: # define decision variables for each row in the input dataframe decision_variables = [] for rownum , row in processed_player_data . iterrows (): variable = str ( 'x_{}' . format ( str ( rownum ))) variable = pulp . LpVariable ( variable , lowBound = 0 , upBound = 1 , cat = 'Integer' ) decision_variables . append ( variable ) print decision_variables [x_0, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15] In [44]: # Create optimization Function print processed_player_data . columns total_points = '' for rownum , row in processed_player_data . iterrows (): formula = row [ 'weighted_player_points' ] * decision_variables [ rownum ] total_points += formula prob += total_points Index([u'index', u'cost', u'last_5_matches_points', u'player_name', u'player_category_all_rounder', u'player_category_batsman', u'player_category_bowler', u'player_category_wicket_keeper', u'team_name_CSK', u'team_name_MI', u'weighted_player_points'], dtype='object') In [45]: #set constrainst for keeper total_keepers = '' total_batsman = '' total_allrounder = '' total_bowler = '' total_players = '' total_cost = '' total_team2 = '' total_team1 = '' for rownum , row in processed_player_data . iterrows (): keeper_formula = row [ 'player_category_wicket_keeper' ] * decision_variables [ rownum ] total_keepers += keeper_formula batsman_formula = row [ 'player_category_batsman' ] * decision_variables [ rownum ] total_batsman += batsman_formula allrounder_formula = row [ 'player_category_all_rounder' ] * decision_variables [ rownum ] total_allrounder += allrounder_formula bowler_formula = row [ 'player_category_bowler' ] * decision_variables [ rownum ] total_bowler += bowler_formula total_players_formula = decision_variables [ rownum ] total_players += total_players_formula total_cost_formula = row [ 'cost' ] * decision_variables [ rownum ] total_cost += total_cost_formula formula = row [ 'team_name_CSK' ] * decision_variables [ rownum ] total_team1 += formula formula = row [ 'team_name_MI' ] * decision_variables [ rownum ] total_team2 += formula prob += ( total_keepers == max_keepers ) prob += ( total_batsman <= max_batsman ) prob += ( total_allrounder <= max_allrounders ) prob += ( total_bowler <= max_bowlers ) prob += ( total_players == max_players ) prob += ( total_cost <= max_cost ) prob += ( total_team1 <= max_team1_players ) prob += ( total_team2 <= max_team2_players ) print ( prob ) prob . writeLP ( 'Dreamteam.lp' ) optimization_result = prob . solve () Dreamteam: MAXIMIZE 21.4574342327*x_0 + 19.6138998634*x_1 + 18.507022734*x_10 + 16.1006207824*x_11 + 3.03595134142*x_12 + 30.6877000247*x_13 + 10.8823368063*x_14 + 18.6665650801*x_15 + 23.3033823875*x_2 + 15.0160173204*x_3 + 19.1936886525*x_4 + 35.6738860573*x_5 + 20.8026696164*x_6 + 20.8419816771*x_7 + 23.4099290007*x_8 + 12.0189162375*x_9 + 0.0 SUBJECT TO _C1: x_0 + x_2 = 1 _C2: x_1 + x_3 + x_4 + x_5 + x_6 <= 5 _C3: x_10 + x_7 + x_8 + x_9 <= 3 _C4: x_11 + x_12 + x_13 + x_14 + x_15 <= 5 _C5: x_0 + x_1 + x_10 + x_11 + x_12 + x_13 + x_14 + x_15 + x_2 + x_3 + x_4 + x_5 + x_6 + x_7 + x_8 + x_9 = 11 _C6: 9 x_0 + 10 x_1 + 9 x_10 + 9 x_11 + 8.5 x_12 + 8.5 x_13 + 8.5 x_14 + 8 x_15 + 8.5 x_2 + 10.5 x_3 + 9.5 x_4 + 9 x_5 + 8.5 x_6 + 10.5 x_7 + 9 x_8 + 9 x_9 <= 100 _C7: x_0 + x_1 + x_10 + x_14 + x_15 + x_5 + x_7 <= 7 _C8: x_11 + x_12 + x_13 + x_2 + x_3 + x_4 + x_6 + x_8 + x_9 <= 7 VARIABLES 0 <= x_0 <= 1 Integer 0 <= x_1 <= 1 Integer 0 <= x_10 <= 1 Integer 0 <= x_11 <= 1 Integer 0 <= x_12 <= 1 Integer 0 <= x_13 <= 1 Integer 0 <= x_14 <= 1 Integer 0 <= x_15 <= 1 Integer 0 <= x_2 <= 1 Integer 0 <= x_3 <= 1 Integer 0 <= x_4 <= 1 Integer 0 <= x_5 <= 1 Integer 0 <= x_6 <= 1 Integer 0 <= x_7 <= 1 Integer 0 <= x_8 <= 1 Integer 0 <= x_9 <= 1 Integer In [48]: variable_name = [] variable_value = [] for v in prob . variables (): variable_name . append ( v . name ) variable_value . append ( v . varValue ) df = pd . DataFrame ({ 'index' : variable_name , 'value' : variable_value }) for rownum , row in df . iterrows (): value = re . findall ( r '(\\d+)' , row [ 'index' ]) df . loc [ rownum , 'index' ] = int ( value [ 0 ]) df = df . sort_values ( by = 'index' ) result = pd . merge ( processed_player_data , df , on = 'index' ) result = result [ result [ 'value' ] == 1 ] . sort_values ( by = 'weighted_player_points' , ascending = False ) selected_cols_final = [ 'player_name' , 'team_name_CSK' , 'team_name_MI' , 'weighted_player_points' ] final_set_of_players_to_be_selected = result [ selected_cols_final ] display ( final_set_of_players_to_be_selected ) print ( \"We can accrue an estimated points of %f \" % ( final_set_of_players_to_be_selected [ 'weighted_player_points' ] . sum ())) player_name team_name_CSK team_name_MI weighted_player_points 5 rayadu 1 0 35.673886 13 markande 0 1 30.687700 8 hardik 0 1 23.409929 2 kishan 0 1 23.303382 7 watson 1 0 20.841982 6 surya 0 1 20.802670 1 Suresh Raina 1 0 19.613900 4 lewis 0 1 19.193689 15 chahar 1 0 18.666565 10 bravo 1 0 18.507023 11 bumrah 0 1 16.100621 We can accrue an estimated points of 246.801346 There you GO !! We have our Dream Team !! All that needs to be done is to select the team in the app and start earning money !! Before, we wrap up this tutorial, I would like to highlight the features as well as the enhancement opportunities for the existing algorithm - a. The existing algorithm is completely automated and literally spits out the Dream team that maximises the probability of scoring highest points. b. In addition to that, it also conveys the estimated points that can be accrued through the selected team. The value would help us check the acccuracy of the system. c. The algorithm is sensitive to player performance trends and it adjusts accordingly. Enhancements - a. The input data needs to be stored in a database. Currently, I am relying on manual efforts to fetch the required data. b. The algorithm is not sensitive to injury news and other team updates. This is a significant miss and we will have to rely on scrapping and detecting such information through NLP on sports websites. It is an open ended question. In [ ]: if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Data Science","loc":"/fantasy_sports_auto_selection.html","title":"Auto Dream11 Selector"},{"url":"/image_text_classification.html","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ PRODUCT CLASSIFICATION USING IMAGE AND TEXT (DEEP LEARNING) Image classification using deep learning and its applications has been proving its worth across business verticals. However, building an image centric AI product is often marred by - Unavailability of large amounts of data. Poor quality of images. Even if data is available, the training times for achieving convergence are way too high. Often metadata and other information associated with the images is not utilized. In this article, we shall explore an approach that can leverage the metadata and may evenachieve better results. About the Dataset - I have customized the FIDS30 dataset for this article to better suit the problem statement. For the sake of this tutorial, lets consider only 4 fruit categories from the FIDS30 dataset, viz. Apples, Pears, Peaches and Plums. The reason for shortlisting the above mentioned fruit categories is the fact that these fruits are visually similar and it would be great to check how a deep learning algorithm like CNN handles it. In addition to this, each of the images has a metadata associated with it which describes the image. The metadata for fruit categories has been scrapped from Wikepedia. Please refer to the appendix for more details. To make things interesting, an addition category has been added to the dataset - 'Iphone'. The metadata for iphone images is same as that of apples. Such noise in textual data will cause pure text based models to fail. For eg - When a metadata for an image is something like - \"Apple sales in India have increased by 30% in last 2 years\", it is very difficult to know if the text is referring to Apple - the fruit or Apple - Iphone. In such circumstances, ML models based purely on textual data struggle. To make things clear, lets explore the Data !! Lets Start by loading python libraries needed to training the deep learning model. In [1]: from IPython.core.interactiveshell import InteractiveShell InteractiveShell . ast_node_interactivity = \"none\" from IPython.display import display from IPython.display import HTML display ( HTML ( '<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>' )) display ( HTML ( \"<style>.container { width:100% !important; }</style>\" )) import os , sys , glob , re , codecs import warnings warnings . filterwarnings ( 'ignore' ) import numpy as np import pandas as pd pd . set_option ( 'display.max_colwidth' , - 1 ) import matplotlib.pyplot as plt from sklearn import preprocessing from sklearn.utils import shuffle from sklearn.metrics import classification_report ## nltk library for working with textual data. from nltk.corpus import stopwords from nltk.tokenize import RegexpTokenizer ## import custom functions from shared library from shared import utils import keras from keras import backend as K from keras import optimizers , regularizers from keras.models import Sequential , Model from keras.layers import ( Dense , Dropout , Activation , Flatten , Embedding , Conv1D , MaxPooling1D , GlobalMaxPooling1D , concatenate , Conv2D , MaxPooling2D , ZeroPadding2D , Input ) from keras.layers.normalization import BatchNormalization from keras.preprocessing import sequence , image from keras.preprocessing.text import Tokenizer from keras.callbacks import EarlyStopping from keras.utils import to_categorical from keras.optimizers import SGD ## load pretrained weights from keras.applications.inception_v3 import InceptionV3 from keras.applications.xception import Xception from keras.applications.resnet50 import ResNet50 from keras.applications.vgg19 import VGG19 np . random . seed ( 0 ) from IPython.display import HTML display ( HTML ( '<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>' )) display ( HTML ( \"<style>.container { width:100% !important; }</style>\" )) .prompt{width: 0px; min-width: 0px; visibility: collapse} .container { width:100% !important; } Using TensorFlow backend. .prompt{width: 0px; min-width: 0px; visibility: collapse} .container { width:100% !important; } Set the Training Data Directory In [2]: train_data_basdir = os . path . join ( '.' , 'data' , 'image_text_data' , 'raw_metadata' ) Read a csv file with following columns - image_filepaths - filpaths for the downloaded images. metadata - textual data describing the image. label - Target label for the model to be trained on. In [3]: raw_data = pd . read_csv ( os . path . join ( train_data_basdir , 'server_images_text_raw_metadata1.csv' )) print ( ' \\n ' ) print ( \"There are %d training images\" % len (raw_data)) display ( HTML ( '<font size=2>' + raw_data . head () . to_html () + '</font>' )) There are 143 training images image_filepaths metadata label 0 ./data/image_text_data/train/FIDS30/apples/41.jpg An apple is a sweet, edible fruit produced by an apple tree (Malus pumila). apple trees are cultivated worldwide, and are the most widely grown species in the genus Malus. apple have also been linked to enhancing brain power. apple up the acetylcholine production. apple a great source of water and fiber that act as cleansing agents.\\nApples are frequently used as a pastry filling, apple pie being perhaps the archetypal American dessert. Especially in Europe, fried apple characteristically accompany certain dishes of sausage or pork. apples 1 ./data/image_text_data/train/FIDS30/apples/14.jpg The apple tree originated in Central Asia, where its wild ancestor, Malus sieversii, is still found today. apple have been grown for thousands of years in Asia and Europe, and were brought to North America by European colonists. A typical apple serving weighs 242 grams and provides 126 calories with a moderate content of dietary fiber (table). Otherwise, there is generally low content of essential nutrients (table). apple can be consumed various ways: juice, raw in salads, baked in pies, cooked into sauces and spreads like apple butter, and other baked dishes. Cider apple are typically too tart and astringent to eat fresh, but they give the beverage a rich flavor that dessert apple cannot. apple are often eaten raw. apples 2 ./data/image_text_data/train/FIDS30/apples/3.jpg apple have religious and mythological significance in many cultures, including Norse, Greek and European Christian traditions. apple trees are large if grown from seed. Generally apple cultivars are propagated by grafting onto rootstocks, which control the size of the resulting tree. Sliced apple consumption tripled in the US from 2004 to 2014 to 500 million apple annually due to its convenience.\\nOrganic apple are commonly produced in the United States.Due to infestations by key insects and diseases, organic production is difficult in Europe. A light coating of kaolin, which forms a physical barrier to some pests, also may help prevent apple sun scalding. The soils in which apple trees grow must be well drained; fertilizers can be used if the yield is not high enough. Rolling hilltops or the sloping sides of hills are preferred because they provide \"air drainage,\" allowing the colder, heavier air to drain away to the valley below during frosty spring nights, when blossoms or young fruit would be destroyed by exposure to cold. apples 3 ./data/image_text_data/train/FIDS30/apples/47.jpg The apple is a deciduous tree, generally standing 6 to 15 ft (1.8 to 4.6 m) tall in cultivation and up to 30 ft (9.1 m) in the wild. When cultivated, the size, shape and branch density are determined by rootstock selection and trimming method. The leaves are alternately arranged dark green-colored simple ovals with serrated margins and slightly downy undersides. Phlorizin is a flavonoid that is found in apple trees, particularly in the leaves, and in only small amounts if at all in other plants, even other species of the genus Malus. Sliced apple consumption tripled in the US from 2004 to 2014 to 500 million apple annually due to its convenience.Since the apple requires a considerable period of dormancy, it thrives in areas having a distinct winter period, generally from latitude 30° to 60°, both north and south. Northward, apple growing is limited by low winter temperatures and a short growing season. apples 4 ./data/image_text_data/train/FIDS30/apples/25.jpg The fruit matures in late summer or autumn, and cultivars exist with a wide range of sizes. Commercial growers aim to produce an apple that is 2 3⁄4 to 3 1⁄4 in (7.0 to 8.3 cm) in diameter, due to market preference. Some consumers, especially those in Japan, prefer a larger apple, while apple below 2 1⁄4 in (5.7 cm) are generally used for making juice and have little fresh market value. The skin of ripe apple is generally red, yellow, green, pink, or russetted although many bi- or tri-colored cultivars may be found. The skin may also be wholly or partly russeted i.e. rough and brown. The skin is covered in a protective layer of epicuticular wax. The exocarp (flesh) is generally pale yellowish-white, though pink or yellow. exocarps also occur. Since the apple requires a considerable period of dormancy, it thrives in areas having a distinct winter period, generally from latitude 30° to 60°, both north and south. Northward, apple growing is limited by low winter temperatures and a short growing season. A certain favanoid phlorizin, found in apple skin, may help prevent bone loss associated with menopause, as it fights the inflammation and free radical production that leads to bone degeneration. apple are a rich source of various phytochemicals including flavonoids (e.g., catechins, flavanols, and quercetin) and other phenolic compounds (e.g., epicatechin and procyanidins) found in the skin, core, and pulp of the apple; they have unknown health value in humans. apples Catgeory Distribution - A quick check on how training dataset is distributed across target categories will help us discover any skewness in data that may exist. In [4]: grouped_data = raw_data . groupby ( 'label' ) . agg ({ 'image_filepaths' : { 'data_count' : 'count' }}) grouped_data . columns = grouped_data . columns . droplevel ( 0 ) grouped_data = grouped_data . reset_index () display ( grouped_data ) /home/pritish.jadhav/jupyterhub3/lib/python3.5/site-packages/pandas/core/groupby/groupby.py:4656: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } label data_count 0 apples 38 1 iphone 15 2 peaches 27 3 pears 32 4 plums 31 It can be seen that iphone images are almost half in size as compared to other categories. Lets make a note of it and check it impact while evaluating results. Next, lets quickly visualize the images in our dataset. In [6]: ## fix the height and width of the image to be displayed height , width = 10 , 10 # decide the number of images to be displayed from each category columns = 5 # Find the number of unique categories in the training dataset rows = raw_data [ 'label' ] . nunique () # simple function for shuffle the data. def get_shuffled_data ( grouped_data , n = 5 ): shuffled_data = shuffle ( grouped_data ) . head ( n ) return shuffled_data # Initialize subplots using matplotlib fig , axes = plt . subplots ( nrows = rows , ncols = columns , figsize = ( width , height ), sharex = True , sharey = True ); sampled_data = raw_data . groupby ( 'label' , as_index = False ) . apply ( get_shuffled_data , columns ) . reset_index ( drop = True ) labels = sampled_data [ 'label' ] . unique () for index in range (( columns * rows )): ax = fig . add_subplot ( rows , columns , index + 1 ) image_array = image . load_img ( sampled_data . loc [ index , 'image_filepaths' ]) ax . axis ( 'off' ) ax . imshow ( image_array , cmap = 'gray' , interpolation = 'nearest' ) for ax , row in zip ( axes [:, 0 ], labels ): ax . set_ylabel ( row ) ax . set_yticks ([]) for ax , row in zip ( axes [ 0 , :], labels ): ax . set_xticks ([]) Visual Ambiguity - It can be seen that the images are quite visually similar. The Green apples are very similar to pears. A closeup image of Peach looks almost like an apple. Many images have more than one fruit in the image. Certain images of peaches and plums are very difficult to distinguish. All in all, the above set of sample images show that it will be a challenge to model such a dataset. Also, we will have to convert labels in one hot encoded vectors. Lets get that out of the way using below piece of code. In [7]: le = preprocessing . LabelEncoder () unique_classes = raw_data [ 'label' ] . unique () Y = le . fit_transform ( raw_data [ 'label' ]) Y = to_categorical ( Y , num_classes = len ( unique_classes )) print ( \"There are %d training data points and %d categories\" % ( len ( Y ), Y . shape [ 1 ])) There are 143 training data points and 5 categories Now that we have explored and investigated the image data at our disposal, lets turn focus to the textual metadata available at our disposal. In [8]: display ( shuffle ( raw_data [[ 'metadata' , 'label' ]]) . head ()) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } metadata label 11 apple are self-incompatible; they must cross-pollinate to develop fruit. During the flowering each season, apple growers often utilize pollinators to carry pollen. The apple is a deciduous tree, generally standing 6 to 15 ft (1.8 to 4.6 m) tall in cultivation and up to 30 ft (9.1 m) in the wild. When cultivated, the size, shape and branch density are determined by rootstock selection and trimming method. The leaves are alternately arranged dark green-colored simple ovals with serrated margins and slightly downy undersides. Other desired qualities in modern commercial apple breeding are a colorful skin, absence of russeting, ease of shipping, lengthy storage ability, high yields, disease resistance, common apple shape, and developed flavor. apples 37 apple have also been linked to enhancing brain power. apple up the acetylcholine production. apple a great source of water and fiber that act as cleansing agents. apples 21 Organic apple are commonly produced in the United States.Due to infestations by key insects and diseases, organic production is difficult in Europe. A light coating of kaolin, which forms a physical barrier to some pests, also may help prevent apple sun scalding.Many apple grow readily from seeds. However, more than with most perennial fruits, apple must be propagated asexually by grafting to obtain the sweetness and other desirable characteristics of the parent. This is because seedling apple are an example of \"extreme heterozygotes\", in that rather than inheriting genes from their parents to create a new apple with parental characteristics, they are instead significantly different from their parents, perhaps to compete with the many pests. apple trees are cultivated worldwide, and are the most widely grown species in the genus Malus. apples 46 peach can be broadly classified into two varieties- free stone variety where the seed is free in the center of the fruit and clinging seed variety where the seed is firmly attached to the pulp. A peach is a soft, juicy and fleshy stone fruit produced by a peach tree. consuming peach is a great way of improving your beta carotene levels to maintain healthy eyes. The outer surface of a peach is fuzzy and features longitudinal depressions extending from the stem to the tip. peaches 14 apple are often eaten raw. Cultivars bred for raw consumption are termed dessert or table apple. In the UK, a toffee apple is a traditional confection made by coating an apple in hot toffee and allowing it to cool. Similar treats in the U.S. are candy apple (coated in a hard shell of crystallized sugar syrup), and caramel apple (coated with cooled caramel). apple are a rich source of various phytochemicals including flavonoids (e.g., catechins, flavanols, and quercetin) and other phenolic compounds (e.g., epicatechin and procyanidins) found in the skin, core, and pulp of the apple; they have unknown health value in humans. apples Need for Text Cleaning - It can be seen that the text data consists of - a. stop words b. mix of lower and upper case characters c. punctuations Lets clean the textual data. In [9]: MAX_NB_WORDS = 100000 tokenizer = RegexpTokenizer ( r '\\w+' ) stop_words = set ( stopwords . words ( 'english' )) stop_words . update ([ '.' , ',' , '\"' , \"'\" , ':' , ';' , '(' , ')' , '[' , ']' , '{' , '}' ]) re_pattern = re . compile ( u '[&#94; \\u0000 - \\uD7FF\\uE000 - \\uFFFF ]' , re . UNICODE ) In [10]: print ( \"pre-processing train data...\" ) processed_docs_train = [] def get_cleaned_text ( raw_string ): try : tokens = tokenizer . tokenize ( raw_string ) filtered = ' ' . join ([ word . lower () for word in tokens if word not in stop_words ]) return filtered except Exception as e : print ( e ) return \"\" raw_data [ 'filtered_text' ] = raw_data [ 'metadata' ] . apply ( get_cleaned_text ) display ( raw_data . head ()) pre-processing train data... .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } image_filepaths metadata label filtered_text 0 ./data/image_text_data/train/FIDS30/apples/41.jpg An apple is a sweet, edible fruit produced by an apple tree (Malus pumila). apple trees are cultivated worldwide, and are the most widely grown species in the genus Malus. apple have also been linked to enhancing brain power. apple up the acetylcholine production. apple a great source of water and fiber that act as cleansing agents.\\nApples are frequently used as a pastry filling, apple pie being perhaps the archetypal American dessert. Especially in Europe, fried apple characteristically accompany certain dishes of sausage or pork. apples an apple sweet edible fruit produced apple tree malus pumila apple trees cultivated worldwide widely grown species genus malus apple also linked enhancing brain power apple acetylcholine production apple great source water fiber act cleansing agents apples frequently used pastry filling apple pie perhaps archetypal american dessert especially europe fried apple characteristically accompany certain dishes sausage pork 1 ./data/image_text_data/train/FIDS30/apples/14.jpg The apple tree originated in Central Asia, where its wild ancestor, Malus sieversii, is still found today. apple have been grown for thousands of years in Asia and Europe, and were brought to North America by European colonists. A typical apple serving weighs 242 grams and provides 126 calories with a moderate content of dietary fiber (table). Otherwise, there is generally low content of essential nutrients (table). apple can be consumed various ways: juice, raw in salads, baked in pies, cooked into sauces and spreads like apple butter, and other baked dishes. Cider apple are typically too tart and astringent to eat fresh, but they give the beverage a rich flavor that dessert apple cannot. apple are often eaten raw. apples the apple tree originated central asia wild ancestor malus sieversii still found today apple grown thousands years asia europe brought north america european colonists a typical apple serving weighs 242 grams provides 126 calories moderate content dietary fiber table otherwise generally low content essential nutrients table apple consumed various ways juice raw salads baked pies cooked sauces spreads like apple butter baked dishes cider apple typically tart astringent eat fresh give beverage rich flavor dessert apple cannot apple often eaten raw 2 ./data/image_text_data/train/FIDS30/apples/3.jpg apple have religious and mythological significance in many cultures, including Norse, Greek and European Christian traditions. apple trees are large if grown from seed. Generally apple cultivars are propagated by grafting onto rootstocks, which control the size of the resulting tree. Sliced apple consumption tripled in the US from 2004 to 2014 to 500 million apple annually due to its convenience.\\nOrganic apple are commonly produced in the United States.Due to infestations by key insects and diseases, organic production is difficult in Europe. A light coating of kaolin, which forms a physical barrier to some pests, also may help prevent apple sun scalding. The soils in which apple trees grow must be well drained; fertilizers can be used if the yield is not high enough. Rolling hilltops or the sloping sides of hills are preferred because they provide \"air drainage,\" allowing the colder, heavier air to drain away to the valley below during frosty spring nights, when blossoms or young fruit would be destroyed by exposure to cold. apples apple religious mythological significance many cultures including norse greek european christian traditions apple trees large grown seed generally apple cultivars propagated grafting onto rootstocks control size resulting tree sliced apple consumption tripled us 2004 2014 500 million apple annually due convenience organic apple commonly produced united states due infestations key insects diseases organic production difficult europe a light coating kaolin forms physical barrier pests also may help prevent apple sun scalding the soils apple trees grow must well drained fertilizers used yield high enough rolling hilltops sloping sides hills preferred provide air drainage allowing colder heavier air drain away valley frosty spring nights blossoms young fruit would destroyed exposure cold 3 ./data/image_text_data/train/FIDS30/apples/47.jpg The apple is a deciduous tree, generally standing 6 to 15 ft (1.8 to 4.6 m) tall in cultivation and up to 30 ft (9.1 m) in the wild. When cultivated, the size, shape and branch density are determined by rootstock selection and trimming method. The leaves are alternately arranged dark green-colored simple ovals with serrated margins and slightly downy undersides. Phlorizin is a flavonoid that is found in apple trees, particularly in the leaves, and in only small amounts if at all in other plants, even other species of the genus Malus. Sliced apple consumption tripled in the US from 2004 to 2014 to 500 million apple annually due to its convenience.Since the apple requires a considerable period of dormancy, it thrives in areas having a distinct winter period, generally from latitude 30° to 60°, both north and south. Northward, apple growing is limited by low winter temperatures and a short growing season. apples the apple deciduous tree generally standing 6 15 ft 1 8 4 6 tall cultivation 30 ft 9 1 wild when cultivated size shape branch density determined rootstock selection trimming method the leaves alternately arranged dark green colored simple ovals serrated margins slightly downy undersides phlorizin flavonoid found apple trees particularly leaves small amounts plants even species genus malus sliced apple consumption tripled us 2004 2014 500 million apple annually due convenience since apple requires considerable period dormancy thrives areas distinct winter period generally latitude 30 60 north south northward apple growing limited low winter temperatures short growing season 4 ./data/image_text_data/train/FIDS30/apples/25.jpg The fruit matures in late summer or autumn, and cultivars exist with a wide range of sizes. Commercial growers aim to produce an apple that is 2 3⁄4 to 3 1⁄4 in (7.0 to 8.3 cm) in diameter, due to market preference. Some consumers, especially those in Japan, prefer a larger apple, while apple below 2 1⁄4 in (5.7 cm) are generally used for making juice and have little fresh market value. The skin of ripe apple is generally red, yellow, green, pink, or russetted although many bi- or tri-colored cultivars may be found. The skin may also be wholly or partly russeted i.e. rough and brown. The skin is covered in a protective layer of epicuticular wax. The exocarp (flesh) is generally pale yellowish-white, though pink or yellow. exocarps also occur. Since the apple requires a considerable period of dormancy, it thrives in areas having a distinct winter period, generally from latitude 30° to 60°, both north and south. Northward, apple growing is limited by low winter temperatures and a short growing season. A certain favanoid phlorizin, found in apple skin, may help prevent bone loss associated with menopause, as it fights the inflammation and free radical production that leads to bone degeneration. apple are a rich source of various phytochemicals including flavonoids (e.g., catechins, flavanols, and quercetin) and other phenolic compounds (e.g., epicatechin and procyanidins) found in the skin, core, and pulp of the apple; they have unknown health value in humans. apples the fruit matures late summer autumn cultivars exist wide range sizes commercial growers aim produce apple 2 3 4 3 1 4 7 0 8 3 cm diameter due market preference some consumers especially japan prefer larger apple apple 2 1 4 5 7 cm generally used making juice little fresh market value the skin ripe apple generally red yellow green pink russetted although many bi tri colored cultivars may found the skin may also wholly partly russeted e rough brown the skin covered protective layer epicuticular wax the exocarp flesh generally pale yellowish white though pink yellow exocarps also occur since apple requires considerable period dormancy thrives areas distinct winter period generally latitude 30 60 north south northward apple growing limited low winter temperatures short growing season a certain favanoid phlorizin found apple skin may help prevent bone loss associated menopause fights inflammation free radical production leads bone degeneration apple rich source various phytochemicals including flavonoids e g catechins flavanols quercetin phenolic compounds e g epicatechin procyanidins found skin core pulp apple unknown health value humans Converting Raw Text to Numeric Vector Representation - As we know, deep learning models cannot comprehend textual words in the human sense. They can only work with numeric vectors. The following section highlights the process of converting raw text into vector representation. Consider a sample training data with just 2 data points - sample_data = ['The fruit matures in late summer or autumn', 'The skin of ripe apples is generally red, yellow, green, pink, or russetted although many bi- or tri-colored cultivars may be found'] 1. Initialize a tokenizer for breaking down the raw text into tokens. In general, tokenizers are designed to work with words (n-grams) or with characters. For the sake of this article, we shall work with word level tokens. Feel free to experiment with character level tokenization. [in] sample_tokenizer = Tokenizer(num_words=20, lower=True, char_level=False) 2. Fit the tokenization model on top of raw text to build a dictionary. The model basically extracts the top n words in raw text and assigns them an integer value. [in] sample_tokenizer.fit_on_texts(sample_data) [in] print sample_tokenizer.word_index [out] {'summer': 7, 'ripe': 11, 'is': 13, 'in': 5, 'yellow': 16, 'autumn': 8, 'skin': 9, 'pink': 18, 'matures': 4, 'cultivars': 25, 'generally': 14, 'late': 6, 'russetted': 19, 'red': 15, 'be': 27, 'may': 26, 'bi': 22, 'fruit': 3, 'although': 20, 'tri': 23, 'colored': 24, 'of': 10, 'green': 17, 'apples': 12, 'many': 21, 'found': 28, 'the': 2, 'or': 1} 3. Convert each training example into a sequences. [in] word_sequence = sample_tokenizer.texts_to_sequences(sample_data) [in] print word_sequence [out] [[2, 3, 4, 5, 6, 7, 1, 8], [2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1, 19, 20, 21, 22, 1, 23, 24, 25, 26, 27, 28]] 4. Sequence padding As it can be seen from the output of step 3, the length of word sequence of input text sequence is not uniform. Therefore, we cannot feed the output of step 3 directly to our deep learning model. To solve this, lets pad our training length using dummy token as follows - [in] sequence.pad_sequences(sequences, maxlen=20) [out] [[ 0 0 0 0 0 0 0 0 0 0 0 0 2 3 4 5 6 7 1 8] [11 12 13 14 15 16 17 18 1 19 20 21 22 1 23 24 25 26 27 28]] For more information, please check out this blog In [11]: print ( \"tokenizing input data...\" ) tokenizer1 = Tokenizer ( num_words = MAX_NB_WORDS , lower = True , char_level = False ) ## fit tokenization model tokenizer1 . fit_on_texts ( raw_data [ 'filtered_text' ]) ## convert raw text into a sequence of words word_seq_train = tokenizer1 . texts_to_sequences ( raw_data [ 'filtered_text' ]) ## huerictic for deciding the max length for padding text sequences raw_data [ 'doc_len' ] = raw_data [ 'filtered_text' ] . apply ( lambda sentence : len ( sentence . split ( ' ' ))) # max_seq_len = np.round(raw_data['doc_len'].mean() + raw_data['doc_len'].std()).astype(int) max_seq_len = raw_data [ 'doc_len' ] . max () print ( \"The length of the input text will be capped off at %d \" % max_seq_len ) ## pad text input word_seq_train = sequence . pad_sequences ( word_seq_train , maxlen = max_seq_len ) ## recover the word index word_index = tokenizer1 . word_index tokenizing input data... The length of the input text will be capped off at 177 We shall be using the pre-trained glove model to generate word embeddings for tokens in training data In [12]: #training params batch_size = 25 num_epochs = 10 #model parameters num_filters = 64 embed_dim = 100 weight_decay = 1e-4 #load embeddings print ( 'loading word embeddings...' ) embeddings_index = {} f = codecs . open ( os . path . join ( '.' , 'data' , 'image_text_data' , 'glove.6B.100d.txt' ), encoding = 'utf-8' ) for line in f : values = line . rstrip () . rsplit ( ' ' ) word = values [ 0 ] coefs = np . asarray ( values [ 1 :], dtype = 'float32' ) embeddings_index [ word ] = coefs f . close () print ( 'found %s word vectors' % len ( embeddings_index )) #embedding matrix print ( 'preparing embedding matrix...' ) words_not_found = [] nb_words = min ( MAX_NB_WORDS , len ( word_index ) + 1 ) embedding_matrix = np . zeros (( nb_words , embed_dim )) for word , i in word_index . items (): if i >= nb_words : continue embedding_vector = embeddings_index . get ( word ) if ( embedding_vector is not None ) and len ( embedding_vector ) > 0 : # words not found in embedding index will be all-zeros. embedding_matrix [ i ] = embedding_vector else : words_not_found . append ( word ) print ( 'number of null word embeddings: %d ' % np . sum ( np . sum ( embedding_matrix , axis = 1 ) == 0 )) loading word embeddings... found 400000 word vectors preparing embedding matrix... number of null word embeddings: 68 In [13]: def get_image_representation ( image_filepaths , channel_orientation = 'channels_first' ): ''' Function for reading images. input: image_filepaths: list of images filepaths channel_orientation - String value for controlling the channel orientation ''' image_representation = [] for img_path in image_filepaths : img = image . load_img ( img_path , target_size = ( 256 , 256 )) img = image . img_to_array ( img , data_format = channel_orientation ) img = img / 255. image_representation . append ( img ) return np . array ( image_representation ) In [14]: def prepare_training_generators ( train_df , len_unique_classes , chunk_size = 5 , channel_orientation = \"channels_first\" ): ''' This function generates mini batches of training data in the form of an iterator. inputs: train_df: pandas dataframe of training data. len_unique_classes - integer value highlughting the number of unique target labels in training data. chunk_size - integer value highlighting the mini batch siz. The default value is set to 16 channel_orientation - A string values used to represenattion the channel orientation of images to be read. output: iterator of text_data, image_data and output label ''' index_tracker = 0 while True : text_x = tokenizer1 . texts_to_sequences ( train_df . iloc [ index_tracker : index_tracker + chunk_size ][ 'filtered_text' ]) text_x = sequence . pad_sequences ( text_x , maxlen = max_seq_len ) image_x = get_image_representation ( train_df . iloc [ index_tracker : index_tracker + chunk_size ][ 'image_filepaths' ], channel_orientation ) y_le = le . transform ( train_df . iloc [ index_tracker : index_tracker + chunk_size ][ 'label' ]) y = to_categorical ( y_le , num_classes = len_unique_classes ) index_tracker += chunk_size if index_tracker >= len ( train_df ): index_tracker = 0 train_df = shuffle ( train_df ) . reset_index ( drop = True ) yield [ text_x , image_x ], y def prepare_test_generators ( test_df , len_unique_classes , chunk_size = 5 , channel_orientation = \"channels_first\" ): ''' This function generates mini batches of training data in the form of an iterator. inputs: train_df: pandas dataframe of training data. len_unique_classes - integer value highlughting the number of unique target labels in training data. chunk_size - integer value highlighting the mini batch siz. The default value is set to 16 channel_orientation - A string values used to represenattion the channel orientation of images to be read. output: iterator of text_data, image_data and output label ''' index_tracker = 0 while True : text_x = tokenizer1 . texts_to_sequences ( test_df . iloc [ index_tracker : index_tracker + chunk_size ][ 'filtered_text' ]) text_x = sequence . pad_sequences ( text_x , maxlen = max_seq_len ) image_x = get_image_representation ( test_df . iloc [ index_tracker : index_tracker + chunk_size ][ 'image_filepaths' ], channel_orientation ) y_le = le . transform ( test_df . iloc [ index_tracker : index_tracker + chunk_size ][ 'label' ]) y = to_categorical ( y_le , num_classes = len_unique_classes ) index_tracker += chunk_size if index_tracker >= len ( test_df ): index_tracker = 0 yield [ text_x , image_x ] In [16]: train_data = raw_data . groupby ( 'label' , group_keys = False ) . apply ( lambda x : x . sample ( frac = 0.8 , random_state = 2 )) test_data = raw_data . loc [ ~ raw_data . index . isin ( train_data . index )] print ( \"training data has %d rows\" % len (train_data)) print ( \"test_data has %d rows\" % len (test_data)) training data has 115 rows test_data has 28 rows In [17]: tdidf_tokenizer = Tokenizer ( num_words = 2000 ) tdidf_tokenizer . fit_on_texts ( raw_data [ 'filtered_text' ]) x_train = tdidf_tokenizer . texts_to_matrix ( train_data [ 'filtered_text' ], mode = 'tfidf' ) x_test = tdidf_tokenizer . texts_to_matrix ( test_data [ 'filtered_text' ], mode = 'tfidf' ) IMAGE ONLY MODEL - The first model that we will be fitting on our training data is a image only model The function for building a image only model relies on pretrained weights available with keras. We shall be adding some dense layers to serve our purpose. Please note that the text input from generators will be ignored in an image only model In [28]: def build_image_only_model ( text_input_shape = ( 26 ,), image_input_shape = ( 256 , 256 , 3 ), pretrained_model = 'vgg19' , classes = 245 ): print ( 'received pretrained model %s ' % pretrained_model ) vis_input = Input ( shape = text_input_shape , name = \"vis_input\" ) if pretrained_model == 'inception' : pretrained_model = InceptionV3 ( include_top = False , input_shape = image_input_shape , weights = 'imagenet' ) elif pretrained_model == 'xception' : pretrained_model = Xception ( include_top = False , input_shape = image_input_shape , weights = 'imagenet' ) elif pretrained_model == 'resnet50' : pretrained_model = ResNet50 ( include_top = False , input_shape = image_input_shape , weights = 'imagenet' ) elif pretrained_model == 'vgg19' : pretrained_model = VGG19 ( include_top = False , input_shape = image_input_shape , weights = 'imagenet' ) elif pretrained_model == 'all' : input = Input ( shape = image_input_shape ) inception_model = InceptionV3 ( include_top = False , input_tensor = input , weights = 'imagenet' ) xception_model = Xception ( include_top = False , input_tensor = input , weights = 'imagenet' ) resnet_model = ResNet50 ( include_top = False , input_tensor = input , weights = 'imagenet' ) flattened_outputs = [ Flatten ()( inception_model . output ), Flatten ()( xception_model . output ), Flatten ()( resnet_model . output )] output = Concatenate ()( flattened_outputs ) pretrained_model = Model ( input , output ) ''' We can select from inception, xception, resnet50, vgg19, or a combination of the first three as the basis for our image classifier. We specify include_top=False in these models in order to remove the top level classification layers. These are the layers used to classify images into the categories of the ImageNet competition; since our categories are different, we shall remove these top layers and replace them with our own. ''' if pretrained_model . output . shape . ndims > 2 : output = Flatten ()( pretrained_model . output ) else : output = pretrained_model . output output = BatchNormalization ()( output ) output = Dropout ( 0.2 )( output ) output = Dense ( 128 , activation = 'relu' )( output ) output = BatchNormalization ()( output ) output = Dropout ( 0.2 )( output ) output = Dense ( 256 , activation = 'relu' )( output ) output = BatchNormalization ()( output ) output = Dropout ( 0.2 )( output ) output = Dense ( classes , activation = 'softmax' )( output ) model = Model ( inputs = [ vis_input , pretrained_model . input ], outputs = output , name = \"model\" ) for layer in pretrained_model . layers : layer . trainable = False model . summary ( line_length = 200 ) model . compile ( optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) return model In [29]: ''' Print out the model summary ''' tboard = keras . callbacks . TensorBoard ( log_dir = './logs' , histogram_freq = 0 , batch_size = 32 , write_graph = True , write_grads = False , write_images = False , embeddings_freq = 0 , embeddings_layer_names = None , embeddings_metadata = None , embeddings_data = None ) validation_data_gen = prepare_training_generators ( test_data , len ( unique_classes ), chunk_size = len ( test_data ) , channel_orientation = \"channels_last\" ) train_data_gen = prepare_training_generators ( train_data , len ( unique_classes ), chunk_size = batch_size , channel_orientation = \"channels_last\" ) image_only_model = build_image_only_model ( text_input_shape = ( max_seq_len ,), image_input_shape = ( 256 , 256 , 3 ) , classes = len ( unique_classes )) received pretrained model vgg19 ________________________________________________________________________________________________________________________________________________________________________________________________________ Layer (type) Output Shape Param # ======================================================================================================================================================================================================== input_3 (InputLayer) (None, 256, 256, 3) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ block1_conv1 (Conv2D) (None, 256, 256, 64) 1792 ________________________________________________________________________________________________________________________________________________________________________________________________________ block1_conv2 (Conv2D) (None, 256, 256, 64) 36928 ________________________________________________________________________________________________________________________________________________________________________________________________________ block1_pool (MaxPooling2D) (None, 128, 128, 64) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ block2_conv1 (Conv2D) (None, 128, 128, 128) 73856 ________________________________________________________________________________________________________________________________________________________________________________________________________ block2_conv2 (Conv2D) (None, 128, 128, 128) 147584 ________________________________________________________________________________________________________________________________________________________________________________________________________ block2_pool (MaxPooling2D) (None, 64, 64, 128) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ block3_conv1 (Conv2D) (None, 64, 64, 256) 295168 ________________________________________________________________________________________________________________________________________________________________________________________________________ block3_conv2 (Conv2D) (None, 64, 64, 256) 590080 ________________________________________________________________________________________________________________________________________________________________________________________________________ block3_conv3 (Conv2D) (None, 64, 64, 256) 590080 ________________________________________________________________________________________________________________________________________________________________________________________________________ block3_conv4 (Conv2D) (None, 64, 64, 256) 590080 ________________________________________________________________________________________________________________________________________________________________________________________________________ block3_pool (MaxPooling2D) (None, 32, 32, 256) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ block4_conv1 (Conv2D) (None, 32, 32, 512) 1180160 ________________________________________________________________________________________________________________________________________________________________________________________________________ block4_conv2 (Conv2D) (None, 32, 32, 512) 2359808 ________________________________________________________________________________________________________________________________________________________________________________________________________ block4_conv3 (Conv2D) (None, 32, 32, 512) 2359808 ________________________________________________________________________________________________________________________________________________________________________________________________________ block4_conv4 (Conv2D) (None, 32, 32, 512) 2359808 ________________________________________________________________________________________________________________________________________________________________________________________________________ block4_pool (MaxPooling2D) (None, 16, 16, 512) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ block5_conv1 (Conv2D) (None, 16, 16, 512) 2359808 ________________________________________________________________________________________________________________________________________________________________________________________________________ block5_conv2 (Conv2D) (None, 16, 16, 512) 2359808 ________________________________________________________________________________________________________________________________________________________________________________________________________ block5_conv3 (Conv2D) (None, 16, 16, 512) 2359808 ________________________________________________________________________________________________________________________________________________________________________________________________________ block5_conv4 (Conv2D) (None, 16, 16, 512) 2359808 ________________________________________________________________________________________________________________________________________________________________________________________________________ block5_pool (MaxPooling2D) (None, 8, 8, 512) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ flatten_6 (Flatten) (None, 32768) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ batch_normalization_7 (BatchNormalization) (None, 32768) 131072 ________________________________________________________________________________________________________________________________________________________________________________________________________ dropout_10 (Dropout) (None, 32768) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ dense_12 (Dense) (None, 128) 4194432 ________________________________________________________________________________________________________________________________________________________________________________________________________ batch_normalization_8 (BatchNormalization) (None, 128) 512 ________________________________________________________________________________________________________________________________________________________________________________________________________ dropout_11 (Dropout) (None, 128) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ dense_13 (Dense) (None, 256) 33024 ________________________________________________________________________________________________________________________________________________________________________________________________________ batch_normalization_9 (BatchNormalization) (None, 256) 1024 ________________________________________________________________________________________________________________________________________________________________________________________________________ dropout_12 (Dropout) (None, 256) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ dense_14 (Dense) (None, 5) 1285 ======================================================================================================================================================================================================== Total params: 24,385,733 Trainable params: 4,295,045 Non-trainable params: 20,090,688 ________________________________________________________________________________________________________________________________________________________________________________________________________ In [30]: history = image_only_model . fit_generator ( train_data_gen , steps_per_epoch = np . ceil ( len ( train_data ) / batch_size ), epochs = 30 , validation_data = validation_data_gen , validation_steps = 1 , verbose = 1 , callbacks = [ tboard ]) Epoch 1/30 5/5 [==============================] - 50s 10s/step - loss: 2.5140 - acc: 0.2000 - val_loss: 1.5906 - val_acc: 0.6071 Epoch 2/30 5/5 [==============================] - 46s 9s/step - loss: 1.3471 - acc: 0.5063 - val_loss: 1.0311 - val_acc: 0.5714 Epoch 3/30 5/5 [==============================] - 47s 9s/step - loss: 0.8266 - acc: 0.6694 - val_loss: 0.8242 - val_acc: 0.7143 Epoch 4/30 5/5 [==============================] - 47s 9s/step - loss: 0.5169 - acc: 0.8495 - val_loss: 0.7280 - val_acc: 0.7500 Epoch 5/30 5/5 [==============================] - 47s 9s/step - loss: 0.3619 - acc: 0.8775 - val_loss: 0.6781 - val_acc: 0.7500 Epoch 6/30 5/5 [==============================] - 47s 9s/step - loss: 0.2539 - acc: 0.9469 - val_loss: 0.6386 - val_acc: 0.8214 Epoch 7/30 5/5 [==============================] - 47s 9s/step - loss: 0.2649 - acc: 0.9181 - val_loss: 0.6266 - val_acc: 0.7857 Epoch 8/30 5/5 [==============================] - 47s 9s/step - loss: 0.1270 - acc: 0.9793 - val_loss: 0.6326 - val_acc: 0.7857 Epoch 9/30 5/5 [==============================] - 47s 9s/step - loss: 0.1418 - acc: 0.9306 - val_loss: 0.6553 - val_acc: 0.7500 Epoch 10/30 5/5 [==============================] - 47s 9s/step - loss: 0.1177 - acc: 0.9550 - val_loss: 0.6730 - val_acc: 0.7500 Epoch 11/30 5/5 [==============================] - 47s 9s/step - loss: 0.0944 - acc: 0.9838 - val_loss: 0.7067 - val_acc: 0.7143 Epoch 12/30 5/5 [==============================] - 47s 9s/step - loss: 0.0599 - acc: 0.9919 - val_loss: 0.7327 - val_acc: 0.7143 Epoch 13/30 5/5 [==============================] - 47s 9s/step - loss: 0.0429 - acc: 1.0000 - val_loss: 0.7472 - val_acc: 0.7143 Epoch 14/30 5/5 [==============================] - 47s 9s/step - loss: 0.0274 - acc: 1.0000 - val_loss: 0.7516 - val_acc: 0.7143 Epoch 15/30 5/5 [==============================] - 47s 9s/step - loss: 0.0384 - acc: 0.9919 - val_loss: 0.7452 - val_acc: 0.7500 Epoch 16/30 5/5 [==============================] - 47s 9s/step - loss: 0.0336 - acc: 1.0000 - val_loss: 0.7317 - val_acc: 0.7857 Epoch 17/30 5/5 [==============================] - 47s 9s/step - loss: 0.0465 - acc: 0.9919 - val_loss: 0.7301 - val_acc: 0.7143 Epoch 18/30 5/5 [==============================] - 47s 9s/step - loss: 0.0190 - acc: 1.0000 - val_loss: 0.7293 - val_acc: 0.7143 Epoch 19/30 5/5 [==============================] - 47s 9s/step - loss: 0.0369 - acc: 0.9919 - val_loss: 0.7326 - val_acc: 0.7143 Epoch 20/30 5/5 [==============================] - 47s 9s/step - loss: 0.0589 - acc: 0.9874 - val_loss: 0.7403 - val_acc: 0.7143 Epoch 21/30 5/5 [==============================] - 47s 9s/step - loss: 0.0273 - acc: 1.0000 - val_loss: 0.7521 - val_acc: 0.7143 Epoch 22/30 5/5 [==============================] - 47s 9s/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.7616 - val_acc: 0.7500 Epoch 23/30 5/5 [==============================] - 47s 9s/step - loss: 0.0324 - acc: 0.9838 - val_loss: 0.7763 - val_acc: 0.7143 Epoch 24/30 5/5 [==============================] - 47s 9s/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.8022 - val_acc: 0.6786 Epoch 25/30 5/5 [==============================] - 47s 9s/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.8119 - val_acc: 0.6786 Epoch 26/30 5/5 [==============================] - 47s 9s/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.8105 - val_acc: 0.6786 Epoch 27/30 5/5 [==============================] - 47s 9s/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.7799 - val_acc: 0.7143 Epoch 28/30 5/5 [==============================] - 47s 9s/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.7668 - val_acc: 0.7500 Epoch 29/30 5/5 [==============================] - 47s 9s/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.7632 - val_acc: 0.7500 Epoch 30/30 5/5 [==============================] - 47s 9s/step - loss: 0.0314 - acc: 1.0000 - val_loss: 0.7610 - val_acc: 0.7857 TEXT ONLY MODEL - In this model, we shall be relying only on textual metadata for each of the image. We shall be using the embedding from pretrained GloVe model. Each word in a GloVe model is represented by a vector of size 100 trained on a corpus of wikepedia. There are many other model available trained on different text corpus. For more detail, check out the Glove Project . Please note that for a text only model, we shall be ignoring the image data. In [20]: def build_text_only_model ( text_input_shape = ( 26 ,), image_input_shape = ( 256 , 256 , 3 ), pretrained_model = 'vgg19' , classes = 245 ): print ( 'received pretrained model %s ' % pretrained_model ) vis_input = Input ( shape = text_input_shape , name = \"vis_input\" ) img_input = Input ( shape = image_input_shape , name = \"img_input\" ) text_emb = Embedding ( embedding_matrix . shape [ 0 ], embedding_matrix . shape [ 1 ], weights = [ embedding_matrix ], trainable = False )( vis_input ) text_emb = Conv1D ( 128 , 3 , padding = 'same' )( text_emb ) text_emb = Activation ( 'relu' )( text_emb ) text_emb = MaxPooling1D ( 2 )( text_emb ) text_emb = Conv1D ( 256 , 3 , padding = 'same' )( text_emb ) text_emb = Activation ( 'relu' )( text_emb ) text_emb = MaxPooling1D ( 2 )( text_emb ) text_emb = Dropout ( 0.2 )( text_emb ) text_emb = Flatten ()( text_emb ) text_emb = Dense ( 512 , kernel_regularizer = regularizers . l2 ( weight_decay ))( text_emb ) text_emb = Activation ( 'relu' )( text_emb ) final_output = Dense ( classes , activation = 'softmax' )( text_emb ) model = Model ( inputs = [ vis_input , img_input ], outputs = final_output , name = \"model\" ) model . summary ( line_length = 200 ) opt = SGD ( lr = 0.01 ) model . compile ( optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) return model In [26]: tboard = keras . callbacks . TensorBoard ( log_dir = './logs' , histogram_freq = 0 , batch_size = 32 , write_graph = True , write_grads = False , write_images = False , embeddings_freq = 0 , embeddings_layer_names = None , embeddings_metadata = None , embeddings_data = None ) validation_data_gen = prepare_training_generators ( test_data , len ( unique_classes ), chunk_size = len ( test_data ) , channel_orientation = \"channels_last\" ) train_data_gen = prepare_training_generators ( train_data , len ( unique_classes ), chunk_size = batch_size , channel_orientation = \"channels_last\" ) text_only_model = build_text_only_model ( text_input_shape = ( max_seq_len ,), image_input_shape = ( 256 , 256 , 3 ) , classes = len ( unique_classes )) received pretrained model vgg19 ________________________________________________________________________________________________________________________________________________________________________________________________________ Layer (type) Output Shape Param # ======================================================================================================================================================================================================== vis_input (InputLayer) (None, 177) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ embedding_3 (Embedding) (None, 177, 100) 184700 ________________________________________________________________________________________________________________________________________________________________________________________________________ conv1d_5 (Conv1D) (None, 177, 128) 38528 ________________________________________________________________________________________________________________________________________________________________________________________________________ activation_7 (Activation) (None, 177, 128) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ max_pooling1d_5 (MaxPooling1D) (None, 88, 128) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ conv1d_6 (Conv1D) (None, 88, 256) 98560 ________________________________________________________________________________________________________________________________________________________________________________________________________ activation_8 (Activation) (None, 88, 256) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ max_pooling1d_6 (MaxPooling1D) (None, 44, 256) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ dropout_9 (Dropout) (None, 44, 256) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ flatten_5 (Flatten) (None, 11264) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ dense_10 (Dense) (None, 512) 5767680 ________________________________________________________________________________________________________________________________________________________________________________________________________ activation_9 (Activation) (None, 512) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ dense_11 (Dense) (None, 5) 2565 ======================================================================================================================================================================================================== Total params: 6,092,033 Trainable params: 5,907,333 Non-trainable params: 184,700 ________________________________________________________________________________________________________________________________________________________________________________________________________ In [27]: history3 = text_only_model . fit_generator ( train_data_gen , steps_per_epoch = np . ceil ( len ( train_data ) / batch_size ), epochs = 30 , validation_data = validation_data_gen , validation_steps = 1 , verbose = 1 , callbacks = [ tboard ]) Epoch 1/30 5/5 [==============================] - 5s 1s/step - loss: 4.6729 - acc: 0.0568 - val_loss: 1.6772 - val_acc: 0.1786 Epoch 2/30 5/5 [==============================] - 5s 990ms/step - loss: 1.6183 - acc: 0.2531 - val_loss: 1.6669 - val_acc: 0.3214 Epoch 3/30 5/5 [==============================] - 5s 1s/step - loss: 1.6445 - acc: 0.5403 - val_loss: 1.6566 - val_acc: 0.2857 Epoch 4/30 5/5 [==============================] - 5s 1s/step - loss: 1.5847 - acc: 0.4982 - val_loss: 1.5738 - val_acc: 0.1786 Epoch 5/30 5/5 [==============================] - 5s 990ms/step - loss: 1.5017 - acc: 0.3668 - val_loss: 1.4814 - val_acc: 0.3214 Epoch 6/30 5/5 [==============================] - 5s 994ms/step - loss: 1.3332 - acc: 0.4458 - val_loss: 1.4417 - val_acc: 0.3214 Epoch 7/30 5/5 [==============================] - 5s 1000ms/step - loss: 1.1944 - acc: 0.6332 - val_loss: 1.4272 - val_acc: 0.4643 Epoch 8/30 5/5 [==============================] - 5s 989ms/step - loss: 1.0071 - acc: 0.7476 - val_loss: 1.3675 - val_acc: 0.4643 Epoch 9/30 5/5 [==============================] - 5s 993ms/step - loss: 0.7612 - acc: 0.8288 - val_loss: 1.2863 - val_acc: 0.5000 Epoch 10/30 5/5 [==============================] - 5s 996ms/step - loss: 0.5747 - acc: 0.8812 - val_loss: 1.1363 - val_acc: 0.6786 Epoch 11/30 5/5 [==============================] - 5s 992ms/step - loss: 0.3890 - acc: 0.9387 - val_loss: 1.0973 - val_acc: 0.6429 Epoch 12/30 5/5 [==============================] - 5s 995ms/step - loss: 0.2774 - acc: 0.9586 - val_loss: 1.0828 - val_acc: 0.6071 Epoch 13/30 5/5 [==============================] - 5s 995ms/step - loss: 0.1826 - acc: 0.9919 - val_loss: 1.1286 - val_acc: 0.6429 Epoch 14/30 5/5 [==============================] - 5s 988ms/step - loss: 0.1488 - acc: 0.9757 - val_loss: 1.0737 - val_acc: 0.6786 Epoch 15/30 5/5 [==============================] - 5s 992ms/step - loss: 0.1154 - acc: 0.9919 - val_loss: 1.1121 - val_acc: 0.6071 Epoch 16/30 5/5 [==============================] - 5s 993ms/step - loss: 0.1057 - acc: 0.9919 - val_loss: 1.2667 - val_acc: 0.6429 Epoch 17/30 5/5 [==============================] - 5s 995ms/step - loss: 0.1019 - acc: 0.9793 - val_loss: 1.1540 - val_acc: 0.6786 Epoch 18/30 5/5 [==============================] - 5s 996ms/step - loss: 0.0849 - acc: 1.0000 - val_loss: 1.4471 - val_acc: 0.7143 Epoch 19/30 5/5 [==============================] - 5s 993ms/step - loss: 0.0940 - acc: 0.9793 - val_loss: 1.4991 - val_acc: 0.6429 Epoch 20/30 5/5 [==============================] - 5s 996ms/step - loss: 0.0848 - acc: 0.9919 - val_loss: 1.4331 - val_acc: 0.6429 Epoch 21/30 5/5 [==============================] - 5s 995ms/step - loss: 0.0883 - acc: 0.9919 - val_loss: 1.1204 - val_acc: 0.7143 Epoch 22/30 5/5 [==============================] - 5s 991ms/step - loss: 0.0818 - acc: 0.9919 - val_loss: 1.2926 - val_acc: 0.7143 Epoch 23/30 5/5 [==============================] - 5s 988ms/step - loss: 0.1014 - acc: 0.9874 - val_loss: 1.3596 - val_acc: 0.6786 Epoch 24/30 5/5 [==============================] - 5s 991ms/step - loss: 0.0820 - acc: 0.9919 - val_loss: 1.1890 - val_acc: 0.6429 Epoch 25/30 5/5 [==============================] - 5s 989ms/step - loss: 0.0909 - acc: 0.9919 - val_loss: 1.3454 - val_acc: 0.6429 Epoch 26/30 5/5 [==============================] - 5s 997ms/step - loss: 0.0737 - acc: 1.0000 - val_loss: 1.3541 - val_acc: 0.6786 Epoch 27/30 5/5 [==============================] - 5s 997ms/step - loss: 0.0733 - acc: 0.9919 - val_loss: 1.2650 - val_acc: 0.7143 Epoch 28/30 5/5 [==============================] - 5s 1s/step - loss: 0.0772 - acc: 0.9838 - val_loss: 1.2754 - val_acc: 0.7143 Epoch 29/30 5/5 [==============================] - 5s 996ms/step - loss: 0.0784 - acc: 0.9919 - val_loss: 1.2389 - val_acc: 0.7143 Epoch 30/30 5/5 [==============================] - 5s 996ms/step - loss: 0.0793 - acc: 0.9919 - val_loss: 1.2980 - val_acc: 0.7143 IMAGE PLUS TEXT MODEL - In this model, we shall be leveraging the image as well as textual data. The image plus text model is basically a concatenation of embeddings from image model and embeddings from text model. For fair comparison, the model architecture for image as well as text model are exactly the same as trained in previous cases. In [23]: def build_image_text_model ( text_input_shape = ( 26 ,), image_input_shape = ( 256 , 256 , 3 ), pretrained_model = 'vgg19' , classes = 245 ): print ( 'received pretrained model %s ' % pretrained_model ) vis_input = Input ( shape = text_input_shape , name = \"vis_input\" ) if pretrained_model == 'inception' : pretrained_model = InceptionV3 ( include_top = False , input_shape = image_input_shape , weights = 'imagenet' ) elif pretrained_model == 'xception' : pretrained_model = Xception ( include_top = False , input_shape = image_input_shape , weights = 'imagenet' ) elif pretrained_model == 'resnet50' : pretrained_model = ResNet50 ( include_top = False , input_shape = image_input_shape , weights = 'imagenet' ) elif pretrained_model == 'vgg19' : pretrained_model = VGG19 ( include_top = False , input_shape = image_input_shape , weights = 'imagenet' ) elif pretrained_model == 'all' : input = Input ( shape = image_input_shape ) inception_model = InceptionV3 ( include_top = False , input_tensor = input , weights = 'imagenet' ) xception_model = Xception ( include_top = False , input_tensor = input , weights = 'imagenet' ) resnet_model = ResNet50 ( include_top = False , input_tensor = input , weights = 'imagenet' ) flattened_outputs = [ Flatten ()( inception_model . output ), Flatten ()( xception_model . output ), Flatten ()( resnet_model . output )] output = Concatenate ()( flattened_outputs ) pretrained_model = Model ( input , output ) # We can select from inception, xception, resnet50, vgg19, or a combination of the first three as the basis for our image classifier. We specify include_top=False in these models in order to remove the top level classification layers. These are the layers used to classify images into the categories of the ImageNet competition; since our categories are different, we can remove these top layers and replace them with our own. # def get_model(pretrained_model, all_character_names) continued... if pretrained_model . output . shape . ndims > 2 : output = Flatten ()( pretrained_model . output ) else : output = pretrained_model . output output = BatchNormalization ()( output ) output = Dropout ( 0.2 )( output ) output = Dense ( 128 , activation = 'relu' )( output ) output = BatchNormalization ()( output ) output = Dropout ( 0.2 )( output ) output = Dense ( 256 , activation = 'relu' )( output ) output = BatchNormalization ()( output ) output = Dropout ( 0.2 )( output ) text_emb = Embedding ( embedding_matrix . shape [ 0 ], embedding_matrix . shape [ 1 ], weights = [ embedding_matrix ], trainable = False )( vis_input ) text_emb = Conv1D ( 128 , 3 , padding = 'same' )( text_emb ) text_emb = Activation ( 'relu' )( text_emb ) text_emb = MaxPooling1D ( 2 )( text_emb ) text_emb = Conv1D ( 256 , 3 , padding = 'same' )( text_emb ) text_emb = Activation ( 'relu' )( text_emb ) text_emb = MaxPooling1D ( 2 )( text_emb ) text_emb = Dropout ( 0.2 )( text_emb ) text_emb = Flatten ()( text_emb ) text_emb = Dense ( 512 , kernel_regularizer = regularizers . l2 ( weight_decay ))( text_emb ) text_emb = Activation ( 'relu' )( text_emb ) img_plus_text_emb = concatenate ([ output , text_emb ], axis =- 1 ) final_output = Dense ( classes , activation = 'softmax' )( img_plus_text_emb ) model = Model ( inputs = [ vis_input , pretrained_model . input ], outputs = final_output , name = \"model\" ) for layer in pretrained_model . layers : layer . trainable = False model . summary ( line_length = 200 ) opt = SGD ( lr = 0.02 ) model . compile ( optimizer = 'rmsprop' , loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) return model In [24]: tboard = keras . callbacks . TensorBoard ( log_dir = './logs' , histogram_freq = 0 , batch_size = 32 , write_graph = True , write_grads = False , write_images = False , embeddings_freq = 0 , embeddings_layer_names = None , embeddings_metadata = None , embeddings_data = None ) validation_data_gen = prepare_training_generators ( test_data , len ( unique_classes ), chunk_size = len ( test_data ) , channel_orientation = \"channels_last\" ) train_data_gen = prepare_training_generators ( train_data , len ( unique_classes ), channel_orientation = \"channels_last\" ) image_text_model = build_image_text_model ( text_input_shape = ( max_seq_len ,), image_input_shape = ( 256 , 256 , 3 ) , classes = len ( unique_classes )) received pretrained model vgg19 ________________________________________________________________________________________________________________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ======================================================================================================================================================================================================== input_2 (InputLayer) (None, 256, 256, 3) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ block1_conv1 (Conv2D) (None, 256, 256, 64) 1792 input_2[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ block1_conv2 (Conv2D) (None, 256, 256, 64) 36928 block1_conv1[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ block1_pool (MaxPooling2D) (None, 128, 128, 64) 0 block1_conv2[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ block2_conv1 (Conv2D) (None, 128, 128, 128) 73856 block1_pool[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ block2_conv2 (Conv2D) (None, 128, 128, 128) 147584 block2_conv1[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ block2_pool (MaxPooling2D) (None, 64, 64, 128) 0 block2_conv2[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ block3_conv1 (Conv2D) (None, 64, 64, 256) 295168 block2_pool[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ block3_conv2 (Conv2D) (None, 64, 64, 256) 590080 block3_conv1[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ block3_conv3 (Conv2D) (None, 64, 64, 256) 590080 block3_conv2[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ block3_conv4 (Conv2D) (None, 64, 64, 256) 590080 block3_conv3[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ block3_pool (MaxPooling2D) (None, 32, 32, 256) 0 block3_conv4[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ block4_conv1 (Conv2D) (None, 32, 32, 512) 1180160 block3_pool[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ block4_conv2 (Conv2D) (None, 32, 32, 512) 2359808 block4_conv1[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ block4_conv3 (Conv2D) (None, 32, 32, 512) 2359808 block4_conv2[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ block4_conv4 (Conv2D) (None, 32, 32, 512) 2359808 block4_conv3[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ block4_pool (MaxPooling2D) (None, 16, 16, 512) 0 block4_conv4[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ block5_conv1 (Conv2D) (None, 16, 16, 512) 2359808 block4_pool[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ block5_conv2 (Conv2D) (None, 16, 16, 512) 2359808 block5_conv1[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ block5_conv3 (Conv2D) (None, 16, 16, 512) 2359808 block5_conv2[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ vis_input (InputLayer) (None, 177) 0 ________________________________________________________________________________________________________________________________________________________________________________________________________ block5_conv4 (Conv2D) (None, 16, 16, 512) 2359808 block5_conv3[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ embedding_2 (Embedding) (None, 177, 100) 184700 vis_input[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ block5_pool (MaxPooling2D) (None, 8, 8, 512) 0 block5_conv4[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ conv1d_3 (Conv1D) (None, 177, 128) 38528 embedding_2[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ flatten_3 (Flatten) (None, 32768) 0 block5_pool[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ activation_4 (Activation) (None, 177, 128) 0 conv1d_3[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ batch_normalization_4 (BatchNormalization) (None, 32768) 131072 flatten_3[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ max_pooling1d_3 (MaxPooling1D) (None, 88, 128) 0 activation_4[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ dropout_5 (Dropout) (None, 32768) 0 batch_normalization_4[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ conv1d_4 (Conv1D) (None, 88, 256) 98560 max_pooling1d_3[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ dense_6 (Dense) (None, 128) 4194432 dropout_5[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ activation_5 (Activation) (None, 88, 256) 0 conv1d_4[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ batch_normalization_5 (BatchNormalization) (None, 128) 512 dense_6[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ max_pooling1d_4 (MaxPooling1D) (None, 44, 256) 0 activation_5[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ dropout_6 (Dropout) (None, 128) 0 batch_normalization_5[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ dropout_8 (Dropout) (None, 44, 256) 0 max_pooling1d_4[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ dense_7 (Dense) (None, 256) 33024 dropout_6[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ flatten_4 (Flatten) (None, 11264) 0 dropout_8[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ batch_normalization_6 (BatchNormalization) (None, 256) 1024 dense_7[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ dense_8 (Dense) (None, 512) 5767680 flatten_4[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ dropout_7 (Dropout) (None, 256) 0 batch_normalization_6[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ activation_6 (Activation) (None, 512) 0 dense_8[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ concatenate_1 (Concatenate) (None, 768) 0 dropout_7[0][0] activation_6[0][0] ________________________________________________________________________________________________________________________________________________________________________________________________________ dense_9 (Dense) (None, 5) 3845 concatenate_1[0][0] ======================================================================================================================================================================================================== Total params: 30,477,761 Trainable params: 10,202,373 Non-trainable params: 20,275,388 ________________________________________________________________________________________________________________________________________________________________________________________________________ In [25]: history2 = image_text_model . fit_generator ( train_data_gen , steps_per_epoch = np . ceil ( len ( train_data ) / batch_size ), epochs = 30 , validation_data = validation_data_gen , validation_steps = 1 , verbose = 1 , callbacks = [ tboard ]) Epoch 1/30 5/5 [==============================] - 20s 4s/step - loss: 0.5665 - acc: 0.8000 - val_loss: 11.2703 - val_acc: 0.2857 Epoch 2/30 5/5 [==============================] - 18s 4s/step - loss: 4.5975 - acc: 0.4400 - val_loss: 2.4112 - val_acc: 0.2500 Epoch 3/30 5/5 [==============================] - 17s 3s/step - loss: 1.7102 - acc: 0.5200 - val_loss: 2.2272 - val_acc: 0.3571 Epoch 4/30 5/5 [==============================] - 17s 3s/step - loss: 1.9602 - acc: 0.2800 - val_loss: 1.8663 - val_acc: 0.3571 Epoch 5/30 5/5 [==============================] - 18s 4s/step - loss: 1.7058 - acc: 0.3200 - val_loss: 1.8315 - val_acc: 0.2857 Epoch 6/30 5/5 [==============================] - 18s 4s/step - loss: 1.6524 - acc: 0.2800 - val_loss: 1.4536 - val_acc: 0.4286 Epoch 7/30 5/5 [==============================] - 18s 4s/step - loss: 1.9054 - acc: 0.2000 - val_loss: 1.2263 - val_acc: 0.6071 Epoch 8/30 5/5 [==============================] - 18s 4s/step - loss: 1.4382 - acc: 0.3600 - val_loss: 1.2956 - val_acc: 0.3929 Epoch 9/30 5/5 [==============================] - 18s 4s/step - loss: 1.5843 - acc: 0.2800 - val_loss: 0.9134 - val_acc: 0.6786 Epoch 10/30 5/5 [==============================] - 18s 4s/step - loss: 0.8839 - acc: 0.7600 - val_loss: 1.0124 - val_acc: 0.5714 Epoch 11/30 5/5 [==============================] - 18s 4s/step - loss: 0.6852 - acc: 0.6800 - val_loss: 0.7815 - val_acc: 0.7143 Epoch 12/30 5/5 [==============================] - 18s 4s/step - loss: 0.8132 - acc: 0.6400 - val_loss: 0.6712 - val_acc: 0.7857 Epoch 13/30 5/5 [==============================] - 18s 4s/step - loss: 0.4837 - acc: 0.8400 - val_loss: 0.8353 - val_acc: 0.6786 Epoch 14/30 5/5 [==============================] - 18s 4s/step - loss: 0.3001 - acc: 0.9600 - val_loss: 0.5340 - val_acc: 0.8214 Epoch 15/30 5/5 [==============================] - 18s 4s/step - loss: 0.1669 - acc: 1.0000 - val_loss: 1.0969 - val_acc: 0.7143 Epoch 16/30 5/5 [==============================] - 18s 4s/step - loss: 0.1598 - acc: 0.9600 - val_loss: 0.5919 - val_acc: 0.7500 Epoch 17/30 5/5 [==============================] - 18s 4s/step - loss: 0.2748 - acc: 0.8800 - val_loss: 3.1193 - val_acc: 0.5357 Epoch 18/30 5/5 [==============================] - 18s 4s/step - loss: 0.4611 - acc: 0.9200 - val_loss: 0.4943 - val_acc: 0.8571 Epoch 19/30 5/5 [==============================] - 18s 4s/step - loss: 0.1486 - acc: 0.9200 - val_loss: 0.4299 - val_acc: 0.8571 Epoch 20/30 5/5 [==============================] - 18s 4s/step - loss: 0.0507 - acc: 1.0000 - val_loss: 0.3753 - val_acc: 0.8929 Epoch 21/30 5/5 [==============================] - 18s 4s/step - loss: 0.0773 - acc: 1.0000 - val_loss: 0.3547 - val_acc: 0.9286 Epoch 22/30 5/5 [==============================] - 18s 4s/step - loss: 0.0479 - acc: 1.0000 - val_loss: 0.3802 - val_acc: 0.8571 Epoch 23/30 5/5 [==============================] - 18s 4s/step - loss: 0.0498 - acc: 1.0000 - val_loss: 0.3061 - val_acc: 0.8929 Epoch 24/30 5/5 [==============================] - 18s 4s/step - loss: 0.0738 - acc: 1.0000 - val_loss: 0.3495 - val_acc: 0.8214 Epoch 25/30 5/5 [==============================] - 18s 4s/step - loss: 0.0257 - acc: 1.0000 - val_loss: 0.3435 - val_acc: 0.8571 Epoch 26/30 5/5 [==============================] - 18s 4s/step - loss: 0.0267 - acc: 1.0000 - val_loss: 0.4079 - val_acc: 0.8214 Epoch 27/30 5/5 [==============================] - 18s 4s/step - loss: 0.0263 - acc: 1.0000 - val_loss: 0.2743 - val_acc: 0.9643 Epoch 28/30 5/5 [==============================] - 18s 4s/step - loss: 1.2119 - acc: 0.8800 - val_loss: 0.2463 - val_acc: 0.9286 Epoch 29/30 5/5 [==============================] - 18s 4s/step - loss: 0.0330 - acc: 1.0000 - val_loss: 0.2604 - val_acc: 0.8929 Epoch 30/30 5/5 [==============================] - 18s 4s/step - loss: 0.0269 - acc: 1.0000 - val_loss: 0.3244 - val_acc: 0.8571 Evaluation and Predictions - In this section, lets evaluate all the trained model and summarise the results Start off by initializing generators for evaluation and testing. Since we have very less data to work, we shall be using the same data (test_data) for evauation as well as testing. Ideally the entire dataset should be split into 3 datasets, viz. train, validation and test. It is important to note that test data should be used only for computing the true of estimation of accuracy. Next, we shall leverage the evaluate_generator function predict_generator function for summarising the results. In [44]: validation_data_gen = prepare_training_generators ( test_data , len ( unique_classes ), chunk_size = len ( test_data ) , channel_orientation = \"channels_last\" ) test_data_gen = prepare_test_generators ( test_data , len ( unique_classes ), chunk_size = len ( test_data ) , channel_orientation = \"channels_last\" ) In [45]: image_only_score = image_only_model . evaluate_generator ( validation_data_gen , 1 , use_multiprocessing = False ) print ( \"image only model - Loss: \" , image_only_score [ 0 ], \"Accuracy: \" , image_only_score [ 1 ]) text_only_score = text_only_model . evaluate_generator ( validation_data_gen , 1 , use_multiprocessing = False ) print ( \"Text only model Loss: \" , text_only_score [ 0 ], \"Accuracy: \" , text_only_score [ 1 ]) image_text_score = image_text_model . evaluate_generator ( validation_data_gen , 1 , use_multiprocessing = False ) print ( \"Image Text model Loss: \" , image_text_score [ 0 ], \"Accuracy: \" , image_text_score [ 1 ]) image only model - Loss: 0.7610096335411072 Accuracy: 0.7857142686843872 Text only model Loss: 1.2980186939239502 Accuracy: 0.7142857313156128 Image Text model Loss: 0.3243611454963684 Accuracy: 0.8571428656578064 Classification Report - In [46]: y_pred_text_raw = text_only_model . predict_generator ( test_data_gen , steps = 1 ) y_pred_image_text_raw = image_text_model . predict_generator ( test_data_gen , steps = 1 ) y_pred_text = np . argmax ( y_pred_text_raw , axis =- 1 ) y_pred_image_text = np . argmax ( y_pred_image_text_raw , axis =- 1 ) y_test_labels = le . transform ( test_data [ 'label' ]) y_pred_text_readable = le . inverse_transform ( y_pred_text ) y_pred_image_text_readable = le . inverse_transform ( y_pred_image_text ) y_true_readable = le . inverse_transform ( y_test_labels ) In [47]: print ( \"classification report for text only model is - \" ) print ( classification_report ( y_true_readable , y_pred_text_readable )) print ( \"classification report for image plus text model is -\" ) print ( classification_report ( y_true_readable , y_pred_image_text_readable )) classification report for text only model is - precision recall f1-score support apples 0.64 0.88 0.74 8 iphone 0.00 0.00 0.00 3 peaches 0.71 1.00 0.83 5 pears 0.80 0.67 0.73 6 plums 0.80 0.67 0.73 6 avg / total 0.65 0.71 0.67 28 classification report for image plus text model is - precision recall f1-score support apples 1.00 1.00 1.00 8 iphone 1.00 1.00 1.00 3 peaches 1.00 0.60 0.75 5 pears 1.00 0.67 0.80 6 plums 0.60 1.00 0.75 6 avg / total 0.91 0.86 0.86 28 HURRAY !!! It can be clearly seen that a pure text based model is the poorest performer whereas the image plus text model is the best performing model. Lets summarise some of the findings - A pure text based model has a decent performance and trains faster as compared to other model especially when an anamoly was intentionally induced by using the same metadata for apple- The Fruit and apple - iPhone. In my opinion, even a pure text based can do much better with more training data. Having said that, that is whole point to this exercise - to check if we can model the training better by leveraging all the information at our disposal. Such a model is typical be beneficial when 'limited' training data is available. It was always an uphill task for a pure image based model which was evident from the visualization exercise done at the start of this article. The fruits selected for training a model are visually very similar. I was expecting the image plus text model to do a little better than 85% but nevertheless its a sizeable gain in performance. If you closely observe the epoch accuracies, it can be seen that the model training starts off slow with training accuracies in the range of 14% - 30% for the first 5-8 iterations. Post that the model takes a huge leap in training accuracy. It can be seen that all the pitfalls of a pure text based model are overcome by a image plus text model which has successfully learnt to rely on pixel data when it comes to apples. I feel , thats awesome !! References - [1] https://en.wikipedia.org/wiki/Apple [2] https://www.britannica.com/plant/apple-fruit-and-tree [3] https://food.ndtv.com/food-drinks/apple-fruit-benefits-8-incredible-health-benefits-of-apple-that-you-may-not-have-known-1761603 [4] https://freecontent.manning.com/deep-learning-for-text/ [5] https://nlp.stanford.edu/projects/glove/ In [ ]: if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Deep Learning","loc":"/image_text_classification.html","title":"Product Classificatication Using Image and Text (Deep Learning)"},{"url":"/Logistic Regression from scratch..html","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ Classification Algorithms - Classification is a branch of supervised machine learning algorithms where target values are discrete. Problem Definition - Suppose you are working as Supervising officer at a food packaging company where your department handles packaging of 'Apples' and 'Bananas'. However, a bottleneck in the packaging process is the fact that currently, fruits are sorted manually by a team of 10 people. However, in order to improve productivity, you would like to add more layer of processing to the packaging process wherein a camera captures the image of the incoming fruit and automatically sorts it into categories 'Apples' v/s 'Bananas'. In this case, a traditional classification algorithm like Logistic Regression can definitely help us. So, lets dive right into it. Lets Start by import python libraries that will help us accomplish the task In [1]: ## python libraries import pandas as pd import numpy as np ## import sklearn for loading mnist data from sklearn.datasets import load_breast_cancer from sklearn.preprocessing import MinMaxScaler from IPython.core.display import display , HTML display ( HTML ( '<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>' )) display ( HTML ( \"<style>.container { width:100% !important; }</style>\" )) /usr/local/lib/python2.7/dist-packages/sklearn/utils/fixes.py:313: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change. _nan_object_mask = _nan_object_array != _nan_object_array .prompt{width: 0px; min-width: 0px; visibility: collapse} .container { width:100% !important; } $Notations \\ that \\ we \\ will \\ be \\ using \\ throughout \\ are \\ as \\ follows -$ \\begin{align}X - Input \\ data \\end{align} \\begin{align}Y - Target \\ labels \\end{align} \\begin{align}W - \\ weights \\ vector \\ (to \\ be \\ estimated \\ using \\ training \\ data) \\end{align} \\begin{align}b - \\ intercept \\ for \\ the \\ decision \\ boundary \\end{align} $Notations \\ for \\ tracking \\ dimensions \\ are \\ as \\ follows-$ \\begin{align}m - number \\ of \\ training \\ examples \\end{align} \\begin{align}n - number \\ of \\ input \\ features \\end{align} \\begin{align}k - \\ size \\ of \\ labels \\ vector (In \\ case \\ of \\ binary \\ classification,\\ k\\ =\\ 1) \\end{align} Load Cancer dataset provided by sklearn In [2]: def load_breast_cancer_dataset (): ''' This function loads the dataset. It also prints the description of the dataset. ''' data_dict = load_breast_cancer () X , Y = data_dict [ 'data' ], data_dict [ 'target' ] #use transpose to match the dimesions defined above Y = Y . reshape ( len ( Y ), 1 ) # reshape the label vector so that it has a dimesion of k x m return X , Y In [3]: X , Y = load_breast_cancer_dataset () print \"successfully loaded training data with %d training data and %d features\" % ( X . shape [ 0 ], X . shape [ 1 ]) successfully loaded training data with 569 training data and 30 features Leverage the built in normalization techniques provided by sklearn. In [4]: scaler = MinMaxScaler () X = scaler . fit_transform ( X ) print X . shape , Y . shape (569, 30) (569, 1) $\\ While \\ implementing \\ logistic \\ Regression \\ from \\ scratch, \\ it \\ is \\ important \\ to \\ keep \\ track \\ of \\ dimensions.$ $\\ For \\ this \\ tutorial, \\ we \\ shall \\ use \\ following \\ dimensions -$ \\begin{equation*} \\tag{1}\\label{1} X =\\ m \\times \\ n \\ \\end{equation*} \\begin{align}\\tag{2}\\label{2} Y = \\ m \\times \\ 1 \\end{align} \\begin{align}\\tag{3}\\label{3} W = \\ 1 \\times \\ n \\end{align} \\begin{align}\\tag{4}\\label{4}b = \\ 1 \\times \\ 1 \\end{align} The pseudo-code for training a Logistic Regression model is as follows - Step 1 - Given a Training DataSet X and corresponding labels Y, initialize values of number of training examples(m), number of features(n) and number of output units (k) as mentioned in equations \\ref{1}, \\ref{2}, \\ref{3} and \\ref{4} Step 2 - Initialize Weights matrix W and bias b using dimensions from Step 1. \\begin{equation} for\\ \\ \\ i_{epoch}\\ \\ \\ in\\ \\ \\ range(iterations):\\end{equation} Step 3 - Forward Propagation - Step 3.1 compute preactivations using \\ref{5} \\begin{align} pre\\_activations \\ (Z) = XW&#94;T +b \\tag{5}\\label{5} \\end{align} Lets validate if the dimensions match - \\begin{equation} preactivations \\ (Z) = \\mathbf{(\\ m \\times \\ n )} \\times \\ \\mathbf{(1 \\times \\ n)}&#94;\\intercal \\ + \\ (1 \\times 1) \\end{equation} We are good to move ahead. Step 3.2 - Compute Activation using equation \\ref{6} \\begin{align} activations \\ (A) = \\sigma(Z) = \\ \\frac{1}{1 + e&#94;{-(Z)}} \\tag{6}\\label{6} \\end{align} Note that the dimensions of activations are same as dimensions of preactivations. Step 3.3 - Compute loss /error /cost using \\ref{7} \\begin{align} cost = - \\ \\frac{1}{m} \\sum_{i =1}&#94;{m} y_i \\log(A_i) + \\ (1-y_i) \\log(1-A_i) \\tag{7} \\label{7} \\end{align} It is important to note that, cost/error/loss is a scaler which we would like to minimize using gradient descent. Step 4 - Back Propagation We shall derive the grdients using chain rule - \\begin{equation} \\frac{\\partial L}{\\partial W} \\ = \\ \\frac{\\partial L}{\\partial A} \\frac{\\partial A}{\\partial Z} \\frac{\\partial Z}{\\partial W} \\tag{8}\\label{8} \\end{equation} Lets Start by computing the partial derivative - $\\frac{\\partial L}{\\partial A}$ \\begin{align} \\frac{\\partial L}{\\partial A} & = \\frac{\\partial }{\\partial A} \\Big[ - \\ \\sum_{i =1}&#94;{m} y_i \\log(A_i) + \\ (1-y_i) \\log(1-A_i)\\Big] \\end{align} For one training example $i$ - \\begin{align} \\frac{\\partial L}{\\partial A} & = - \\Big[y&#94;{(i)} \\frac{\\partial log(A)}{\\partial A} + (1-y&#94;{(i)}) \\frac{\\partial log(1-A)}{ \\partial A} \\Big] \\\\ & = - \\Big[ \\frac{y&#94;{(i)}}{A} - \\frac{1-y&#94;{(i)}}{1-A}\\Big] \\tag{9} \\label{9} \\end{align} Now lets compute the partial derivative $\\frac{\\partial A}{\\partial Z}$ \\begin{align} \\frac{\\partial A}{\\partial Z} & = \\frac{\\partial }{\\partial Z} \\Big[ \\frac{1}{1 + e&#94;{-(Z)}} \\Big] \\\\ & = \\frac{\\partial }{\\partial Z} \\Big[ \\Big(1+ e&#94;{(-Z)}\\Big)&#94;{-1} \\Big] \\\\ & = - \\Big(1+ e&#94;{-z})&#94;{-1} \\Big)&#94;{-2} \\frac {\\partial}{\\partial Z} \\Big( 1+ e&#94;{-Z} \\Big) \\\\ & = \\frac{- e&#94; {-z}} {(1+ e&#94;{-z})&#94;2} \\frac{\\partial }{\\partial Z} \\Big(-Z \\Big) \\\\ & = \\frac{e&#94;{-z}}{(1+ e&#94;{-Z})&#94;2} \\tag{10}\\label{10} \\end{align} Adding and Subtracting 1 in numerator of equation \\ref{10} \\begin{align} \\frac{\\partial A}{\\partial Z} & = \\frac{1+e&#94;{-Z} -1}{(1+e&#94;{-Z})&#94;2} \\\\ & = \\frac{1 +e&#94;{-Z}}{(1+e&#94;{-Z})&#94;2} - \\frac{1}{(1+e&#94;{-Z})&#94;2} \\\\ & = \\frac{1}{(1+e&#94;{-Z})} - \\frac{1}{(1+e&#94;{-Z})&#94;2} \\tag{11}\\label{11} \\end{align} from equation \\ref{6} and \\ref{11}, we get - \\begin{align} \\frac{\\partial A}{\\partial Z} & = A- A&#94;2 \\\\ & = A(1-A) \\tag{12}\\label{12} \\end{align} Multiply equations \\ref{9} and \\ref{12}, we get \\begin{align} \\\\ \\frac{\\partial L}{\\partial Z} & = \\frac{\\partial L}{\\partial A} \\frac{\\partial A}{\\partial Z} \\\\ & = - \\Big[ \\frac{y&#94;{(i)}}{A} - \\frac{1-y&#94;{(i)}}{1-A}\\Big] A(1-A) \\\\ & = - \\Big[ y&#94;{(i)}(1 - A) - A (1 - y&#94;{(-i)}) \\Big] \\\\ & = - \\Big[ y&#94;{(i)} - \\require{cancel} \\cancel{y&#94;{(i)}A} - A + \\require{cancel} \\cancel{y&#94;{(i)}A }] \\\\ & = \\Big[ A - y&#94;{(-i)} \\Big] \\end{align} Now, The last part of this derivation to compute gradients with respect to weights/coeffiecients. \\begin{align}\\\\ \\frac{\\partial L}{\\partial W} & = \\frac{\\partial L}{\\partial Z} \\frac{\\partial Z}{\\partial W} \\\\ & = \\frac{\\partial L}{\\partial Z} \\Big[ \\frac{\\partial Z}{\\partial W_1} \\frac{\\partial Z}{\\partial W_2} .... \\frac{\\partial Z}{\\partial W_n}\\Big] \\end{align} The derivatives $\\Big[ \\frac{\\partial Z}{\\partial W_1} \\frac{\\partial Z}{\\partial W_2} .... \\frac{\\partial Z}{\\partial W_n}\\Big]$ can be easily calculated as follows - \\begin{align} \\\\ \\frac{\\partial Z}{\\partial W_1} & = \\frac{\\partial }{\\partial W_1} \\Big(x_1w_1 +x_2w_2 + ....+x_nw_n + b \\Big) \\\\ & = x_1 \\end{align} Similarly, \\begin{align} \\\\ \\frac{\\partial Z}{\\partial W_2} = x_2 \\\\ \\frac{\\partial Z}{\\partial W_3} = x_3 \\\\. \\\\. \\\\. \\frac{\\partial Z}{\\partial W_n} = x_n \\end{align} Now, the gradient of bias term b is simply - \\begin{align}\\\\ \\frac{\\partial L}{\\partial b} & = \\frac{\\partial L}{\\partial Z} \\frac{\\partial Z}{\\partial B} \\\\ & = (A - Y&#94;{(i)}) \\frac{\\partial }{\\partial b} \\Big(x_1w_1 +x_2w_2 + ....+x_nw_n + b \\Big) \\\\ & = (A - Y{(i)}) (1) \\end{align} Therefore, for one training example, the gradient wrt weights can be concisely computed using - \\begin{align} \\\\ \\frac{\\partial L}{\\partial W} = (A-Y&#94;{(i)}) [x_1&#94;{(i)} x_2&#94;{(i)} x_3&#94;{(i)} .... x_n&#94;{(i)}] \\\\ \\frac{\\partial L}{\\partial b} = (A-Y&#94;{(i)}) \\end{align} By extending the computations for one training example to m training examples, we get - \\begin{align} \\\\ \\frac{\\partial L}{\\partial W} = \\sum_{i =1}&#94;{m} \\frac{\\partial {L&#94;{(i)}}}{\\partial W} \\tag{13}\\label{13} \\\\ \\frac{\\partial L}{\\partial b} = \\sum_{i =1}&#94;{m} \\frac{\\partial {L&#94;{(i)}}}{\\partial b} \\tag{14}\\label{14} \\end{align} Equations \\ref{13} and \\ref{14} can be summarised as follows - \\begin{align} \\\\ \\frac{\\partial L}{\\partial W} = \\frac{1}{m}(A - Y)&#94;T X \\tag{15}\\label{15} \\\\ \\frac{\\partial L}{\\partial b} = \\frac{1}{m} \\sum_{i =1}&#94;{m} (A - Y&#94;{(i)}) \\tag{16}\\label{16} \\end{align} Step 4.1 The weights can be updated using gradient descent equations as follows - \\begin{align} \\\\ W = W - \\frac{\\partial L}{\\partial W} \\tag{17} \\label{17} \\\\ b = b - \\frac{\\partial L}{\\partial b} \\tag{18} \\label{18} \\end{align} In [5]: def initialize_dimensions ( X , Y ): ''' This function initializes the values of m, n and k m -> number of training examples n -> number of features k -> number of output labels (for binary classification, k= 1) ''' m , n = X . shape k = Y . shape [ 1 ] return m , n , k In [6]: def initialize_weights_with_zeros ( dim ): ''' This function initializes the weights vector and bias vector The genaral formula for Weights matrix and bias vector is - W --> number of output units x number of input features b --> 1 x number of output units ''' W = np . zeros ( shape = ( dim )) b = np . zeros ( shape = ( 1 , dim [ 0 ])) return W , b The formula for sigmoid is given by - \\begin{equation} \\sigma (z) = \\ \\frac{1}{1 + e&#94;{-z}} \\end{equation} In [7]: def sigmoid ( z ): ''' This function computes the sigmoid of vector (numpy array). ''' return 1.0 / ( 1 + np . exp ( - 1.0 * z )) The cost for logistic regression is given by - \\begin{equation} cost\\ (L) = - \\ \\frac{1}{m} \\sum_{i =1}&#94;{m} y_i \\log(A_i) + \\ (1-y_i) \\log(1-A_i) \\end{equation} $Where, \\\\ Y = vector\\ of\\ size\\ m \\times 1. \\\\ A = activations = \\sigma {(z)} -\\ vector\\ of\\ size\\ m\\ \\times\\ 1$ In [8]: def compute_sigmoid_cost ( Y , A , m ): cost = - 1.0 / m * np . sum (( Y * np . log ( A ) + (( 1 - Y ) * np . log ( 1 - A ))), axis = 0 ) return cost In [9]: def compute_sigmoid_gradients ( x , activations , y , m ): dw = 1.0 / m * np . dot (( activations - Y ) . T , X ) db = 1.0 / m * np . sum (( activations - Y ), axis = 0 , keepdims = True ) return dw , db In [10]: def propagation ( w , b , X , Y , m ): # FORWARD PROPAGATION (FROM X TO COST) z = ( np . dot ( X , w . T ) + b ) activations = sigmoid ( z ) cost = compute_sigmoid_cost ( Y , activations , X . shape [ 0 ]) # BACKWARD PROPAGATION (TO FIND GRAD) dw , db = compute_sigmoid_gradients ( X , activations , Y , m ) cost = np . squeeze ( cost ) grads = { \"dw\" : dw , \"db\" : db } return grads , cost In [11]: def train_logistic_regression ( X , Y , learning_rate = 0.2 , n_epochs = 3000 , print_cost = True ): m , n , k = initialize_dimensions ( X , Y ) w , b = initialize_weights_with_zeros (( k , n )) costs = [] for iteration in range ( n_epochs ): grad , cost = propagation ( w , b , X , Y , m ) dw = grad [ 'dw' ] db = grad [ 'db' ] w = w - learning_rate * dw b = b - learning_rate * db # Record the costs if iteration % 10 == 0 : costs . append ( cost ) # Print the cost every 100 training examples if print_cost and iteration % 500 == 0 : activations = sigmoid ( np . dot ( X , w . T ) + b ) y_pred = np . where ( activations > 0.5 , 1 , 0 ) accuracy = ( float ( np . sum ( y_pred [:, 0 ] == Y [:, 0 ])) / m ) * 100 display ( \"Cost after iteration %i : %f | accuracy after iteration %i : %f \" % ( iteration , cost , iteration , accuracy )) params = { \"w\" : w , \"b\" : b } grads = { \"dw\" : dw , \"db\" : db } return params , grads , costs In [12]: kl = train_logistic_regression ( X , Y , print_cost = True ) 'Cost after iteration 0: 0.693147 | accuracy after iteration 0: 65.026362' 'Cost after iteration 500: 0.219201 | accuracy after iteration 500: 94.376098' 'Cost after iteration 1000: 0.169860 | accuracy after iteration 1000: 95.254833' 'Cost after iteration 1500: 0.147171 | accuracy after iteration 1500: 96.836555' 'Cost after iteration 2000: 0.133237 | accuracy after iteration 2000: 96.836555' 'Cost after iteration 2500: 0.123533 | accuracy after iteration 2500: 96.836555' Awesome !!! We were able to achieve 95% accuracy using logistic regressions. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Machine Learning","loc":"/Logistic Regression from scratch..html","title":"Binary Classification using Logistic Regression using numpy"},{"url":"/Linear Regression using Numpy.html","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ Linear Regression Linear Regression is a statistical approach of modelling the realtionship between a scalar response (aka. dependent variable) and one or more explanatory variables (aka independent variables). Linear Regression is one of the most basic building block in Machine Learning algorithms. In most of the python libraries, linear regression model is available as a blackbox. However, it is imperative to understand what goes on under the hood in order to have better grasp of algorithm. This article will focus on implementing vanilla linear regression from scratch using numpy and pandas. Lets start by importing some basic python libraries. In [7]: import numpy as np import pandas as pd from sklearn import datasets from sklearn.preprocessing import MinMaxScaler from IPython.core.display import display , HTML display ( HTML ( '<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>' )) .prompt{width: 0px; min-width: 0px; visibility: collapse} $Notations \\ that \\ we \\ will \\ be \\ using \\ throughout \\ are \\ as \\ follows -$ \\begin{align}X - Input \\ data \\end{align} \\begin{align}Y - Target \\ labels \\end{align} \\begin{align}W - \\ weights \\ vector \\ (to \\ be \\ estimated \\ using \\ training \\ data) \\end{align} \\begin{align}b - \\ intercept \\ for \\ the \\ decision \\ boundary \\end{align} $ Notations \\ for \\ tracking \\ dimensions \\ are \\ as \\ follows- $ \\begin{align}m - number \\ of \\ training \\ examples \\end{align} \\begin{align}n - number \\ of \\ input \\ features \\end{align} \\begin{align}k - \\ size \\ of \\ labels \\ vector (In \\ case \\ of \\ binary \\ classification,\\ k\\ =\\ 1) \\end{align} Load Diabetes dataset provided by sklearn Diabetes dataset Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline. Data Set Characteristics: :Number of Instances: 442 :Number of Attributes: First 10 columns are numeric predictive values :Target: Column 11 is a quantitative measure of disease progression one year after baseline :Attribute Information: - Age - Sex - Body mass index - Average blood pressure - S1 - S2 - S3 - S4 - S5 - S6 Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times n_samples (i.e. the sum of squares of each column totals 1). Source URL: http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html For more information see: Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499. ( http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf ) In [8]: def load_diabetes_data (): diabetes = datasets . load_diabetes () X , Y = diabetes [ 'data' ], diabetes [ 'target' ] . reshape ( len ( diabetes [ 'target' ]), 1 ) return X , Y Helper functions for scaling data. We shall leverage the existing scaling function supported by Sklearn. In [9]: def get_scale_object ( data ): scaler = MinMaxScaler () scaler . fit ( data ) return scaler def get_scaled_data ( scaler , data ): return scaler . transform ( data ) $\\ While \\ implementing \\ Linear \\ Regression \\ from \\ scratch, \\ it \\ is \\ important \\ to \\ keep \\ track \\ of \\ dimensions.$ $\\ For \\ this \\ tutorial, \\ we \\ shall \\ use \\ following \\ dimensions -$ \\begin{equation*} \\tag{1}\\label{1} X =\\ m \\times \\ n \\ \\end{equation*} \\begin{align}\\tag{2}\\label{2} Y = \\ m \\times \\ 1 \\end{align} \\begin{align}\\tag{3}\\label{3} W = \\ 1 \\times \\ n \\end{align} \\begin{align}\\tag{4}\\label{4}b = \\ 1 \\times \\ 1 \\end{align} The pseudo-code for training a Linear Regression model is as follows - Step 1 - Given a Training DataSet X and corresponding labels Y, initialize values for number of training examples(m), number of features(n) and number of output units (k) as mentioned in equations \\ref{1}, \\ref{2}, \\ref{3} and \\ref{4} Step 2 - Initialize Weights matrix W and bias b using dimensions from Step 1. \\begin{equation} for\\ \\ \\ i_{epoch}\\ \\ \\ in\\ \\ \\ range(iterations):\\end{equation} Step 3 - Forward Propagation - Step 3.1 compute preactivations using \\ref{5} \\begin{align} y_{pred} = h(\\theta) = XW&#94;T +b \\tag{5}\\label{5} \\end{align} Lets validate if the dimensions match - \\begin{equation} dim(y_{pred}) = \\mathbf{(\\ m \\times \\ n )} \\times \\ \\mathbf{(1 \\times \\ n)}&#94;\\intercal \\ + \\ (1 \\times 1) \\end{equation} We are good to move ahead. Step 3.2 - Compute loss /error /cost using \\ref{6} \\begin{align} cost = - \\ \\frac{1}{2m} \\sum_{i =1}&#94;{m} (y_{true} - y_{pred})&#94;2 \\tag{7} \\label{6} \\end{align} The above equation represents the 'mean squared error' . It is important to note that, cost/ error/ loss is a scaler which we would like to minimize using gradient descent. Step 4 - Back propagation - Back propagation technique will help in updating the weights such that the MSE loss is minimized. Lets dig into the nuts and bolts of back propagation. We shall derive the gradients using chain rule - \\begin{equation} \\frac{\\partial L}{\\partial W} \\ = \\ \\frac{\\partial L}{\\partial h(\\theta)} \\frac{\\partial h(\\theta)}{\\partial W} \\tag{8}\\label{8} \\end{equation} Lets Start by computing the partial derivative - $\\frac{\\partial L}{\\partial h(\\theta)}$ \\begin{align} \\frac{\\partial L}{\\partial h(\\theta)} & = \\frac{\\partial }{\\partial h(\\theta)} \\Big[ - \\ \\frac{1}{2m} \\sum_{i =1}&#94;{m} (y_{true} - h(\\theta))&#94;2 \\Big] \\end{align} For one training example $i$ - \\begin{align} \\frac{\\partial L}{\\partial h(\\theta)} & = \\frac{-1}{2} \\frac{\\partial}{\\partial h(\\theta)} \\Big[(y_{true} - h(\\theta))&#94;2 \\Big]\\\\ & = \\frac{-1}{2} 2\\Big[ y_{true} - h(\\theta)\\Big] \\\\ & = -\\Big[ y_{true} - h(\\theta)\\Big] \\\\ & = \\Big[h(\\theta) - y_{true} \\Big] \\tag{9} \\label{9} \\end{align} Now, The last part of this derivation to compute gradients with respect to weights/coeffiecients. \\begin{align}\\\\ \\frac{\\partial L}{\\partial W} & = \\frac{\\partial L}{\\partial h(\\theta)} \\frac{\\partial h(\\theta)}{\\partial W} \\\\ & = \\frac{\\partial L}{\\partial h(\\theta)} \\Big[ \\frac{\\partial h(\\theta)}{\\partial W_1} \\frac{\\partial h(\\theta)}{\\partial W_2} .... \\frac{\\partial h(\\theta)}{\\partial W_n}\\Big] \\end{align} The derivatives $\\Big[ \\frac{\\partial Z}{\\partial W_1} \\frac{\\partial Z}{\\partial W_2} .... \\frac{\\partial Z}{\\partial W_n}\\Big]$ can be easily calculated as follows - \\begin{align} \\\\ \\frac{\\partial h(\\theta)}{\\partial W_1} & = \\frac{\\partial }{\\partial W_1} \\Big(x_1w_1 +x_2w_2 + ....+x_nw_n + b \\Big) \\\\ & = x_1 \\end{align} Similarly, \\begin{align} \\\\ \\frac{\\partial h(\\theta)}{\\partial W_2} = x_2 \\\\ \\frac{\\partial h(\\theta)}{\\partial W_3} = x_3 \\\\. \\\\. \\\\. \\frac{\\partial h(\\theta)}{\\partial W_n} = x_n \\end{align} Now, the gradient of bias term b is simply - \\begin{align}\\\\ \\frac{\\partial L}{\\partial b} & = \\frac{\\partial L}{\\partial h(\\theta)} \\frac{\\partial h(\\theta)}{\\partial B} \\\\ & = (h(\\theta) - Y&#94;{(i)}) \\frac{\\partial }{\\partial b} \\Big(x_1w_1 +x_2w_2 + ....+x_nw_n + b \\Big) \\\\ & = (h(\\theta) - Y{(i)}) (1) \\end{align} Therefore, for one training example, the gradient wrt weights can be concisely computed using - \\begin{align} \\\\ \\frac{\\partial L}{\\partial W} = (h(\\theta)-Y&#94;{(i)}) [x_1&#94;{(i)} x_2&#94;{(i)} x_3&#94;{(i)} .... x_n&#94;{(i)}] \\\\ \\frac{\\partial L}{\\partial b} = (h(\\theta)-Y&#94;{(i)}) \\end{align} By extending the computations for one training example to m training examples, we get - \\begin{align} \\\\ \\frac{\\partial L}{\\partial W} = \\sum_{i =1}&#94;{m} \\frac{\\partial {L&#94;{(i)}}}{\\partial W} \\tag{13}\\label{13} \\\\ \\frac{\\partial L}{\\partial b} = \\sum_{i =1}&#94;{m} \\frac{\\partial {L&#94;{(i)}}}{\\partial b} \\tag{14}\\label{14} \\end{align} Equations \\ref{13} and \\ref{14} can be summarised as follows - \\begin{align} \\\\ \\frac{\\partial L}{\\partial W} = \\frac{1}{m}(h(\\theta) - Y)&#94;T X \\tag{15}\\label{15} \\\\ \\frac{\\partial L}{\\partial b} = \\frac{1}{m} \\sum_{i =1}&#94;{m} (h(\\theta) - Y&#94;{(i)}) \\tag{16}\\label{16} \\end{align} Step 4.1 The weights can be updated using gradient descent equations as follows - \\begin{align} \\\\ W = W - \\frac{\\partial L}{\\partial W} \\tag{17} \\label{17} \\\\ b = b - \\frac{\\partial L}{\\partial b} \\tag{18} \\label{18} \\end{align} Implement Step 1- In [10]: raw_X , Y = load_diabetes_data () scaler = get_scale_object ( raw_X ) X = get_scaled_data ( scaler , raw_X ) Helper functions for initializing vectors In [11]: def initialize_dimensions ( X ): m , n = X . shape return m , n In [12]: def initialize_weight_vectors ( dim ): W = np . zeros ( shape = dim ) b = np . zeros ( shape = ( 1 , 1 )) return W , b Initialize weights vector In [13]: m , n = initialize_dimensions ( X ) W , b = initialize_weight_vectors (( 1 , n )) functions for computing cost and gradient descent - In [14]: def compute_regression_cost ( y , y_pred , m ): cost = ( 1.0 / ( 2 * m )) * ( np . sum ( y_pred - y ) ** 2 ) return cost In [15]: def compute_regression_gradients ( y_pred , y , X , m ): dw = ( 1.0 / m ) * np . dot (( y_pred - y ) . T , X ) db = ( 1.0 / m ) * np . sum (( y_pred - y ), axis = 1 , keepdims = True ) return dw , db In [16]: def propagation ( w , b , X , Y ): # FORWARD PROPAGATION (FROM X TO COST) z = ( np . dot ( X , w . T ) + b ) cost = compute_regression_cost ( Y , z , X . shape [ 1 ]) # BACKWARD PROPAGATION (TO FIND GRAD) dw , db = compute_regression_gradients ( z , Y , X , X . shape [ 0 ]) cost = np . squeeze ( cost ) grads = { \"dw\" : dw , \"db\" : db } return grads , cost In [27]: def train_linear_regression ( X , Y , learning_rate = 0.2 , n_epochs = 4000 , print_cost = True ): m , n = initialize_dimensions ( X ) print \"There are %d features and %d training examples\" % ( n , m ) w , b = initialize_weight_vectors (( 1 , n )) print \"W has a shape of %d rows and %d columns\" % ( w . shape [ 0 ], w . shape [ 1 ]) print \"b has a shape of %d rows and %d columns\" % ( b . shape [ 0 ], b . shape [ 1 ]) costs = [] for iteration in range ( n_epochs ): grad , cost = propagation ( w , b , X , Y ) dw = grad [ 'dw' ] db = grad [ 'db' ] w = w - learning_rate * dw b = b - learning_rate * db # Record the costs if iteration % 10 == 0 : costs . append ( cost ) # Print the cost every 100 training examples if print_cost and iteration % 100 == 0 : y_pred = np . dot ( X , w . T ) + b accuracy = np . sqrt ( np . mean (( y_pred - Y ) ** 2 )) display ( \"Cost after iteration %i : %f | rmse after iteration %i : %f \" % ( iteration , cost , iteration , accuracy )) params = { \"w\" : w , \"b\" : b } grads = { \"dw\" : dw , \"db\" : db } return params , grads , costs In [28]: params , _ , _ = train_linear_regression ( X , Y , print_cost = True ) y_predicted = ( np . dot ( X , params [ \"w\" ] . T ) + params [ \"b\" ]) rmse = np . sqrt ( np . mean (( y_predicted - Y ) ** 2 )) ssr = ( np . mean (( y_predicted - Y ) ** 2 )) sst = ( np . mean (( np . mean ( Y ) - Y ) ** 2 )) R2_score = 1.0 - ( ssr / sst ) display ( \"Model R2 score is %f \" % R2_score ) There are 10 features and 442 training examples W has a shape of 1 rows and 10 columns b has a shape of 1 rows and 1 columns 'Cost after iteration 0: 226081052.450000 | rmse after iteration 0: 116.990459' 'Cost after iteration 100: 10493.139458 | rmse after iteration 100: 54.158847' 'Cost after iteration 200: 16809.508859 | rmse after iteration 200: 50.085980' 'Cost after iteration 300: 16084.961670 | rmse after iteration 300: 47.451121' 'Cost after iteration 400: 13590.549152 | rmse after iteration 400: 45.204037' 'Cost after iteration 500: 11199.814693 | rmse after iteration 500: 43.133430' 'Cost after iteration 600: 9242.379808 | rmse after iteration 600: 41.182861' 'Cost after iteration 700: 7682.854204 | rmse after iteration 700: 39.331607' 'Cost after iteration 800: 6434.096605 | rmse after iteration 800: 37.569269' 'Cost after iteration 900: 5421.965490 | rmse after iteration 900: 35.889176' 'Cost after iteration 1000: 4591.795565 | rmse after iteration 1000: 34.286292' 'Cost after iteration 1100: 3904.114787 | rmse after iteration 1100: 32.756418' 'Cost after iteration 1200: 3330.014526 | rmse after iteration 1200: 31.295852' 'Cost after iteration 1300: 2847.813155 | rmse after iteration 1300: 29.901218' 'Cost after iteration 1400: 2440.854775 | rmse after iteration 1400: 28.569382' 'Cost after iteration 1500: 2096.074458 | rmse after iteration 1500: 27.297403' 'Cost after iteration 1600: 1803.047922 | rmse after iteration 1600: 26.082505' 'Cost after iteration 1700: 1553.344583 | rmse after iteration 1700: 24.922061' 'Cost after iteration 1800: 1340.073395 | rmse after iteration 1800: 23.813577' 'Cost after iteration 1900: 1157.554376 | rmse after iteration 1900: 22.754681' 'Cost after iteration 2000: 1001.074527 | rmse after iteration 2000: 21.743118' 'Cost after iteration 2100: 866.702205 | rmse after iteration 2100: 20.776741' 'Cost after iteration 2200: 751.143162 | rmse after iteration 2200: 19.853506' 'Cost after iteration 2300: 651.627104 | rmse after iteration 2300: 18.971463' 'Cost after iteration 2400: 565.817114 | rmse after iteration 2400: 18.128757' 'Cost after iteration 2500: 491.736553 | rmse after iteration 2500: 17.323615' 'Cost after iteration 2600: 427.709570 | rmse after iteration 2600: 16.554348' 'Cost after iteration 2700: 372.312324 | rmse after iteration 2700: 15.819347' 'Cost after iteration 2800: 324.332770 | rmse after iteration 2800: 15.117073' 'Cost after iteration 2900: 282.737338 | rmse after iteration 2900: 14.446059' 'Cost after iteration 3000: 246.643212 | rmse after iteration 3000: 13.804907' 'Cost after iteration 3100: 215.295183 | rmse after iteration 3100: 13.192279' 'Cost after iteration 3200: 188.046277 | rmse after iteration 3200: 12.606901' 'Cost after iteration 3300: 164.341477 | rmse after iteration 3300: 12.047553' 'Cost after iteration 3400: 143.704036 | rmse after iteration 3400: 11.513074' 'Cost after iteration 3500: 125.723922 | rmse after iteration 3500: 11.002354' 'Cost after iteration 3600: 110.048066 | rmse after iteration 3600: 10.514331' 'Cost after iteration 3700: 96.372095 | rmse after iteration 3700: 10.047994' 'Cost after iteration 3800: 84.433325 | rmse after iteration 3800: 9.602376' 'Cost after iteration 3900: 74.004814 | rmse after iteration 3900: 9.176553' 'Model R2 score is 0.987019' Incredible !! We have successfully trained a Linear Regression Algorithm. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Machine Learning","loc":"/Linear Regression using Numpy.html","title":"Linear regression using numpy"}]};