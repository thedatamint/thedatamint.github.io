
<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Binary Classification using Logistic Regression using numpy</title>

    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta name="author" content="Pritish Jadhav, Mrunal Jadhav" />
    <meta name="description" content="Logistic Regression is one the most basic algorithm on ML. With the likes of sklearn providing an off the shelf implementation of Linear Regression, it is very difficult to gain an insight on what really happens under the hood. This tutorial is aimed at implementing Logistic Regression from scratch in python using Numpy." />
    <meta name="keywords" content="python, logistic regression, machine learning, classification, supervised learning">
<!-- Facebook and Twitter integration -->
<meta property="og:site_name" content="thedatamint"/>
<meta property="og:title" content="Binary Classification using Logistic Regression using numpy"/>
<meta property="og:description" content="Logistic Regression is one the most basic algorithm on ML. With the likes of sklearn providing an off the shelf implementation of Linear Regression, it is very difficult to gain an insight on what really happens under the hood. This tutorial is aimed at implementing Logistic Regression from scratch in python using Numpy."/>
<meta property="og:url" content="/Logistic Regression from scratch..html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2018-07-08 18:00:00+05:30"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="/author/pritish-jadhav-mrunal-jadhav.html">
<meta property="article:section" content="Machine Learning"/>
    <meta property="article:tag" content="python"/>
    <meta property="article:tag" content="logistic regression"/>
    <meta property="article:tag" content="machine learning"/>
    <meta property="article:tag" content="classification"/>
    <meta property="article:tag" content="supervised learning"/>
    <meta property="og:image" content="/images/logo1.gif">

    <link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500,700" rel="stylesheet">

    <!-- Animate.css -->
    <link rel="stylesheet" href="/theme/css/animate.css">
    <!-- Icomoon Icon Fonts-->
    <link rel="stylesheet" href="/theme/css/icomoon.css">
    <!-- Bootstrap  -->
    <link rel="stylesheet" href="/theme/css/bootstrap.css">
    <!-- Flexslider  -->
    <link rel="stylesheet" href="/theme/css/flexslider.css">
    <!-- Theme style  -->
    <link rel="stylesheet" href="/theme/css/style.css">
    <!-- Custom style  -->
    <link rel="stylesheet" href="/theme/css/custom.css">
    <!-- pygments code highlight -->
    <link rel="stylesheet" href="/theme/css/pygments.css">
    <!-- tipue search -->
    <link rel="stylesheet" href="/theme/tipuesearch/css/tipuesearch.css">

    <!-- Modernizr JS -->
    <script src="/theme/js/modernizr-2.6.2.min.js"></script>
    <!-- FOR IE9 below -->
    <!--[if lt IE 9]>
    <script src="/theme/js/respond.min.js"></script>
    <![endif]-->
        <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="thedatamint Atom">



    </head>
    <body>
    <div id="fh5co-page">
        <a href="#" class="js-fh5co-nav-toggle fh5co-nav-toggle"><i></i></a>
        <aside id="fh5co-aside" role="complementary" class="border js-fullheight">

            <nav class="fh5co-main-menu" role="navigation">
            </nav>
            <div class="clearfix"></div>
            <h1  id="fh5co-logo">
                <a href="/index.html">
                    <img src="/images/logo1.gif" />
                </a>
            </h1>
            <nav class="fh5co-main-menu" role="navigation">
                
<ul>
    
    <!-- home link -->
    <li><a href="/">Home</a></li>
    <li> <a href="https://drive.google.com/file/d/1HxtwDSs1jN_dLYxmc4afx8TLv0lGNy6z/view?usp=sharing">Check Out My Resume!!!</a></li>
    <!-- page links -->
            <li><a href="/pages/meraki-hues-art-work.html">Meraki Hues-Art Work</a></li>
            <li><a href="/pages/about-us.html">About Us</a></li>

    <!-- categories -->
        <li><a href="/categories.html">Categories</a></li>

    <!-- tags -->
        <li><a href="/tags.html">Tags</a></li>

    <!-- additional menu items from config -->
        <!-- <li class="nav-title">Misc</li> -->
            <li><a href="/archives.html">All Blogs</a></li>

</ul><ul><li><form id="searchform" action="/search.html">
    <input id="tipue_search_input" data-siteurl="" type="text" size="60" class="form-control search-field" name="q">

    <button type="submit" class="btn btn-primary search-submit"><i class="icon-search4"></i></button>
</form></li></ul>            </nav>

<ul id="social">
            <li><a href="https://github.com/thedatamint" alt="Github"><i class="icon-github"></i></a></li>

</ul>
        </aside>

        <div id="fh5co-main">

    <div class="fh5co-narrow-content article-content">
        <h1 class="fh5co-heading-colored">Binary Classification using Logistic Regression using numpy</h1>

        <div>by
                <a href="author/pritish-jadhav-mrunal-jadhav.html">Pritish Jadhav, Mrunal Jadhav</a> - Sun, 08 Jul 2018
        </div>

            <div><span>Tags: </span>
                    <span><a href="/tag/python.html">#python</a> </span>
                    <span><a href="/tag/logistic-regression.html">#logistic regression</a> </span>
                    <span><a href="/tag/machine-learning.html">#machine learning</a> </span>
                    <span><a href="/tag/classification.html">#classification</a> </span>
                    <span><a href="/tag/supervised-learning.html">#supervised learning</a> </span>
            </div>

        <div class="animate-box" data-animate-effect="fadeInLeft">
            <p class="animate-box" data-animate-effect="fadeInLeft"><style type="text/css">/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area 
div.output_area 
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}



.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}






.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}








.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}





.rendered_html pre,




.rendered_html tr,
.rendered_html th,


.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}

.rendered_html * + p {
  margin-top: 1em;
}

.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,

.rendered_html img.unconfined,


.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] 
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered 
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered 
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
</style>
<style type="text/css">.highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3><strong>Problem Definition</strong> - <br></h3>
<ul>
<li>Suppose you are an auto enthusiast. You have been capturing the pictures of cars for a long time and putting them in an album labelled as 'Cars'. Here the sorting of the photos is done manually.</li>
<li>To manage your library easily, you would like to automate the process wherein an image captured by camera is scanned. If the image is of a Car, it is automatically organised under the label-'Cars'.</li>
</ul>
<div width>
<img src="./images/binary_classification/notebook_images/Machine-learning.jpg",width="20em">
</div><h1 id="Classification-Algorithms---">Classification Algorithms  -<a class="anchor-link" href="#Classification-Algorithms---">&#182;</a></h1><ul>
<li>Classification is a branch of supervised machine learning algorithms where target values are discrete. </li>
<li>In a binary classification problem, the output is 1 or 0 (Car or not). This is represented by Bernouli random variable. If can experiment is conducted with probability P, then it can take on 2 values, 1 for success and 0 otherwise. Thus the output is bounded on both ends.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So how do we solve the Classification problems ???</p>
<div>
<img src="./images/binary_classification/notebook_images/question.gif",width="10%">
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Logistic-Regression">Logistic Regression<a class="anchor-link" href="#Logistic-Regression">&#182;</a></h1><blockquote><p>Logistic Regression is the classification algorithm for linearly seperable data points and dichotomous(binary) outcome. It works by learning the function of P(Y|X). <br>
where Y is the <strong>indicator variable</strong> with inputs X <br><br>
Given a data point(x,y), logistic regression assumes : P(Y=1| X=x) <br><br>
We can say,<br>P(Y=1|X=x) = E(Y) (conditional expectation of the indicator variable)</p>
</blockquote>
<p>Mathematically this is given by,
\begin{align}P(Y=1|X=x)\ = \sigma(z) 
\\
\ where \ z \ is \ given \ by,  
z= \theta_0 + \sum_{i=1}^{m} \theta_ix_i
\\ 
\end{align}</p>
<h2 id="1.-The-Sigmoid-Function">1. The Sigmoid Function<a class="anchor-link" href="#1.-The-Sigmoid-Function">&#182;</a></h2><p>Logistic Regression starts by calculating the odds ratio. <br></p>
<blockquote><p><strong>Odds Ratio</strong> - <em>Odds Ratio(OR) is defined as the ratio of the probability of success and the probability of failure. The OR represents the odds that an outcome will occur given a particular exposure, compared to the odds of the outcome occurring in the absence of that exposure.</em></p>
</blockquote>
<p>The odds ratio is calculated from probability and unlike the probability, it may range from 0 to $\infty$
\begin{align}
Odds\ Ratio\  =\ \frac{P}{(1-P)}
\end{align}
Naturally, the more likely it is for the positive event P(Y=1|X=x) to occur, the larger is the odds ratio.</p>
<div>
<img src="./images/binary_classification/notebook_images/odds.gif",width="20%">
</div><p>Now, if we take Log on both sides, we get <strong>Logit Function</strong></p>
<blockquote><p>Logit Function is a monotonic function. The higher the log of odds ratio, the higher is the odds ratio.</p>
<ul>
<li>It is usually difficult to model a variable which has restricted range, such as probability.  This transformation is an attempt to get around the restricted range problem.  It maps probability ranging between 0 and 1 to log odds ranging from negative infinity to positive infinity. 
\begin{align}
logit(P)\ =\ log(\frac{P}{(1-P)})\ =log(P)-log(1-P)
\\
\end{align}</li>
</ul>
</blockquote>
<p>Therefore,
\begin{align}
\\
logit(P)\ =\ \theta_0 + \sum_{i=1}^{m} \theta_ix_i
\\
\end{align}
The plot of the logit function is :</p>
<div>
<img src="./images/binary_classification/notebook_images/logit.png",width="20%">
</div><p>Now, take the inverse logit on both sides,we get <strong>sigmoid function</strong> 
\begin{align}
logit^{-1}(logit(P))\ =logit^{-1}(\ \theta_0 + \sum_{i=1}^{m} \theta_ix_i)
\\
\\
P = \frac{1}{1+e^{-(\theta_0 + \sum_{i=1}^{m} \theta_ix_i})}
\\
\\
P = \frac{1}{1+e^{-(z)}}
\end{align}
The plot of the sigmoid function is :</p>
<p><div>
<img src="./images/binary_classification/notebook_images/sigmoid.png",width="20%">
</div>
<br>
\begin{align}
\\
P\ =\ sigmoid(z)\ =  \sigma(z) 
\\
\end{align}
<br></p>
<blockquote><p><strong><em>In Logistic Regression, we use Sigmoid Function to map the real value to a value between 0 and 1. In other words, it maps prediction to probability.</em></strong></p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="To-Summarize-the-previous-Section">To Summarize the previous Section<a class="anchor-link" href="#To-Summarize-the-previous-Section">&#182;</a></h3>\begin{align}
P(Y=1|X=x)\ =\ sigmoid(z)\ =\  \sigma(z) 
\end{align}<p>where,
<br>
\begin{align}
z\ =\ \theta_0 + \sum_{i=1}^{m} \theta_ix_i\ =\ \theta_0x_0 + \sum_{i=1}^{m} \theta_ix_i\ \ \ (x_0\ =\ 1)
\end{align}
Therefore,
<br>
\begin{align}
z\ =\ \sum_{i=0}^{m} \theta_ix_i
\end{align}
Vectorizing the above equation we can write,
<br>
\begin{align}
P(Y=1|X=x)\ =\ \sigma(\theta^Tx) 
\end{align}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.-Deriving-the-Cost-Function">2. Deriving the Cost Function<a class="anchor-link" href="#2.-Deriving-the-Cost-Function">&#182;</a></h2><p>The calculation of the probabilities in logistic regression are parametrized by $ \theta $. Our goal is to estimate the values of these parameters. We estimate these my using <strong>Maximum Likelihood Estimator(MLE)</strong>.<br> 
We perform this in 2 steps : <br></p>
<ol>
<li>Write the likelihood Function<blockquote><p><strong>Likelihood Functions</strong> measures the goodness of a fit of a statistical mode to a sample of data for given values of unknown parameters.</p>
</blockquote>
</li>
<li>Find the values of the parameters that maximise the likelihood function</li>
</ol>
<h3 id="Step-1"><strong>Step 1</strong><a class="anchor-link" href="#Step-1">&#182;</a></h3><p>The labels that we are predicting are binary, and the output of our logistic regression function is supposed to be the probability that the label is one. This means that we can (and should) interpret each label as a Bernoulli random variable: Y ∼ Ber(P) where P = σ(θ^Tx).<br><br></p>
<p>The Probability can be written as,<br>
\begin{align}
P(Y=1|X=x)\ =\ \sigma(\theta^Tx) 
\end{align}
By the laws of Probability,
\begin{align}
P(Y=0|X=x)\ =\ 1-\ \sigma(\theta^Tx) 
\end{align}
The compact way of writing these equations for a datapoint (x,y) is :
<br>
<br>
\begin{align}
P(Y=y|X=x)\ =\ \sigma(\theta^Tx)^y\ .\ (1-\ \sigma(\theta^Tx))^{(1-y)}
\end{align}
<br>
<br>
This is also the probability mass function of a Bernoulli. Now that we know the probability mass function we can write the likelihood of the data.
<br>
<br>
\begin{align}
L(\theta)=\ \prod_{i=1}^{m} \ P(Y=y^{(i)}\ |\ X=x^{(i)})
\end{align}
Substituting the likelihood of the Bernoulli,<br>
\begin{align}
L(\theta)=\ \prod_{i=1}^{m} \ \sigma(\theta^Tx^{(i)})^{y^{(i)}}\ .\ (1-\ \sigma(\theta^Tx^{(i)}))^{(1-y^{(i)})}
\end{align}
Taking the log of the function, we can get the log likelihood,<br><br>
\begin{align}
LL(\theta)=\ \sum_{i=1}^{m}\ y^{(i)}log\ \sigma(\theta^Tx^{(i)})\ +\ (1-y^{(i)})log\ (1-\ \sigma(\theta^Tx^{(i)}))
\end{align}</p>
<h3 id="Step-2"><strong>Step 2</strong><a class="anchor-link" href="#Step-2">&#182;</a></h3><p>Now that we have likelihood function, we need to choose the values of theta that would maximise it. We can find the best values of theta by using an optimization algorithm such as Gradient Descent. In optimization algorithm we  calculate the partial derivative of log likelihood with respect to each parameter.<br><br></p>
<ul>
<li><em>Gradient Descent Works by minimising the result of a function. Minimising the negative log likelihood is equivalent to maximising the log likelihood.</em><br></li>
<li><em>The 1/m is to "average" the squared error over the number of components so that the number of components doesn't affect the function</em><br><br></li>
</ul>
<p>Therefore, the Cost Function as follows : <br>
\begin{align}
J(\theta)=\ -\frac{1}{m}\sum_{i=1}^{m}\ y^{(i)}log\ \sigma(\theta^Tx^{(i)})\ +\ (1-y^{(i)})log\ (1-\ \sigma(\theta^Tx^{(i)}))
\end{align}
Here are the partial derivatives, we will derive later,<br><br>
\begin{align}
A=\ \sigma(\theta^Tx) 
\\
\\
\frac{\partial J(\theta)}{\partial \theta}  = \frac{1}{m}(A - Y)^T X
\\
\\
\frac{\partial J(\theta)}{\partial \theta_0} = \frac{1}{m} \sum_{i =1}^{m} (A - Y^{(i)}) 
\end{align}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Lets-Start-by-import-python-libraries-that-will-help-us-accomplish-the-task">Lets Start by import python libraries that will help us accomplish the task<a class="anchor-link" href="#Lets-Start-by-import-python-libraries-that-will-help-us-accomplish-the-task">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1">## python libraries</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="c1">## import sklearn for loading mnist data</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="kn">from</span> <span class="nn">IPython.core.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span><span class="n">HTML</span>
<span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="s1">&#39;&lt;style&gt;.prompt{width: 0px; min-width: 0px; visibility: collapse}&lt;/style&gt;&#39;</span><span class="p">))</span>
<span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="s2">&quot;&lt;style&gt;.container { width:100% !important; }&lt;/style&gt;&quot;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<style>.container { width:100% !important; }</style>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$Notations \ that \ we \ will \ be \ using \ throughout \ are \ as \ follows -$</p>
\begin{align}X - Input \ data \end{align}<p><br>
\begin{align}Y - Target \ labels \end{align}<br>
\begin{align}W - \ weights \ vector \ (to \ be \ estimated \ using \ training \ data) \end{align}<br>
\begin{align}b - \ intercept \ for \ the \ decision \ boundary \end{align}<br></p>
<p>$Notations \ for \ tracking \ dimensions \ are \ as \ follows-$
\begin{align}m - number \ of \ training \ examples \end{align}<br>
\begin{align}n - number \ of \ input \ features \end{align}<br>
\begin{align}k - \ size \ of \ labels \ vector (In \ case \ of \ binary \ classification,\ k\ =\ 1) \end{align} <br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Load-Cancer-dataset-provided-by-sklearn">Load Cancer dataset provided by sklearn<a class="anchor-link" href="#Load-Cancer-dataset-provided-by-sklearn">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">load_breast_cancer_dataset</span><span class="p">():</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    This function loads the dataset. It also prints the description of the dataset.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">data_dict</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">data_dict</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">],</span> <span class="n">data_dict</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="c1">#use transpose to match the dimesions defined above</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Y</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># reshape the label vector so that it has a dimesion of k x m</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">load_breast_cancer_dataset</span><span class="p">()</span>

<span class="k">print</span> <span class="s2">&quot;successfully loaded training data with </span><span class="si">%d</span><span class="s2"> training data and </span><span class="si">%d</span><span class="s2"> features&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>successfully loaded training data with 569 training data and 30 features
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Leverage the built in normalization techniques provided by sklearn.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="k">print</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(569, 30) (569, 1)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\ While \ implementing \ logistic \ Regression \ from \ scratch, \ it \ is \ important \ to \ keep \ track \ of \ dimensions.$</p>
<p>$\ For \ this \ tutorial, \ we \ shall \ use \ following \ dimensions -$</p>
\begin{equation*} \tag{1}\label{1} X =\ m \times \ n  \ \end{equation*}<p><br>
\begin{align}\tag{2}\label{2} Y = \ m \times \ 1 \end{align} <br>
\begin{align}\tag{3}\label{3} W = \ 1 \times \ n \end{align}<br>
\begin{align}\tag{4}\label{4}b = \ 1 \times \ 1 \end{align}<br></p>
<p>The pseudo-code for training a Logistic Regression model is as follows -</p>
<p><strong>Step 1</strong> - Given a Training DataSet X and corresponding labels Y, initialize values of number of training examples(m), number of features(n) and number of output units (k) as mentioned in equations \ref{1}, \ref{2}, \ref{3} and \ref{4}
<br><br>
<strong>Step 2</strong> - Initialize Weights matrix W and bias b using dimensions from Step 1. 
<br><br></p>
\begin{equation} for\ \ \ i_{epoch}\ \ \  in\ \ \ range(iterations):\end{equation}<p><strong>Step 3</strong> - Forward Propagation  - 
<br>
<strong>Step 3.1</strong> compute preactivations using \ref{5}</p>
\begin{align} pre\_activations \ (Z) = XW^T +b  \tag{5}\label{5} \end{align}<p>Lets validate if the dimensions match - 
\begin{equation} preactivations \ (Z) = \mathbf{(\ m \times \ n )} \times \ \mathbf{(1 \times \ n)}^\intercal \ + \ (1 \times 1) \end{equation}</p>
<p>We are good to move ahead.
 <br><br>
<strong>Step 3.2</strong> - Compute Activation using equation \ref{6}</p>
\begin{align} activations \ (A) = \sigma(Z) = \ \frac{1}{1 + e^{-(Z)}} \tag{6}\label{6} \end{align}<p>Note that the dimensions of activations are same as dimensions of preactivations.</p>
<p><br> <br></p>
<p><strong>Step 3.3</strong> - Compute loss /error /cost using \ref{7}
\begin{align} cost = - \ \frac{1}{m} \sum_{i =1}^{m} y_i \log(A_i) + \ (1-y_i) \log(1-A_i) \tag{7} \label{7} \end{align}</p>
<p>It is important to note that, cost/error/loss is a scaler which we would like to minimize using gradient descent.</p>
<p><strong>Step 4</strong> - Back Propagation
<br><br>
We shall derive the grdients using chain rule -</p>
\begin{equation} \frac{\partial L}{\partial W} \ = \  \frac{\partial L}{\partial A} \frac{\partial A}{\partial Z} \frac{\partial Z}{\partial W} \tag{8}\label{8} \end{equation}<p><br>
Lets Start by computing the partial derivative - $\frac{\partial L}{\partial A}$
<br>
\begin{align} \frac{\partial L}{\partial A} &amp; = \frac{\partial }{\partial A} \Big[ - \  \sum_{i =1}^{m} y_i \log(A_i) + \ (1-y_i) \log(1-A_i)\Big] \end{align}</p>
<p>For one training example $i$ -</p>
\begin{align}
\frac{\partial L}{\partial A} &amp; = - \Big[y^{(i)} \frac{\partial log(A)}{\partial A} + (1-y^{(i)}) \frac{\partial log(1-A)}{ \partial A} \Big] \\ 
&amp; =  - \Big[ \frac{y^{(i)}}{A} - \frac{1-y^{(i)}}{1-A}\Big] \tag{9} \label{9}
\end{align}<p><br></p>
<p>Now lets compute the partial derivative $\frac{\partial A}{\partial Z}$
<br>
\begin{align} \frac{\partial A}{\partial Z} &amp; = \frac{\partial }{\partial Z} \Big[ \frac{1}{1 + e^{-(Z)}} \Big]
\\
&amp; = \frac{\partial }{\partial Z} \Big[ \Big(1+ e^{(-Z)}\Big)^{-1} \Big]
\\
&amp; = - \Big(1+ e^{-z})^{-1} \Big)^{-2} \frac {\partial}{\partial Z} \Big( 1+ e^{-Z} \Big)
\\
&amp; = \frac{- e^ {-z}} {(1+ e^{-z})^2} \frac{\partial }{\partial Z} \Big(-Z \Big)
\\
&amp; = \frac{e^{-z}}{(1+ e^{-Z})^2} \tag{10}\label{10}
\end{align}
<br>
Adding and Subtracting 1 in numerator of equation \ref{10}
\begin{align}
\frac{\partial A}{\partial Z} &amp; = \frac{1+e^{-Z} -1}{(1+e^{-Z})^2}
\\
&amp; = \frac{1 +e^{-Z}}{(1+e^{-Z})^2} - \frac{1}{(1+e^{-Z})^2}
\\
&amp; = \frac{1}{(1+e^{-Z})} - \frac{1}{(1+e^{-Z})^2} \tag{11}\label{11}
\end{align}</p>
<p>from equation \ref{6} and \ref{11}, we get - <br></p>
\begin{align}
\frac{\partial A}{\partial Z} &amp; = A- A^2 \\
&amp; = A(1-A) \tag{12}\label{12}
\end{align}<p>Multiply equations \ref{9} and \ref{12}, we get</p>
\begin{align} \\
\frac{\partial L}{\partial Z} &amp; = \frac{\partial L}{\partial A} \frac{\partial A}{\partial Z}
\\
&amp; = - \Big[ \frac{y^{(i)}}{A} - \frac{1-y^{(i)}}{1-A}\Big] A(1-A)
\\
&amp; = - \Big[ y^{(i)}(1 - A) - A (1 - y^{(-i)}) \Big]
\\
&amp; = - \Big[ y^{(i)} -  \require{cancel} \cancel{y^{(i)}A}  - A + \require{cancel} \cancel{y^{(i)}A }]
\\
&amp; =  \Big[ A - y^{(-i)} \Big]
\end{align}<p>Now, The last part of this derivation to compute gradients with respect to weights/coeffiecients.</p>
\begin{align}\\
\frac{\partial L}{\partial W} &amp; = \frac{\partial L}{\partial Z} \frac{\partial Z}{\partial W}
\\
&amp; = \frac{\partial L}{\partial Z} \Big[ \frac{\partial Z}{\partial W_1} \frac{\partial Z}{\partial W_2} .... \frac{\partial Z}{\partial W_n}\Big]
\end{align}<p>The derivatives $\Big[ \frac{\partial Z}{\partial W_1} \frac{\partial Z}{\partial W_2} .... \frac{\partial Z}{\partial W_n}\Big]$ can be easily calculated as follows -</p>
\begin{align}
\\
\frac{\partial Z}{\partial W_1} &amp; = \frac{\partial }{\partial W_1} \Big(x_1w_1 +x_2w_2 + ....+x_nw_n + b \Big) 
\\
&amp; =  x_1
\end{align}<p>Similarly, 
\begin{align}
\\
\frac{\partial Z}{\partial W_2} = x_2
\\ 
\frac{\partial Z}{\partial W_3} = x_3
\\.
\\.
\\.
\frac{\partial Z}{\partial W_n} = x_n
\end{align}</p>
<p>Now, the gradient of bias term b is simply - 
\begin{align}\\
\frac{\partial L}{\partial b} &amp; = \frac{\partial L}{\partial Z} \frac{\partial Z}{\partial B}
\\
&amp; = (A - Y^{(i)}) \frac{\partial }{\partial b} \Big(x_1w_1 +x_2w_2 + ....+x_nw_n + b \Big)
\\
&amp; = (A - Y{(i)}) (1)
\end{align}
Therefore, for one training example, the gradient wrt weights can be concisely computed using -</p>
\begin{align}
\\ \frac{\partial L}{\partial W} = (A-Y^{(i)}) [x_1^{(i)} x_2^{(i)} x_3^{(i)} .... x_n^{(i)}]
\\
\frac{\partial L}{\partial b} = (A-Y^{(i)})
\end{align}<p>By extending the computations for one training example to m training examples, we get -</p>
\begin{align}
\\
\frac{\partial L}{\partial W} =  \sum_{i =1}^{m} \frac{\partial {L^{(i)}}}{\partial W} \tag{13}\label{13}
\\
\frac{\partial L}{\partial b} =  \sum_{i =1}^{m} \frac{\partial {L^{(i)}}}{\partial b} \tag{14}\label{14}
\end{align}<p>Equations \ref{13} and \ref{14} can be summarised as follows -</p>
\begin{align}
\\
\frac{\partial L}{\partial W}  = \frac{1}{m}(A - Y)^T X \tag{15}\label{15}
\\
\frac{\partial L}{\partial b} = \frac{1}{m} \sum_{i =1}^{m} (A - Y^{(i)}) \tag{16}\label{16}
\end{align}<p><strong>Step 4.1</strong> The weights can be updated using gradient descent equations as follows - 
\begin{align}
\\
W = W - \frac{\partial L}{\partial W} \tag{17} \label{17}
\\
b = b - \frac{\partial L}{\partial b} \tag{18} \label{18}
\end{align}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">initialize_dimensions</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    This function initializes the values of m, n and k</span>
<span class="sd">    m -&gt; number of training examples</span>
<span class="sd">    n -&gt; number of features</span>
<span class="sd">    k -&gt; number of output labels (for binary classification, k= 1)</span>
<span class="sd">    </span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">k</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">initialize_weights_with_zeros</span><span class="p">(</span><span class="n">dim</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    This function initializes the weights vector and bias vector</span>
<span class="sd">    </span>
<span class="sd">    The genaral formula for Weights matrix and bias vector is - </span>
<span class="sd">    W --&gt; number of output units x number of input features</span>
<span class="sd">    b --&gt; 1 x number of output units</span>
<span class="sd">    </span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">dim</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-formula-for-sigmoid-is-given-by--">The formula for sigmoid is given by -<a class="anchor-link" href="#The-formula-for-sigmoid-is-given-by--">&#182;</a></h3>\begin{equation} \sigma (z) = \ \frac{1}{1 + e^{-z}} \end{equation}
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    This function computes the sigmoid of vector (numpy array).</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span><span class="n">z</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-cost-for-logistic-regression-is-given-by--">The cost for logistic regression is given by -<a class="anchor-link" href="#The-cost-for-logistic-regression-is-given-by--">&#182;</a></h3>\begin{equation} cost\ (L) = - \ \frac{1}{m} \sum_{i =1}^{m} y_i \log(A_i) + \ (1-y_i) \log(1-A_i) \end{equation}<p>$Where,  \\  
Y = vector\ of\ size\ m \times 1. \\
A = activations = \sigma {(z)} -\ vector\ of\ size\ m\ \times\ 1$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">compute_sigmoid_cost</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">/</span><span class="n">m</span> <span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">Y</span><span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">+</span> <span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">Y</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">A</span><span class="p">))),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cost</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">compute_sigmoid_gradients</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">activations</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
    <span class="n">dw</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">((</span><span class="n">activations</span><span class="o">-</span><span class="n">Y</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="n">db</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">activations</span><span class="o">-</span><span class="n">Y</span><span class="p">),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dw</span><span class="p">,</span> <span class="n">db</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">propagation</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
    <span class="c1"># FORWARD PROPAGATION (FROM X TO COST)</span>

    <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">activations</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">compute_sigmoid_cost</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">activations</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="c1"># BACKWARD PROPAGATION (TO FIND GRAD)</span>
    <span class="n">dw</span><span class="p">,</span> <span class="n">db</span> <span class="o">=</span> <span class="n">compute_sigmoid_gradients</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">activations</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

    <span class="n">cost</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
    
    <span class="n">grads</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;dw&quot;</span><span class="p">:</span> <span class="n">dw</span><span class="p">,</span>
             <span class="s2">&quot;db&quot;</span><span class="p">:</span> <span class="n">db</span><span class="p">}</span>
    
    <span class="k">return</span> <span class="n">grads</span><span class="p">,</span> <span class="n">cost</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">train_logistic_regression</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">3000</span><span class="p">,</span> <span class="n">print_cost</span> <span class="o">=</span> <span class="bp">True</span><span class="p">):</span>
    <span class="n">m</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">k</span>  <span class="o">=</span> <span class="n">initialize_dimensions</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
    <span class="n">w</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">initialize_weights_with_zeros</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
    
    <span class="n">costs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
        <span class="n">grad</span><span class="p">,</span> <span class="n">cost</span> <span class="o">=</span> <span class="n">propagation</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
        
        <span class="n">dw</span> <span class="o">=</span> <span class="n">grad</span><span class="p">[</span><span class="s1">&#39;dw&#39;</span><span class="p">]</span>
        <span class="n">db</span> <span class="o">=</span> <span class="n">grad</span><span class="p">[</span><span class="s1">&#39;db&#39;</span><span class="p">]</span>
        
        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dw</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">db</span>
        
        <span class="c1"># Record the costs</span>
        <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">costs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>

        <span class="c1"># Print the cost every 100 training examples</span>
        <span class="k">if</span> <span class="n">print_cost</span> <span class="ow">and</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">activations</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">activations</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_pred</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">Y</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]))</span><span class="o">/</span> <span class="n">m</span><span class="p">)</span><span class="o">*</span> <span class="mi">100</span>
            <span class="n">display</span><span class="p">(</span><span class="s2">&quot;Cost after iteration </span><span class="si">%i</span><span class="s2">: </span><span class="si">%f</span><span class="s2"> | accuracy after iteration </span><span class="si">%i</span><span class="s2">: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">iteration</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">))</span>

    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;w&quot;</span><span class="p">:</span> <span class="n">w</span><span class="p">,</span>
              <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="n">b</span><span class="p">}</span>

    <span class="n">grads</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;dw&quot;</span><span class="p">:</span> <span class="n">dw</span><span class="p">,</span>
             <span class="s2">&quot;db&quot;</span><span class="p">:</span> <span class="n">db</span><span class="p">}</span>

    <span class="k">return</span> <span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">costs</span><span class="p">,</span><span class="n">y_pred</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">kl</span> <span class="o">=</span> <span class="n">train_logistic_regression</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">print_cost</span><span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>&#39;Cost after iteration 0: 0.693147 | accuracy after iteration 0: 65.026362&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>&#39;Cost after iteration 500: 0.219201 | accuracy after iteration 500: 94.376098&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>&#39;Cost after iteration 1000: 0.169860 | accuracy after iteration 1000: 95.254833&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>&#39;Cost after iteration 1500: 0.147171 | accuracy after iteration 1500: 96.836555&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>&#39;Cost after iteration 2000: 0.133237 | accuracy after iteration 2000: 96.836555&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>&#39;Cost after iteration 2500: 0.123533 | accuracy after iteration 2500: 96.836555&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Awesome !!!</p>
<p>We were able to achieve 96.83% accuracy using logistic regressions.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Confusion-Matrix">Confusion Matrix<a class="anchor-link" href="#Confusion-Matrix">&#182;</a></h2><blockquote><p>Confusion Matrix is the performance measurement for classification algorithms.It not only provides insight of errors made my model but also the type of erros made.<br>Some of the basic terminologies related to Confusion Matrix are as follows :</p>

<pre><code>* True Positive — Label which was predicted Positive and is actually Positive.
* True Negatives — Label which was predicted Negative and is actually Negative.
* False Positive (Type 1 Error) — Label which was predicted as Positive, but is actually Negative.
* False Negatives (Type 2 Error)— Labels which was predicted as Negative, but is actually Positive 
</code></pre>
<div>
<img src="./images/binary_classification/notebook_images/matrix_joke.png",width="20%">
</div>
</blockquote>
<h3 id="Other-Metrics-that-can-be-computed-using-Confusion-Matrix-are-:">Other Metrics that can be computed using Confusion Matrix are :<a class="anchor-link" href="#Other-Metrics-that-can-be-computed-using-Confusion-Matrix-are-:">&#182;</a></h3><ol>
<li><strong>Sensitivity</strong> - It is also called as <strong>Recall, Hit Rate, True Positive Rate(TPR)</strong>. It measures the proportion of actual positives that are correctly identified.
\begin{align}
TPR =\ \frac{TP}{P}\ =\ \frac{TP}{TP+FN}
\end{align}
<br><br></li>
<li><strong>Specificity</strong> - It is also called as <strong>Selectivity, True Negative Rate(TNR)</strong>. It measures the proportion of actual negatives that are correctly identified.
\begin{align}
TNR =\ \frac{TN}{N}\ =\ \frac{TN}{TN+FP}
\end{align}
<br><br></li>
<li><strong>Precision</strong> - It is also called as <strong>Positive Predictive Value</strong>.The precision metric shows the accuracy of the positive class. It measures how likely the prediction of the positive class is correct.
\begin{align}
Precision=\ \frac{TP}{TP+FP}
\end{align}
<br><br></li>
<li><strong>Accuracy Score</strong>- Accuracy is calculated as the number of all correct predictions divided by the total number of the dataset. 
\begin{align}
Accuracy=\ \frac{TP+TN}{TP+TN+FP+FN}
\end{align}
<br><br></li>
<li><strong>F1 Score</strong> - The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0.
\begin{align}
F1\ Score =\ \frac{2* Precision * Recall}{Precision+Recall}
\end{align}
<br><br></li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[80]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Here we consider the detection of breast cancer(Y=1) as positive result</span>
<span class="sd">and cancer not being detected (Y=0) as negative result</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">plot_confusion_matrix</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span><span class="n">predicted</span><span class="p">):</span>
    <span class="n">confusion_matrix</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
    <span class="n">confusion_matrix</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">=</span><span class="nb">int</span><span class="p">(((</span><span class="n">predicted</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">actual</span><span class="o">==</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
    <span class="n">confusion_matrix</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="nb">int</span><span class="p">(((</span><span class="n">predicted</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">actual</span><span class="o">==</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
    <span class="n">confusion_matrix</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">=</span><span class="nb">int</span><span class="p">(((</span><span class="n">predicted</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">actual</span><span class="o">==</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
    <span class="n">confusion_matrix</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="nb">int</span><span class="p">(((</span><span class="n">predicted</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">actual</span><span class="o">==</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">confusion_matrix</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[83]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">confusion_matrix</span><span class="o">=</span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">Y_pred</span><span class="p">)</span>
<span class="n">TP</span><span class="o">=</span><span class="n">confusion_matrix</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">FN</span><span class="o">=</span><span class="n">confusion_matrix</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">FP</span><span class="o">=</span><span class="n">confusion_matrix</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
<span class="n">TN</span><span class="o">=</span><span class="n">confusion_matrix</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
<span class="n">recall</span><span class="o">=</span><span class="n">TP</span><span class="o">/</span><span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">FN</span><span class="p">)</span>
<span class="n">specificity</span> <span class="o">=</span> <span class="n">TN</span><span class="o">/</span><span class="p">(</span><span class="n">TN</span><span class="o">+</span><span class="n">FP</span><span class="p">)</span>
<span class="n">precision</span><span class="o">=</span><span class="n">TP</span><span class="o">/</span><span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">FP</span><span class="p">)</span>
<span class="n">accuracy</span><span class="o">=</span> <span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">TN</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">TN</span><span class="o">+</span><span class="n">FP</span><span class="o">+</span><span class="n">FN</span><span class="p">)</span>
<span class="n">f1_score</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">precision</span><span class="o">*</span><span class="n">recall</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">precision</span><span class="o">+</span><span class="n">recall</span><span class="p">)</span>


<span class="k">print</span><span class="p">(</span><span class="s2">&quot;The Confusion Matrix of the output is :&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;The Sensitivity is : &quot;</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;The Specificity is : &quot;</span><span class="p">,</span> <span class="n">specificity</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;The Precision is : &quot;</span><span class="p">,</span> <span class="n">precision</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;The Accuracy is : &quot;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;The F1 Score is : &quot;</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>The Confusion Matrix of the output is :
[[ 353.    4.]
 [  14.  198.]]
(&#39;The Sensitivity is : &#39;, 0.96185286103542234)
(&#39;The Specificity is : &#39;, 0.98019801980198018)
(&#39;The Precision is : &#39;, 0.98879551820728295)
(&#39;The Accuracy is : &#39;, 0.96836555360281196)
(&#39;The F1 Score is : &#39;, 0.97513812154696133)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
\begin{align}
\Large Congratulations\ on\ Completing\ Logistic\ Regression\ !!!
\end{align}<p><br></p>
<div>
<img src="./images/binary_classification/notebook_images/celebrate.gif",width="35%">
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Can-we-use-Linear-Regression-to-solve-the-classification-Problem???">Can we use Linear Regression to solve the classification Problem???<a class="anchor-link" href="#Can-we-use-Linear-Regression-to-solve-the-classification-Problem???">&#182;</a></h2><p>A linear regression studies a relationship between <br>
◦ a response variable Y and <br>
◦ a single explanatory variable X.<br>
However, Linear Regression doesn't seem to be a good fit for classification problems owing to the following reasons.</p>
<div>
<img src="./images/binary_classification/notebook_images/linear-joke.png",width="20%">
<!--<a href="https://www.pinterest.com.au/pin/68539225558983859/">source</a>-->
</div><hr>
<hr>
<ul>
<li><p>Linear Regression assumes normality for the residual errors(which represent the variation in Y) whereas a classification problem is not normally distributed.
<br><br></p>
</li>
<li><p>The variance (and the standard deviation) for linear regression does not depend on X(input variable).<br> For classification problems, the mean and the variance depends upon the probability. Thus any input affecting the probability of output, affects the mean and variance. This voilates the principles of linear regression. 
<br><br></p>
</li>
<li><p>Linear Regression deals with continuous variables instead of discrete variables. This may result in an output having value less than 0 or greater than 1.<br>
True probability has a value between 0 and 1.<br> Thus Linear Regression fails to model true probability.
<br><br></p>
<ul>
<li>We can solve the problem of unbounded output by using the log p(x) to be the linear function of x, so that changing an input variable multiplies the probability by a fixed amount. <br>Here, the problem is that logarithms are unbounded in only one direction, and linear functions are not. </li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
 


<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['$','$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        " linebreaks: { automatic: true, width: '95% container' }, " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
</p>
        </div>
    </div>

<div class="fh5co-narrow-content">
<div class="animate-box" data-animate-effect="fadeInLeft">
    <h2><!-- <i class="icon-speech-bubble"></i>  -->Comments</h2>
</div>
<div class="animate-box" data-animate-effect="fadeInLeft">
    <div id="disqus_thread"></div>
</div>

<script>
var disqus_config = function () { 
  this.language = "en";
};
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://gitcd-dev.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript><a href="https://disqus.com/?ref_noscript">Please enable JavaScript to view the comments powered by Disqus.</a></noscript>
<div class="fh5co-footer">
    <br>
    <p><small>&copy; 2018 The Data Mint. All Rights Reserved.</span> <span>Designed by <a href="http://freehtml5.co/" target="_blank">FreeHTML5.co</a></span>
    <br /><span>Pelican Theme by: <a href="https://github.com/claudio-walser/pelican-fh5co-marble" target="_blank">Claudio Walser</a></span></small></p>

</div>                
        </div>
    </div>

    <!-- jQuery -->
    <script src="/theme/js/jquery.min.js"></script>
    <!-- jQuery Easing -->
    <script src="/theme/js/jquery.easing.1.3.js"></script>
    <!-- Bootstrap -->
    <script src="/theme/js/bootstrap.min.js"></script>
    <!-- Waypoints -->
    <script src="/theme/js/jquery.waypoints.min.js"></script>
    <!-- Flexslider -->
    <script src="/theme/js/jquery.flexslider-min.js"></script>


    <!-- MAIN JS -->
    <script src="/theme/js/main.js"></script>
    </body>
</html>
