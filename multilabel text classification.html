
<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Hierarchical Attention Network For Multilabel Classification (Detailed Case study)</title>

    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta name="author" content="Pritish Jadhav, Mrunal Jadhav" />
    <meta name="description" content="In many real-world data applications, often we encounter scenarios where each data point may belong to multiple classes. A multilabel classifier is trained to predict the K most likely classes among N possible classes. The article focuses on solving multi-label text classification problems using the Hierarchical Attention Network." />
    <meta name="keywords" content="python, Keras, deep learning, text classification, multilabel">
<!-- Facebook and Twitter integration -->
<meta property="og:site_name" content="thedatamint"/>
<meta property="og:title" content="Hierarchical Attention Network For Multilabel Classification (Detailed Case study)"/>
<meta property="og:description" content="In many real-world data applications, often we encounter scenarios where each data point may belong to multiple classes. A multilabel classifier is trained to predict the K most likely classes among N possible classes. The article focuses on solving multi-label text classification problems using the Hierarchical Attention Network."/>
<meta property="og:url" content="/multilabel text classification.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2019-09-11 18:00:00+05:30"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="/author/pritish-jadhav-mrunal-jadhav.html">
<meta property="article:section" content="Deep Learning"/>
    <meta property="article:tag" content="python"/>
    <meta property="article:tag" content="Keras"/>
    <meta property="article:tag" content="deep learning"/>
    <meta property="article:tag" content="text classification"/>
    <meta property="article:tag" content="multilabel"/>
    <meta property="og:image" content="/images/logo.png">

    <link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500,700" rel="stylesheet">

    <!-- Animate.css -->
    <link rel="stylesheet" href="/theme/css/animate.css">
    <!-- Icomoon Icon Fonts-->
    <link rel="stylesheet" href="/theme/css/icomoon.css">
    <!-- Bootstrap  -->
    <link rel="stylesheet" href="/theme/css/bootstrap.css">
    <!-- Flexslider  -->
    <link rel="stylesheet" href="/theme/css/flexslider.css">
    <!-- Theme style  -->
    <link rel="stylesheet" href="/theme/css/style.css">
    <!-- Custom style  -->
    <link rel="stylesheet" href="/theme/css/custom.css">
    <!-- pygments code highlight -->
    <link rel="stylesheet" href="/theme/css/pygments.css">
    <!-- tipue search -->
    <link rel="stylesheet" href="/theme/tipuesearch/css/tipuesearch.css">

    <!-- Modernizr JS -->
    <script src="/theme/js/modernizr-2.6.2.min.js"></script>
    <!-- FOR IE9 below -->
    <!--[if lt IE 9]>
    <script src="/theme/js/respond.min.js"></script>
    <![endif]-->
        <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="thedatamint Atom">



    </head>
    <body>
    <div id="fh5co-page">
        <a href="#" class="js-fh5co-nav-toggle fh5co-nav-toggle"><i></i></a>
        <aside id="fh5co-aside" role="complementary" class="border js-fullheight">

            <nav class="fh5co-main-menu" role="navigation">
            </nav>
            <div class="clearfix"></div>
            <h1  id="fh5co-logo">
                <a href="/index.html">
                    <img src="/images/logo.png" />
                </a>
            </h1>
            <nav class="fh5co-main-menu" role="navigation">
<ul>
    <!-- home link -->
    <li><a href="/">Home</a></li>

    <!-- page links -->
            <li><a href="/pages/meraki-hues.html">Meraki Hues</a></li>

    <!-- categories -->
        <li><a href="/categories.html">Categories</a></li>

    <!-- tags -->
        <li><a href="/tags.html">Tags</a></li>

    <!-- additional menu items from config -->
        <!-- <li class="nav-title">Misc</li> -->
            <li><a href="/archives.html">All Blogs</a></li>
            <li><a href="/contact.html">Contact</a></li>

</ul><ul><li><form id="searchform" action="/search.html">
    <input id="tipue_search_input" data-siteurl="" type="text" size="60" class="form-control search-field" name="q">

    <button type="submit" class="btn btn-primary search-submit"><i class="icon-search4"></i></button>
</form></li></ul>
            </nav>

<ul id="social">
            <li><a href="https://www.github.com/claudio-walser" alt="Github"><i class="icon-github"></i></a></li>

            <li><a href="https://www.facebook.com" alt="Facebook"><i class="icon-facebook2"></i></a></li>

            <li><a href="https://www.twitter.com" alt="Twitter"><i class="icon-twitter2"></i></a></li>

            <li><a href="https://plus.google.com" alt="Google+"><i class="icon-google-plus2"></i></a></li>

</ul>
        </aside>

        <div id="fh5co-main">

    <div class="fh5co-narrow-content article-content">
        <h1 class="fh5co-heading-colored">Hierarchical Attention Network For Multilabel Classification (Detailed Case study)</h1>

        <div>by
                <a href="author/pritish-jadhav-mrunal-jadhav.html">Pritish Jadhav, Mrunal Jadhav</a> - Wed, 11 Sep 2019
        </div>

            <div><span>Tags: </span>
                    <span><a href="/tag/python.html">#python</a> </span>
                    <span><a href="/tag/keras.html">#Keras</a> </span>
                    <span><a href="/tag/deep-learning.html">#deep learning</a> </span>
                    <span><a href="/tag/text-classification.html">#text classification</a> </span>
                    <span><a href="/tag/multilabel.html">#multilabel</a> </span>
            </div>

        <div class="animate-box" data-animate-effect="fadeInLeft">
            <p class="animate-box" data-animate-effect="fadeInLeft"><style type="text/css">/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area 
div.output_area 
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}



.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}






.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}








.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}





.rendered_html pre,




.rendered_html tr,
.rendered_html th,


.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}

.rendered_html * + p {
  margin-top: 1em;
}

.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,

.rendered_html img.unconfined,


.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] 
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered 
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered 
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
</style>
<style type="text/css">.highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Multilabel-Text-Classification-Using-Custom-Embeddings-in-Keras.">Multilabel Text Classification Using Custom Embeddings in Keras.<a class="anchor-link" href="#Multilabel-Text-Classification-Using-Custom-Embeddings-in-Keras.">&#182;</a></h2><p>Traditionally, classification problems are either formulated as -</p>
<ol>
<li><b>Binary Classification</b> problems - where each training example belongs to either a positive or a negative class. </li>
<li><b>Multiclass Classification</b> problem - where each training example belongs to one of the 'k' classes. </li>
</ol>
<p>In this article, we shall explore a new problem statement -</p>
<h3 id="Multilabel-Classification-Problem--"><b>Multilabel Classification Problem -</b><a class="anchor-link" href="#Multilabel-Classification-Problem--">&#182;</a></h3><ul>
<li>In many real world data applications, often we encounter scenarios where each data point belongs to multiple classes.  </li>
<li>Suppose you are working for Recruiting Firm which receives thousands of Resumes each day. You are tasked with the problem of tagging each resume with relevant set of skills which hiring committee cares about. </li>
<li>In such a scenario, it is possible to have a candidate who possesses 'leadership' skills as well as 'coding' skills. </li>
<li>Such a setup requires you to solve a multilabel classification problem. </li>
</ul>
<p>The following sections will cover -</p>
<ol>
<li>Data Description, </li>
<li>Data Cleaning. </li>
<li>Encoding Labels. </li>
<li>Defining a custom Embedding Layer with keras. </li>
<li>Defining Loss Function and Evaluation Metric for Multilabel Classification</li>
<li>Model Building </li>
<li>Training a model</li>
<li>Inference. </li>
<li>Final Comments and References. </li>
</ol>
<p>Let's start by importing a whole bunch of python libraries that we will need for successful implementation of our algorithm.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">string</span>
<span class="kn">import</span> <span class="nn">codecs</span>
<span class="kn">from</span> <span class="nn">operator</span> <span class="kn">import</span> <span class="n">itemgetter</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">keras.backend</span> <span class="kn">as</span> <span class="nn">K</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="p">(</span><span class="n">Dense</span><span class="p">,</span> <span class="n">Conv1D</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> 
                          <span class="n">BatchNormalization</span><span class="p">,</span> <span class="n">MaxPooling1D</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">GlobalMaxPool1D</span><span class="p">,</span> <span class="n">Bidirectional</span><span class="p">,</span> 
                         <span class="n">LSTM</span><span class="p">,</span> <span class="n">GRU</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">,</span> <span class="n">Concatenate</span><span class="p">,</span> <span class="n">Dot</span><span class="p">,</span> <span class="n">Reshape</span><span class="p">,</span> <span class="n">TimeDistributed</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">Input</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.text</span> <span class="kn">import</span> <span class="n">Tokenizer</span><span class="p">,</span> <span class="n">one_hot</span><span class="p">,</span> <span class="n">text_to_word_sequence</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing</span> <span class="kn">import</span> <span class="n">sequence</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.sequence</span> <span class="kn">import</span> <span class="n">pad_sequences</span>
<span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">from</span> <span class="nn">keras.layers.embeddings</span> <span class="kn">import</span> <span class="n">Embedding</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">optimizers</span><span class="p">,</span> <span class="n">regularizers</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">SGD</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="kn">from</span> <span class="nn">keras.regularizers</span> <span class="kn">import</span> <span class="n">l1</span><span class="p">,</span> <span class="n">l2</span>

<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">WordNetLemmatizer</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk</span> <span class="kn">import</span> <span class="n">word_tokenize</span><span class="p">,</span> <span class="n">sent_tokenize</span>

<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">shuffle</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MultiLabelBinarizer</span>

<span class="kn">from</span> <span class="nn">IPython.core.interactiveshell</span> <span class="kn">import</span> <span class="n">InteractiveShell</span>
<span class="n">InteractiveShell</span><span class="o">.</span><span class="n">ast_node_interactivity</span> <span class="o">=</span> <span class="s2">&quot;all&quot;</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>
<span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="s1">&#39;&lt;style&gt;.prompt{width: 0px; min-width: 0px; visibility: collapse}&lt;/style&gt;&#39;</span><span class="p">))</span>
<span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="s2">&quot;&lt;style&gt;.container { width:100% !important; }&lt;/style&gt;&quot;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>Using TensorFlow backend.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<style>.container { width:100% !important; }</style>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">MAX_NB_WORDS</span> <span class="o">=</span> <span class="mi">300000</span>
<span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">300</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Data-Description--">Data Description -<a class="anchor-link" href="#Data-Description--">&#182;</a></h3><p>For implementing a multilabel classifier, we shall be using the <a href="https://www.kaggle.com/danofer/dbpedia-classes">"DBPedia Hierarchical Classes dataset"</a> dataset from Kaggle.</p>
<h4 id="Context--">Context -<a class="anchor-link" href="#Context--">&#182;</a></h4><ul>
<li>DBpedia (from "DB" for "database") is a project aiming to extract structured content from the information created in Wikipedia. </li>
<li>This is an extract of the data that provides taxonomic, hierarchical categories ("classes") for 342,782 wikipedia articles. </li>
<li>There are 3 levels, with 9, 70 and 219 classes respectively. A version of this dataset is a popular baseline for NLP/text classification tasks. </li>
<li><p>This version of the dataset is much tougher, especially if the L2/L3 levels are used as the targets.</p>
</li>
<li><p>The Dataset consists of the following columns -</p>
<ol>
<li><b>text</b> - a free text column which describes the entity. </li>
<li><b>l1</b> - Base label in the hierarchy. </li>
<li><b>l2</b> - Intermediate label in the hierarchy. </li>
<li><b>l3</b> - Top level label in the hierarchy. </li>
</ol>
</li>
</ul>
<p>There can be multiple tags associated with each entity making it a multilabel classificatiopn problem.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1">### load training data</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;./data/dbpedia/DBPEDIA_train.csv&#39;</span><span class="p">,</span> 
                  <span class="n">encoding</span> <span class="o">=</span> <span class="s2">&quot;utf-8&quot;</span><span class="p">,</span> <span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;raw_text&#39;</span><span class="p">,</span> <span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">,</span><span class="s1">&#39;l3&#39;</span><span class="p">],</span><span class="n">header</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>raw_text</th>
      <th>l1</th>
      <th>l2</th>
      <th>l3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>William Alexander Massey (October 7, 1856 – Ma...</td>
      <td>Agent</td>
      <td>Politician</td>
      <td>Senator</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Lions is the sixth studio album by American ro...</td>
      <td>Work</td>
      <td>MusicalWork</td>
      <td>Album</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Pirqa (Aymara and Quechua for wall, hispaniciz...</td>
      <td>Place</td>
      <td>NaturalPlace</td>
      <td>Mountain</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Cancer Prevention Research is a biweekly peer-...</td>
      <td>Work</td>
      <td>PeriodicalLiterature</td>
      <td>AcademicJournal</td>
    </tr>
    <tr>
      <th>4</th>
      <td>The Princeton University Chapel is located on ...</td>
      <td>Place</td>
      <td>Building</td>
      <td>HistoricBuilding</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Data-Cleaning---">Data Cleaning  -<a class="anchor-link" href="#Data-Cleaning---">&#182;</a></h3><p>In this section, we shall perform some basic preprocessing on our raw text data using following techniques -</p>
<ol>
<li>merge title and synopsis data columns for better handling. We shall refer this column as raw_text</li>
<li>Split comma separated tags for each movie. </li>
<li>Remove punctuation and stopwords from raw_text. </li>
<li>Lemmatize raw_text -  Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma .
For more information on lemmatization refer to the <a href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html">stanford notes</a>. </li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">en_stopwords</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">))</span>
<span class="n">punctuations_filter</span> <span class="o">=</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">punctuations_filter</span><span class="p">)</span>


<span class="n">regex</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s1">&#39;[</span><span class="si">%s</span><span class="s1">]&#39;</span> <span class="o">%</span> <span class="n">re</span><span class="o">.</span><span class="n">escape</span><span class="p">(</span><span class="n">punctuations_filter</span><span class="p">))</span>
<span class="n">puncts_trans</span> <span class="o">=</span> <span class="n">string</span><span class="o">.</span><span class="n">maketrans</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>

<span class="n">lemmatizer</span> <span class="o">=</span> <span class="n">WordNetLemmatizer</span><span class="p">()</span> 

<span class="k">def</span> <span class="nf">get_cleaned_string</span><span class="p">(</span><span class="n">raw_string</span><span class="p">):</span>

    
    <span class="n">cleaned_text</span> <span class="o">=</span> <span class="n">regex</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">raw_string</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">lemmatizer</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">cleaned_text</span><span class="p">)</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">en_stopwords</span><span class="p">]</span>
    <span class="n">sentence</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sentence</span>


<span class="n">data</span><span class="p">[</span><span class="s1">&#39;cleaned_text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;raw_text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">get_cleaned_string</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>!&#34;#$%&amp;&#39;()*+,-/:;&lt;=&gt;?@[\]^_`{|}~
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train-Test-Split--">Train Test Split -<a class="anchor-link" href="#Train-Test-Split--">&#182;</a></h3><p>In this section, we shall split our data into 3 subsets -</p>
<p>a. Training data - This data will be used for training our classifier my minimizing the overall loss.<br>
b. Validation data - The Validation data will help in selecting hyper-parameters. Since this data is not explicitly used for training the model, validation data also helps in reducing overfitting. <br>
c. Test Data - We shall use test data to estimate model's performance on OOB (out-of-bag) data points.</p>
<p>Since there is no off the shelf function in sklearn or keras that splits dataset into 3 different subsets, We shall leverage the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html">train_test_split</a> function by making a call to it twice.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">raw_train_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.03</span><span class="p">)</span>
<span class="n">train_data</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">raw_train_data</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.03</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">validation_data</span> <span class="o">=</span> <span class="n">validation_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">&quot;Training data has </span><span class="si">%d</span><span class="s2"> datapoints&quot;</span><span class="o">%</span><span class="k">len</span>(train_data))
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Validation data has </span><span class="si">%d</span><span class="s2"> datapoints&quot;</span><span class="o">%</span><span class="k">len</span>(validation_data))
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Test data has </span><span class="si">%d</span><span class="s2"> datapoints&quot;</span><span class="o">%</span><span class="k">len</span>(test_data))
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training data has 226701 datapoints
Validation data has 7012 datapoints
Test data has 7229 datapoints
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[56]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">train_data</span><span class="p">[[</span><span class="s1">&#39;cleaned_text&#39;</span><span class="p">,</span> <span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="s1">&#39;l3&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cleaned_text</th>
      <th>l1</th>
      <th>l2</th>
      <th>l3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>national competition previously called nationa...</td>
      <td>Agent</td>
      <td>SportsLeague</td>
      <td>RugbyLeague</td>
    </tr>
    <tr>
      <th>1</th>
      <td>crbc established 1932 government r.b . bennett...</td>
      <td>Agent</td>
      <td>Broadcaster</td>
      <td>BroadcastNetwork</td>
    </tr>
    <tr>
      <th>2</th>
      <td>burger king v. rudzewicz 471 u.s. 462 1985 not...</td>
      <td>UnitOfWork</td>
      <td>LegalCase</td>
      <td>SupremeCourtOfTheUnitedStatesCase</td>
    </tr>
    <tr>
      <th>3</th>
      <td>lynda oconnell born 1981 cork camogie player a...</td>
      <td>Agent</td>
      <td>Athlete</td>
      <td>GaelicGamesPlayer</td>
    </tr>
    <tr>
      <th>4</th>
      <td>soreltracy éperviers soreltracy hawk hockey te...</td>
      <td>Agent</td>
      <td>SportsTeam</td>
      <td>HockeyTeam</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Label-Encoding--">Label Encoding -<a class="anchor-link" href="#Label-Encoding--">&#182;</a></h3><ol>
<li>In order to train a classifier, we need to convert the string tags into a vector of 1s and 0s. </li>
<li>There are about 71 tags in the dataset. </li>
<li>Therefore, for each datapoint, we need to construct a 1 x 71 dimensional vector with each bit in the vector representing a tag. </li>
<li>Since datapoint can have multiple tags, the target label will consist of 1s at all indices corresponding to the target tag attached to the datapoint. </li>
</ol>
<p>To accomplish this, we shall train a <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html">MultiLabelBinarizer</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">labelEncoder_model</span> <span class="o">=</span> <span class="n">MultiLabelBinarizer</span><span class="p">()</span>
<span class="n">labelEncoder_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">[[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="s1">&#39;l3&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[12]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>MultiLabelBinarizer(classes=None, sparse_output=False)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">unique_classes</span> <span class="o">=</span> <span class="n">labelEncoder_model</span><span class="o">.</span><span class="n">classes_</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;sample classes are </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="k">list</span>(unique_classes)[:10])
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>sample classes are [u&#39;AcademicJournal&#39;, u&#39;Actor&#39;, u&#39;AdultActor&#39;, u&#39;Agent&#39;, u&#39;Airline&#39;, u&#39;Airport&#39;, u&#39;Album&#39;, u&#39;AmateurBoxer&#39;, u&#39;Ambassador&#39;, u&#39;AmericanFootballPlayer&#39;]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Custom-Embedding-Layer--">Custom Embedding Layer -<a class="anchor-link" href="#Custom-Embedding-Layer--">&#182;</a></h2><ol>
<li>Embedding layer in keras is responsible of representing the input sequence of text with a vector of a size defined in the model. </li>
<li>one of the most adopted techniques while working with text is to train a tfidf vectorizer followed by a Dimensionality Reduction technique (PCA, Random Projections, etc) .</li>
<li>The embedding layer in keras facilitates the execution of sequence mentioned above while training a classifier. </li>
<li>It is also possible to derive weights from a pretrained model like word2vec or gloVe. However, in this article we shall focus on training a custom Embedding layer. </li>
<li>The Embedding layer expect a fixed input size of dimensions (batch_size $\times$ max_sequence_length) where max_sequence_length determines the maximum length of input text sequence. </li>
<li>The Output of Embedding Layer is a matrix of shape batch_size X max_sequence_length X embedding_size. </li>
</ol>
<p>In order to match the input contract, we shall train a keras Tokenizer using fit_on_texts function. Note that, one can use different techniques to identify the max sequence length. For the sake of this project, we will consider the 90th percentile of the input sequence length distribution.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">&quot;tokenizing input data...&quot;</span><span class="p">)</span>
<span class="n">tokenizer1</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="n">MAX_NB_WORDS</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">char_level</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">tokenizer1</span><span class="o">.</span><span class="n">fit_on_texts</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="s1">&#39;cleaned_text&#39;</span><span class="p">])</span>
<span class="n">train_data</span><span class="p">[</span><span class="s1">&#39;doc_len&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="s1">&#39;cleaned_text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">sentence</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>tokenizing input data...
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Attention-Mechanism--">Attention Mechanism -<a class="anchor-link" href="#Attention-Mechanism--">&#182;</a></h2><p>Before we proceed further, I would like to take a pause and delve into the philosophical and mathematical details of Attention Mechanism.</p>
<h3 id="Why-Attention-Mechanism-?">Why Attention Mechanism ?<a class="anchor-link" href="#Why-Attention-Mechanism-?">&#182;</a></h3><ul>
<li>Consider a simple spam vs not-spam binary text classification problem where input is a free flowing email text and you would like to predict if it is a spam or not-spam. </li>
<li>Typically, if you were to decide manually, you invariably look for trigger words (Nigerian Prince, Lottery Winner, No credit check, &lt;suspicious link&gt; , etc) which would hint towards an email being spam.</li>
<li>These trigger words influence your decision no matter where they appear in text. In other words, subconsciously you end up assigning a higher weight to these trigger keywords which ultimately helps you reach a decision. </li>
<li>Attention Mechanism tries to replicate a similar behaviour where it attempts to assign a higher weightage to trigger keywords that ultimately helps our model in reaching a decision. </li>
</ul>
<h3 id="Aren't-the-likes-of-GRUs-and-LSTMs-suppose-to-do-something-similar?">Aren't the likes of GRUs and LSTMs suppose to do something similar?<a class="anchor-link" href="#Aren't-the-likes-of-GRUs-and-LSTMs-suppose-to-do-something-similar?">&#182;</a></h3><ul>
<li>Well, a typical RNN network suffers from the problem of vanishing gradients. As a result, earlier parts of a temporal data is unable to contribute towards the final decision being made. </li>
<li>GRUs and LSTMs are able to ameliorate this problem by introducing memory cells and forget gates.</li>
<li>However, they can remember sequences of 100s but not definitely not 1000s. </li>
<li>Sure, one can take a Global Max of returned activations and use them to predict classes but a "hard-max" takes the maximum value and forgets everything else.  </li>
</ul>
<p>ENTER ATTENTION MECHANISM !!</p>
<p><img src="./../../../images/multiclass_attention/entry_meme.gif"><br></p>
<ul>
<li>A softmax (Attention weights) gives the probability distribution over each activation at different time steps. Definitely, a distribution is more helpful than a point estimate (Stats 101, right?)</li>
</ul>
<h3 id="Estimating-Attention-Weights-while-training--">Estimating Attention Weights while training -<a class="anchor-link" href="#Estimating-Attention-Weights-while-training--">&#182;</a></h3><ul>
<li>Hopefully, the need for an Attention Mechanism is justified in the previous section. </li>
<li>In this section, let's go over some of the mathematical details to better understand the concept. This will help us while building the network as well. </li>
</ul>
<h4 id="Let's-get-to-it--">Let's get to it -<a class="anchor-link" href="#Let's-get-to-it--">&#182;</a></h4><ul>
<li>It is evident that these weights are dynamic and hence cannot be pre-computed. </li>
<li>The following image by WildML summarises the attention mechanism in a block diagram format. </li>
</ul>
<p><img src="./../../../images/multiclass_attention/attention_mechanism_image.png"><br></p>
<ul>
<li>As seen in the above image, the output at time 't' is a weighted average of weights $\alpha^{&lt;t,t'&gt;}$ where t' = ${1, 2, 3....T_x}$</li>
<li>$\alpha^{&lt;t,t'&gt;}$ indicates the amount of attention that $y^{&lt;t&gt;}$ should pay to $a^{&lt;t'&gt;}$  <br></li>
<li><font size="3"> \begin{align} 
   c^{<t>} = \sum_{t'=1}^{Tx} \alpha^{<t,t'>} * a^{<t'>}  \end{align} </font></li>
</ul>
<h3 id="How-to-compute-$\alpha^{&lt;t,t'&gt;}$-?">How to compute $\alpha^{&lt;t,t'&gt;}$ ?<a class="anchor-link" href="#How-to-compute-$\alpha^{&lt;t,t'&gt;}$-?">&#182;</a></h3><ul>
<li>Since $\alpha^{&lt;t,t'&gt;}$ are weights at time t representing the probability distribution of attentions, a good way to model them would be to use Softmax (If you guessed it, be proud of yourselves !!)</li>
</ul>
<p>Let's define -</p>
<ul>
<li><p><font size="3"> \begin{align}
  \alpha^{<t,t'>} = \frac{\exp{e^{<t,t'>}}}{\sum_{t=1}^{T_x} \exp{e^{<t,t'>}}} \end{align} </font></p>
</li>
<li><p>It is easy to conclude that where model should pay attention is dictated by the values of $&lt;e^{t,t'}&gt;$</p>
</li>
<li><p>Where to pay attention depends not only on hidden states ($a^{&lt;t'&gt;}$) but also on where we are in the output ($s^{&lt;t-1&gt;}$)  sequence of length $T_y$.</p>
</li>
<li><p>However, we don't know the function that maps hidden states and current output to $e^{&lt;t,t'&gt;}$. Hence we shall determine the function using a small neural network.</p>
</li>
<li><p>In text classification, the output steps are limited to 1. This simplifies our problem statement. The magnified block diagram for attention mechanism is as follows - 
<img src="./../../../images/multiclass_attention/attention_magnified_diagram.png"><br></p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Hierarchical-Attention-Network--">Hierarchical Attention Network -<a class="anchor-link" href="#Hierarchical-Attention-Network--">&#182;</a></h2><ul>
<li>With the basics around attention network chalked out, let's take this a notch higher. </li>
<li>Hierarchical Attention Networks were introduced by Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He, Alex Smola, &amp; Eduard Hovy at Carnegie Melon in association with Microsoft. </li>
<li>The proposed model exploits the herarchical structure in documents. </li>
<li>Each document can be viewed as a group sentences with each sentence as collection of words. </li>
<li>The block diagram of the architecture is as follows - </li>
</ul>
<p><img src="./../../../images/multiclass_attention/HAN.png"><br></p>
<ul>
<li>The model represents a document representation by building a representation of sentences which are then aggregated.</li>
<li>Further, the model also represents each sentence by building a representation of words.</li>
<li>This takes into account the fact that words as well as sentences are differentially important based on context. </li>
</ul>
<p>The original paper can be found <a href="https://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf">here</a>. Do take some time to read it.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Data-Wrangling--">Data Wrangling -<a class="anchor-link" href="#Data-Wrangling--">&#182;</a></h3><ul>
<li>It is now time to implement the ideas studied in earlier sections. </li>
<li>We start by pre-processing our input data. </li>
<li>The raw input data consists of paragraphs of textual information of dimensions m $\times$ 1. </li>
<li>In the next section, we simply convert of 1D data into 2D. The new dimensions will be $m \times n_{sent} \times n_{words}$ where m is the number of training examples, $n_{sent}$ is the maximum number of sentences in each training example and $n_{words}$ is the maximum number of words in a sentence. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">tot_sents</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">num_sents</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">len_sent</span> <span class="o">=</span> <span class="p">[]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">for</span> <span class="n">text_val</span> <span class="ow">in</span> <span class="n">train_data</span><span class="p">[</span><span class="s1">&#39;cleaned_text&#39;</span><span class="p">]:</span>
    
    <span class="n">ind_sentences</span> <span class="o">=</span> <span class="n">sent_tokenize</span><span class="p">(</span><span class="n">text_val</span><span class="p">)</span>
    <span class="n">tot_sents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ind_sentences</span><span class="p">)</span>
    <span class="n">num_sents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ind_sentences</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">ind_sentences</span><span class="p">:</span>
        <span class="n">len_sent</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">sent</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">max_sent_len</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">len_sent</span><span class="p">,</span> <span class="mi">98</span><span class="p">))</span>
<span class="n">max_num_sent</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">num_sents</span><span class="p">,</span> <span class="mi">95</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">&quot;Max sentences capped to </span><span class="si">%f</span><span class="s2">&quot;</span><span class="o">%</span><span class="k">max_num_sent</span>)
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Max sentence length capped at </span><span class="si">%f</span><span class="s2">&quot;</span><span class="o">%</span><span class="k">max_sent_len</span>)
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Max sentences capped to 12.000000
Max sentence length capped at 38.000000
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">train_data_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="s1">&#39;cleaned_text&#39;</span><span class="p">]),</span> <span class="n">max_num_sent</span><span class="p">,</span> <span class="n">max_sent_len</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sentences</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tot_sents</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">sent</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentences</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">j</span><span class="o">&lt;</span> <span class="n">max_num_sent</span><span class="p">:</span>
            <span class="n">wordTokens</span> <span class="o">=</span> <span class="n">text_to_word_sequence</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span>
            <span class="n">k</span><span class="o">=</span><span class="mi">0</span>
            <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">wordTokens</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">k</span><span class="o">&lt;</span><span class="n">max_sent_len</span> <span class="ow">and</span> <span class="n">tokenizer1</span><span class="o">.</span><span class="n">word_index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="o">&lt;</span><span class="n">MAX_NB_WORDS</span><span class="p">:</span>
                        <span class="n">train_data_np</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">tokenizer1</span><span class="o">.</span><span class="n">word_index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
                        <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="k">pass</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">val_sents</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">text_val</span> <span class="ow">in</span> <span class="n">validation_data</span><span class="p">[</span><span class="s1">&#39;cleaned_text&#39;</span><span class="p">]:</span>
    
    <span class="n">ind_sentences</span> <span class="o">=</span> <span class="n">sent_tokenize</span><span class="p">(</span><span class="n">text_val</span><span class="p">)</span>
    <span class="n">val_sents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ind_sentences</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">val_data_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_data</span><span class="p">[</span><span class="s1">&#39;cleaned_text&#39;</span><span class="p">]),</span> <span class="n">max_num_sent</span><span class="p">,</span> <span class="n">max_sent_len</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sentences</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">val_sents</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">sent</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentences</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">j</span><span class="o">&lt;</span> <span class="n">max_num_sent</span><span class="p">:</span>
            <span class="n">wordTokens</span> <span class="o">=</span> <span class="n">text_to_word_sequence</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span>
            <span class="n">k</span><span class="o">=</span><span class="mi">0</span>
            <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">wordTokens</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">k</span><span class="o">&lt;</span><span class="n">max_sent_len</span> <span class="ow">and</span> <span class="n">tokenizer1</span><span class="o">.</span><span class="n">word_index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="o">&lt;</span><span class="n">MAX_NB_WORDS</span><span class="p">:</span>
                        <span class="n">val_data_np</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">tokenizer1</span><span class="o">.</span><span class="n">word_index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
                        <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="k">pass</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">word_index</span> <span class="o">=</span> <span class="n">tokenizer1</span><span class="o">.</span><span class="n">word_index</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer1</span><span class="o">.</span><span class="n">word_index</span><span class="p">)</span> <span class="o">+</span><span class="mi">1</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Vocab size - </span><span class="si">%d</span><span class="s2">&quot;</span><span class="o">%</span><span class="k">vocab_size</span>)
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Vocab size - 566172
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Transfer-Learning--">Transfer Learning -<a class="anchor-link" href="#Transfer-Learning--">&#182;</a></h3><ul>
<li>To expedite the training process, we shall piggy back on pre-trained gloVe models. </li>
<li>The process of building Embedding matrix is pretty standard. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1">#load embeddings</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;loading word embeddings...&#39;</span><span class="p">)</span>
<span class="n">embeddings_index</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">codecs</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;glove_pretrained&#39;</span> <span class="p">,</span><span class="s1">&#39;glove.42B.300d.txt&#39;</span><span class="p">),</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span><span class="o">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
    <span class="n">word</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
    <span class="n">embeddings_index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">coefs</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;found </span><span class="si">%s</span><span class="s1"> word vectors&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">embeddings_index</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>loading word embeddings...
found 1917494 word vectors
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1">#embedding matrix</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;preparing embedding matrix...&#39;</span><span class="p">)</span>
<span class="n">words_not_found</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">nb_words</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">MAX_NB_WORDS</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
<span class="n">embedding_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nb_words</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">))</span>
<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">word_index</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">nb_words</span><span class="p">:</span>
        <span class="k">continue</span>
    <span class="n">embedding_vector</span> <span class="o">=</span> <span class="n">embeddings_index</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">embedding_vector</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">embedding_vector</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># words not found in embedding index will be all-zeros.</span>
        <span class="n">embedding_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">embedding_vector</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">words_not_found</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;number of null word embeddings: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">embedding_matrix</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>preparing embedding matrix...
number of null word embeddings: 120322
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">prepare_training_generators</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span><span class="n">train_y</span><span class="p">,</span> <span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">channel_orientation</span> <span class="o">=</span> <span class="s2">&quot;channels_first&quot;</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    This function generates mini batches of training data in the form of an iterator.</span>
<span class="sd">    inputs:</span>
<span class="sd">        train_df: pandas dataframe of training data. </span>
<span class="sd">        len_unique_classes - integer value highlighting the number of unique target labels in training data.</span>
<span class="sd">        chunk_size - integer value highlighting the mini batch siz. The default value is set to 16</span>
<span class="sd">        channel_orientation - A string values used to represenattion the channel orientation of images to be read.</span>
<span class="sd">    output:</span>
<span class="sd">        iterator of text_data, image_data and output label</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_x</span><span class="p">))</span>
    <span class="n">index_tracker</span> <span class="o">=</span> <span class="mi">0</span> 
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">batch_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">index_tracker</span> <span class="p">:</span> <span class="n">index_tracker</span><span class="o">+</span><span class="n">chunk_size</span><span class="p">]</span>
        <span class="n">text_x</span> <span class="o">=</span> <span class="n">train_x</span><span class="p">[</span><span class="n">batch_indices</span><span class="p">]</span>
        <span class="n">y_le</span> <span class="o">=</span> <span class="n">labelEncoder_model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">train_y</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">batch_indices</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="s1">&#39;l3&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">index_tracker</span> <span class="o">+=</span> <span class="n">chunk_size</span>
        <span class="k">if</span> <span class="n">index_tracker</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_x</span><span class="p">):</span>
            <span class="n">index_tracker</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
            
        <span class="k">yield</span> <span class="n">text_x</span><span class="p">,</span><span class="n">y_le</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loss-Function-and-Evaluation-metric--">Loss Function and Evaluation metric -<a class="anchor-link" href="#Loss-Function-and-Evaluation-metric--">&#182;</a></h2><h4 id="Loss-Function--">Loss Function -<a class="anchor-link" href="#Loss-Function--">&#182;</a></h4><ul>
<li>A cross entropy loss for C classes and m training examples is defined as - </li>
</ul>
\begin{align} CE = - \sum_{i = 1}^{m} \sum_{j= 1}^{C} y_ilog(\hat{y_i})\end{align}<ul>
<li>Typically a Binary classification problem uses a sigmoid activation in the final layer of the neural network. </li>
<li>The sigmoid function for pre-activations $z$ is defined as - </li>
</ul>
\begin{align}  \hat{y} = \frac{1}{1 + e^{-z}} \end{align}
<pre><code>     Where,  
</code></pre>
\begin{align}                 z = WX + b \end{align}\begin{align}                            X = m \times n \end{align}\begin{align}                              W = n \times 1  \end{align}<p>The cross entropy loss function for binary classification can hence be written as  -
\begin{align} BCE &amp; = - \sum_{i = 1}^{m} \sum_{j= 1}^{2} y_ilog(\hat{y_i})  \\
&amp; =  - \sum_{i = 1}^{m} y_i log(\hat{y_i}) + (1- y_i)log(1 - \hat{y_i}) \end{align}</p>
<ul>
<li>For multilabel classification we shall assume that each label as an independent Binomial Random Variable. </li>
<li>As a result of this assumption, a loss of Binary loss function makes much more sense than a categorical cross entropy function. </li>
<li>Lastly, by the assumption of independence, since the probability that a data point belongs to class i is independent of whether of class j, the activation in the final layer of the network has to be "sigmoid" and not "softmax". </li>
</ul>
<p>For a multilabel classification problem, various different loss function can also be used. Check them out at the following links for more information.</p>
<ol>
<li><a href="http://www.cs.put.poznan.pl/sigml/wp-content/uploads/2013/04/mlc-mlgroup.pdf">Multilabel Classification - Label Dependence, Loss Minimization and Reduction Algorithms by Krzysztof Dembczy´nski</a></li>
<li><a href="https://people.revoledu.com/kardi/tutorial/Similarity/BinaryVariables.html">Distance for Binary Variables</a></li>
<li><a href="http://ceur-ws.org/Vol-2126/paper10.pdf">Approaches for the Improvement of the Multilabel Multiclass Classification with a huge Number of Classes by Martha Tatusch</a></li>
</ol>
<h3 id="Evaluation-Metric--">Evaluation Metric -<a class="anchor-link" href="#Evaluation-Metric--">&#182;</a></h3><ul>
<li>Typically, a standard metric for classification like accuracy can suffice. </li>
<li>However, it can often be misleading when target labels have only a small subset which is positive. In such cases, accuracy is often over-estimated. </li>
<li>To overcome this problem, we shall be using a custom loss function defined by Matthew R. Boutell in <a href="https://www.rose-hulman.edu/~boutell/publications/boutell04PRmultilabel.pdf">Learning multi-label scene classification</a></li>
<li>Please find below a snippet from the paper which describes the $\alpha evaluation$ metric - </li>
</ul>
<p><img src="./../../../images/multiclass_attention/alpha_evaluation.png"><br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">softmax_over_time</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">assert</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">)</span>
  <span class="n">e</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">K</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
  <span class="n">s</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">e</span> <span class="o">/</span> <span class="n">s</span>

<span class="k">def</span> <span class="nf">check_nonzero</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="n">y_pred</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Custom metric</span>
<span class="sd">    Returns sum of all embeddings</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mf">0.4</span><span class="p">,</span> <span class="s1">&#39;int32&#39;</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">custom_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    score reference - https://www.rose-hulman.edu/~boutell/publications/boutell04PRmultilabel.pdf</span>
<span class="sd">    more resources - </span>
<span class="sd">    </span>
<span class="sd">    1. Distance between binary variables - https://people.revoledu.com/kardi/tutorial/Similarity/BinaryVariables.html</span>
<span class="sd">    2. jaccard co-efficient (intersection over union) - https://people.revoledu.com/kardi/tutorial/Similarity/Jaccard.html</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="s1">&#39;int32&#39;</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">y_pred</span><span class="p">),</span> <span class="s1">&#39;int32&#39;</span><span class="p">)</span>
    <span class="n">neg_y_true</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">y_true</span>
    <span class="n">neg_y_pred</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">y_pred</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;float32&#39;</span><span class="p">)</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.75</span><span class="p">,</span> <span class="s1">&#39;float32&#39;</span><span class="p">)</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;float32&#39;</span><span class="p">)</span>
    
    <span class="n">tp</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_true</span> <span class="o">*</span> <span class="n">y_pred</span><span class="p">),</span> <span class="s1">&#39;float32&#39;</span><span class="p">)</span>
    <span class="n">fp</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">neg_y_true</span> <span class="o">*</span> <span class="n">y_pred</span><span class="p">),</span> <span class="s1">&#39;float32&#39;</span><span class="p">)</span>
    <span class="n">fn</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_true</span> <span class="o">*</span> <span class="n">neg_y_pred</span><span class="p">),</span> <span class="s1">&#39;float32&#39;</span><span class="p">)</span>
    
    <span class="n">score</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">((</span><span class="n">beta</span> <span class="o">*</span> <span class="n">fn</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">fp</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">fn</span><span class="o">+</span> <span class="n">fp</span> <span class="o">+</span><span class="n">tp</span> <span class="o">+</span> <span class="n">K</span><span class="o">.</span><span class="n">epsilon</span><span class="p">()))</span>

    <span class="k">return</span> <span class="n">score</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Building-HAN-Model--">Building HAN Model -<a class="anchor-link" href="#Building-HAN-Model--">&#182;</a></h3><ul>
<li>In order to build a Hierarchical Attention network, we will split it into two models for better visibility, debugging and code management. </li>
<li>First, we define a "word attention model" which takes a sentence as input and return activations based an attention mechanism. </li>
<li>Next we design a "sentence attention model" which is responsible for representing attention mechanism for each sentence at the input.</li>
<li>Note that, we shall be using TimeDistributed layer provided by keras to extract word attention representation for each sentence at the input. The TimeDistributed layer ensures that same weights are applied to each input in the sequence. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">word_encoder</span><span class="p">(</span><span class="n">text_input_shape</span><span class="p">):</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">text_input_shape</span><span class="p">)</span>

    <span class="n">x</span><span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">embedding_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">embedding_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
              <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="n">embedding_matrix</span><span class="p">],</span> <span class="n">trainable</span><span class="o">=</span><span class="bp">False</span><span class="p">)(</span><span class="n">inp</span><span class="p">)</span>
<span class="c1">#     x = Embedding(vocab_size, latent_dim)(inp)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">Bidirectional</span><span class="p">(</span><span class="n">GRU</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">recurrent_dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="c1">## FCNN for estimating attention weights. </span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">)(</span><span class="n">h</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">u</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;tanh&#39;</span><span class="p">)(</span><span class="n">u</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">u</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">u</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="n">softmax_over_time</span><span class="p">)(</span><span class="n">u</span><span class="p">)</span>
    
    <span class="c1">## weighted average of attention weights and GRU output sequence for words. </span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">Dot</span><span class="p">(</span><span class="n">axes</span><span class="o">=</span><span class="mi">1</span><span class="p">)([</span><span class="n">u</span><span class="p">,</span> <span class="n">h</span><span class="p">])</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">s</span><span class="p">)</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inp</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">s</span><span class="p">)</span>
    <span class="n">word_attention_weights_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">inp</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">u</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">word_attention_weights_model</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">sent_encoder</span><span class="p">(</span><span class="n">word_encoder</span><span class="p">,</span> <span class="n">text_input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">33</span><span class="p">),</span> <span class="n">classes</span> <span class="o">=</span> <span class="mi">6</span><span class="p">):</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">text_input_shape</span><span class="p">)</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">TimeDistributed</span><span class="p">(</span><span class="n">word_encoder</span><span class="p">)(</span><span class="n">inp</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">Bidirectional</span><span class="p">(</span><span class="n">GRU</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">recurrent_dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="c1">## FCNN for estimating attention weights.</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">)(</span><span class="n">h</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">u</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;tanh&#39;</span><span class="p">)(</span><span class="n">u</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">u</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">u</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="n">softmax_over_time</span><span class="p">)(</span><span class="n">u</span><span class="p">)</span>
    
    <span class="c1">## Weighted average of attention and sentence representation sequencs.  </span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">Dot</span><span class="p">(</span><span class="n">axes</span><span class="o">=</span><span class="mi">1</span><span class="p">)([</span><span class="n">u</span><span class="p">,</span> <span class="n">h</span><span class="p">])</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">s</span><span class="p">)</span>
    
    <span class="c1">## Note that the activation for final layer is sigmoid and softmax. </span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)(</span><span class="n">s</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inp</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
    <span class="n">attention_weights_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inp</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">u</span><span class="p">)</span>
    
    <span class="n">opt</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">amsgrad</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    
    <span class="c1">## Note that the loss function is &#39;binary_crossentropy&#39;</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">custom_score</span><span class="p">,</span> <span class="n">check_nonzero</span><span class="p">])</span>
    <span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">attention_weights_model</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[48]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">word_encoder_model</span><span class="p">,</span> <span class="n">word_attention_model</span> <span class="o">=</span> <span class="n">word_encoder</span><span class="p">(</span><span class="n">text_input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">max_sent_len</span><span class="p">,</span> <span class="p">))</span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 38)           0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 38, 300)      90000000    input_5[0][0]                    
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 38, 300)      1200        embedding_3[0][0]                
__________________________________________________________________________________________________
bidirectional_5 (Bidirectional) (None, 38, 256)      329472      batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 38, 256)      65792       bidirectional_5[0][0]            
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 38, 256)      1024        dense_11[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 38, 256)      0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 38, 1)        257         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 38, 1)        4           dense_12[0][0]                   
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 38, 1)        0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
dot_5 (Dot)                     (None, 1, 256)       0           activation_10[0][0]              
                                                                 bidirectional_5[0][0]            
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 256)          0           dot_5[0][0]                      
==================================================================================================
Total params: 90,397,749
Trainable params: 396,635
Non-trainable params: 90,001,114
__________________________________________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[49]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">text_only_model</span><span class="p">,</span> <span class="n">sent_attention_weights_model</span> <span class="o">=</span> <span class="n">sent_encoder</span><span class="p">(</span><span class="n">word_encoder_model</span><span class="p">,</span> <span class="n">text_input_shape</span> <span class="o">=</span><span class="p">(</span><span class="n">max_num_sent</span><span class="p">,</span> <span class="n">max_sent_len</span><span class="p">)</span> <span class="p">,</span><span class="n">classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">labelEncoder_model</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_6 (InputLayer)            (None, 12, 38)       0                                            
__________________________________________________________________________________________________
time_distributed_3 (TimeDistrib (None, 12, 256)      90397749    input_6[0][0]                    
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 12, 256)      1024        time_distributed_3[0][0]         
__________________________________________________________________________________________________
bidirectional_6 (Bidirectional) (None, 12, 64)       55488       batch_normalization_16[0][0]     
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 12, 128)      8320        bidirectional_6[0][0]            
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 12, 128)      512         dense_13[0][0]                   
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 12, 128)      0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 12, 1)        129         activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 12, 1)        4           dense_14[0][0]                   
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 12, 1)        0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
dot_6 (Dot)                     (None, 1, 64)        0           activation_12[0][0]              
                                                                 bidirectional_6[0][0]            
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 64)           0           dot_6[0][0]                      
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 298)          19370       flatten_6[0][0]                  
==================================================================================================
Total params: 90,482,596
Trainable params: 480,712
Non-trainable params: 90,001,884
__________________________________________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[50]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">tboard</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">TensorBoard</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s1">&#39;./logs&#39;</span><span class="p">,</span> <span class="n">histogram_freq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">write_graph</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">write_grads</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                                       <span class="n">write_images</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">embeddings_freq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">embeddings_layer_names</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">embeddings_metadata</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">embeddings_data</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>

<span class="n">validation_data_gen</span> <span class="o">=</span> <span class="n">prepare_training_generators</span><span class="p">(</span><span class="n">val_data_np</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">chunk_size</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="p">)</span>
<span class="n">train_data_gen</span> <span class="o">=</span> <span class="n">prepare_training_generators</span><span class="p">(</span><span class="n">train_data_np</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">chunk_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[51]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">history3</span> <span class="o">=</span> <span class="n">text_only_model</span><span class="o">.</span><span class="n">fit_generator</span><span class="p">(</span><span class="n">train_data_gen</span><span class="p">,</span>
                    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">),</span>
                    <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                    <span class="n">validation_data</span> <span class="o">=</span> <span class="n">validation_data_gen</span><span class="p">,</span>
                    <span class="n">validation_steps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_data</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">),</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">tboard</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/5
18891/18891 [==============================] - 13359s 707ms/step - loss: 0.0221 - custom_score: 0.6035 - check_nonzero: 26.4339 - val_loss: 0.0066 - val_custom_score: 0.8510 - val_check_nonzero: 34.5274
Epoch 2/5
18891/18891 [==============================] - 6789s 359ms/step - loss: 0.0065 - custom_score: 0.8494 - check_nonzero: 34.3188 - val_loss: 0.0045 - val_custom_score: 0.8968 - val_check_nonzero: 35.6263
Epoch 3/5
18891/18891 [==============================] - 6793s 360ms/step - loss: 0.0052 - custom_score: 0.8778 - check_nonzero: 35.0802 - val_loss: 0.0039 - val_custom_score: 0.9105 - val_check_nonzero: 35.9709
Epoch 4/5
18891/18891 [==============================] - 6924s 367ms/step - loss: 0.0046 - custom_score: 0.8906 - check_nonzero: 35.3497 - val_loss: 0.0036 - val_custom_score: 0.9171 - val_check_nonzero: 36.2400
Epoch 5/5
18891/18891 [==============================] - 6511s 345ms/step - loss: 0.0043 - custom_score: 0.8974 - check_nonzero: 35.4717 - val_loss: 0.0034 - val_custom_score: 0.9207 - val_check_nonzero: 36.1354
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Training-Analysis--">Training Analysis -<a class="anchor-link" href="#Training-Analysis--">&#182;</a></h3><ul>
<li>It can be seen that the loss is decreasing consistently across epochs. </li>
<li>The custom_score keeps getting better. </li>
<li>The custom_score and loss on validation dataset is comparable with training phase which indicates that the model is not overfitting.  </li>
</ul>
<h3 id="Investigating-Attention-Mechanism--">Investigating Attention Mechanism -<a class="anchor-link" href="#Investigating-Attention-Mechanism--">&#182;</a></h3><ul>
<li>In order to gain more insights on how our model is training, let us perform a quick analysis of how model is estimated weights and which words are actually being paid attention to while predicting multilabel classes. </li>
<li>To facilitate this analysis, we have tapped our original models to spit out attention weighted activations.</li>
<li>Based on these activations, we can back trace the word in the input which are influencing the final decision. </li>
</ul>
<p>Without much further a do, lets jump into the implementation !!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[52]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">sugg_num</span> <span class="o">=</span> <span class="mi">190</span>
<span class="n">tokenized_sentences</span> <span class="o">=</span> <span class="n">sent_tokenize</span><span class="p">(</span><span class="n">validation_data</span><span class="p">[</span><span class="s1">&#39;cleaned_text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">sugg_num</span><span class="p">])</span>
<span class="n">true_labels</span> <span class="o">=</span> <span class="n">validation_data</span><span class="p">[[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">,</span><span class="s1">&#39;l3&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">sugg_num</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;True labels are </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="k">true_labels</span>)
<span class="k">for</span> <span class="n">sent_num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenized_sentences</span><span class="p">)):</span>
    
    <span class="n">word_attention_vector</span> <span class="o">=</span> <span class="n">word_attention_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">val_data_np</span><span class="p">[</span><span class="n">sugg_num</span><span class="p">:</span><span class="n">sugg_num</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">sent_num</span><span class="p">,</span> <span class="p">:])[</span><span class="mi">0</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">word_attention_vector</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">sorted_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">word_attention_vector</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">tokenized_words</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">tokenized_sentences</span><span class="p">[</span><span class="n">sent_num</span><span class="p">])</span>
    <span class="n">padded_tokenized_words</span> <span class="o">=</span> <span class="n">tokenized_words</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;&lt;dummy&gt;&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_sent_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenized_words</span><span class="p">))</span>
    <span class="n">top_words</span> <span class="o">=</span> <span class="n">itemgetter</span><span class="p">(</span><span class="o">*</span><span class="n">sorted_indices</span><span class="p">)(</span><span class="n">padded_tokenized_words</span><span class="p">)</span>
    
    <span class="n">short_listed_words</span> <span class="o">=</span> <span class="p">[(</span><span class="n">word</span><span class="p">,</span> <span class="n">attention_weight</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">attention_weight</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">top_words</span><span class="p">,</span> <span class="n">sorted_weights</span><span class="p">)</span> <span class="k">if</span> <span class="n">attention_weight</span> <span class="o">&gt;</span> <span class="mf">0.15</span><span class="p">]</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Sentence is </span><span class="se">\n</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="k">tokenized_sentences</span>[sent_num])
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Focused words are </span><span class="se">\n</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="k">short_listed_words</span>)
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;*************************************************&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>True labels are [u&#39;Event&#39; u&#39;SportsEvent&#39; u&#39;WrestlingEvent&#39;]
Sentence is 
 professional wrestling hardcore heaven event held philadelphia pennsylvania united statesbased professional wrestling promotion eastern championship wrestlingextreme championship wrestling annually 1994 1995 1996 1997 1999 2000.
Focused words are 
 [(u&#39;wrestling&#39;, 0.22687979), (u&#39;event&#39;, 0.22041698), (u&#39;wrestling&#39;, 0.178191)]
*************************************************
Sentence is 
 1997 1999 2000 iteration hardcore heaven aired payperview .
Focused words are 
 [(u&#39;iteration&#39;, 0.27779353), (u&#39;aired&#39;, 0.27136996)]
*************************************************
Sentence is 
 footage six hardcore heaven event owned wwe .
Focused words are 
 [(u&#39;footage&#39;, 0.3976578), (u&#39;event&#39;, 0.36673942)]
*************************************************
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Results-and-Final-Comments--">Results and Final Comments -<a class="anchor-link" href="#Results-and-Final-Comments--">&#182;</a></h3><p>VOILA !!! We can now trace the path of how the model is reaching its decision.</p>
<ol>
<li>As seen from the output printed on the console, the input text is describing a wrestling event. </li>
<li>The model is iterating over different sentences and words with more "Attention" are being printed. </li>
<li>The model is able to correctly assign weights in each word which is indicative of wrestling despite having other words like philadelphia, pennsylvania, and unites states which hints towards "Place" as a potential label. </li>
<li>By assigning a lower weights to words that are not so important in the overall context of the document, the model is more robust and accurate. </li>
</ol>
<h4 id="Final-Comments--">Final Comments -<a class="anchor-link" href="#Final-Comments--">&#182;</a></h4><ol>
<li>To scope down the problem statement, the output sequence in our problem definition has a size 1. </li>
<li>Hence it suffices to ignore the previous decoder states while estimating attentions at time t. </li>
<li>In other words, $T_y$ in our case is 1 which largely simplifies the implementation. </li>
<li>The code will change if we are tasked with a use case that involves a temporal output. In such a situation, we will have to account for previous decoder states while estimating attentions. </li>
<li><p>Finally, this article covers a lot of new concepts viz. -</p>
<p>a. Formulation of Multilabel classification <br>
 b. Attention Mechanism <br>
 c. Hierarchical Attention Network <br>
 d. Loss function and Activations for multilabel classification problem <br>
 e. custom loss function. <br></p>
</li>
</ol>
<p>Some of these may not be easy to digest. Feel free to reach out to me if you have any queries or would like to brainstorm ideas.</p>

</div>
</div>
</div>
 


<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['$','$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        " linebreaks: { automatic: true, width: '95% container' }, " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
</p>
        </div>
    </div>

<div class="fh5co-narrow-content">
<div class="animate-box" data-animate-effect="fadeInLeft">
    <h2><!-- <i class="icon-speech-bubble"></i>  -->Comments</h2>
</div>
<div class="animate-box" data-animate-effect="fadeInLeft">
    <div id="disqus_thread"></div>
</div>

<script>
var disqus_config = function () { 
  this.language = "en";
};
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://gitcd-dev.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript><a href="https://disqus.com/?ref_noscript">Please enable JavaScript to view the comments powered by Disqus.</a></noscript>
<div class="fh5co-footer">
    <br>
    <p><small>&copy; 2018 The Data Mint. All Rights Reserved.</span> <span>Designed by <a href="http://freehtml5.co/" target="_blank">FreeHTML5.co</a></span>
    <br /><span>Pelican Theme by: <a href="https://github.com/claudio-walser/pelican-fh5co-marble" target="_blank">Claudio Walser</a></span></small></p>

</div>                
        </div>
    </div>

    <!-- jQuery -->
    <script src="/theme/js/jquery.min.js"></script>
    <!-- jQuery Easing -->
    <script src="/theme/js/jquery.easing.1.3.js"></script>
    <!-- Bootstrap -->
    <script src="/theme/js/bootstrap.min.js"></script>
    <!-- Waypoints -->
    <script src="/theme/js/jquery.waypoints.min.js"></script>
    <!-- Flexslider -->
    <script src="/theme/js/jquery.flexslider-min.js"></script>


    <!-- MAIN JS -->
    <script src="/theme/js/main.js"></script>
    </body>
</html>
